1. 메모리 관리 (Memory Management)
1-1. 심각: config_load 함수 내 문자열 처리 오류 (Use-after-free)
파일: src/config.c

문제점: toml_string_in 함수로 TOML 파일에서 문자열을 읽은 후, strdup으로 복사하고 나서 곧바로 원본 문자열을 free(d.u.s)로 해제합니다. toml.c 라이브러리의 구현에 따라 d.u.s는 라이브러리가 관리하는 메모리일 수 있으므로, 사용자가 직접 해제하면 이중 해제(Double Free) 또는 해제 후 사용(Use-after-free) 버그를 유발할 수 있습니다. toml_free(conf)가 호출될 때 라이브러리가 알아서 전체 메모리를 해제해야 합니다.

코드:

C

d = toml_string_in(paths, "train_fasta");
if (d.ok) {
  config->train_fasta = strdup(d.u.s);
  free(d.u.s); // <--- 이 부분이 문제입니다.
}


수정 제안: free(d.u.s); 라인을 모두 제거해야 합니다.

1-2. 중요: fft 함수 내 불필요한 메모리 할당 및 복사
파일: src/fft.c

문제점: fft 함수는 비트 반전 순열(bit-reversal permutation)을 위해 임시 버퍼 temp를 할당하고, bit_reverse_copy를 호출한 뒤 memcpy로 다시 원본 버퍼에 복사합니다. 이 과정은 불필요하며, 입력 버퍼를 직접 수정(in-place)하는 방식으로 최적화할 수 있습니다. 현재 방식은 매 FFT 호출마다 메모리 할당, 복사, 해제를 반복하여 성능 저하를 유발합니다.

코드:

C

cplx* temp = (cplx*)malloc(n * sizeof(cplx));
bit_reverse_copy(temp, x, n);
memcpy(x, temp, n * sizeof(cplx));
free(temp);


수정 제안: bit_reverse_copy 함수가 dst와 src를 동일한 버퍼로 처리하지 못한다면, 버퍼 내에서 직접 위치를 바꾸는(in-place) 비트 반전 함수를 구현하여 메모리 오버헤드를 줄여야 합니다.

1-3. 보통: convolve_with_wavelet 함수 내 이중 free 가능성
파일: src/cwt.c

문제점: calloc 호출이 실패했을 때 에러 처리 로직에 결함이 있습니다. 만약 signal_padded 할당은 성공하고 wavelet_padded 할당이 실패하면, signal_padded는 초기화된 포인터이고 wavelet_padded는 NULL입니다. 이때 free(signal_padded)는 괜찮지만 free(wavelet_padded)는 NULL 포인터를 해제하므로 문제는 없습니다. 하지만 코드를 더 안전하게 만들기 위해 NULL이 아닌 경우에만 free를 호출하는 것이 좋습니다. 더 큰 문제는, calloc이 실패했는데도 함수가 false를 반환하기 전에 메모리를 해제하려고 시도한다는 점입니다.

코드:

C

cplx* signal_padded = (cplx*)calloc(padded_len, sizeof(cplx));
cplx* wavelet_padded = (cplx*)calloc(padded_len, sizeof(cplx));
if (signal_padded == NULL || wavelet_padded == NULL) {
    free(signal_padded);
    free(wavelet_padded);
    return false;
}


수정 제안: 각 포인터가 NULL이 아닌지 확인하고 해제하는 것이 더 안전한 코딩 스타일입니다.

2. 구현 정확성 및 잠재적 버그 (Correctness & Bugs)
2-1. 심각: Adam 옵티마이저의 시간(t) 단계 오류
파일: src/transformer.c

문제점: Adam 옵티마이저의 adam_optimizer_step 함수는 바이어스 보정(bias correction)을 위해 시간 단계 t를 인자로 받습니다. 하지만

process_sequence_window 함수에서 이 함수를 호출할 때 항상 t=1로 고정된 값을 전달합니다.  Adam 알고리즘에서

t는 1부터 시작하여 매 스텝마다 1씩 증가해야 합니다. t가 1로 고정되면 바이어스 보정이 제대로 이루어지지 않아 학습이 불안정해지거나 최적점에 도달하지 못할 수 있습니다.

코드:

C

adam_optimizer_step(model->optimizer, model->output_projection->data,
                    d_model * num_labels, model->config->learning_rate, 0.9,
                    0.999, 1e-8, 1); // <--- t=1로 고정되어 있습니다.


수정 제안: TransformerModel 구조체에 학습 스텝 카운터(예: int training_step;)를 추가하고, process_sequence_window가 호출될 때마다 이 값을 1씩 증가시켜 adam_optimizer_step에 전달해야 합니다.

2-2. 중요: 역전파(Backpropagation) 구현 누락
파일: src/transformer.c


문제점: 현재 학습 코드는 최종 출력 레이어(output_projection)의 가중치에 대해서만 그래디언트를 계산하고 업데이트합니다.  트랜스포머의 인코더 레이어들(어텐션 가중치, 피드포워드 네트워크 가중치 등)에 대한 역전파 로직이 전혀 구현되어 있지 않습니다. 이로 인해 모델의 극히 일부만 학습이 이루어지며, 사실상 모델이 제대로 학습되지 않습니다.

수정 제안: 전체 모델 파라미터(인코더 레이어의 모든 가중치 및 편향 포함)에 대한 그래디언트를 계산하는 완전한 역전파 로직을 구현해야 합니다. 이는 매우 복잡한 작업이며, 행렬 연산에 대한 미분을 포함합니다.

2-3. 보통: fasta_parser.c의 시퀀스 이어붙이기 로직 오류
파일: src/fasta_parser.c


문제점: FASTA 파일의 시퀀스 부분을 여러 줄에 걸쳐 읽어와 하나의 문자열로 합칠 때 memcpy(cur + cur_len, line, ll + 1)을 사용합니다.

ll + 1은 line 버퍼의 \0 종결 문자를 포함하여 복사하는 것을 의도한 것으로 보입니다. 이로 인해 이전 라인의 끝에 \0 문자가 삽입되고, 다음 라인이 그 뒤에 복사됩니다. strlen은 첫 번째 \0에서 멈추므로 시퀀스가 중간에 잘리는 결과가 발생합니다.

수정 제안: memcpy 대신 strcat을 사용하거나, memcpy(cur + cur_len, line, ll)을 사용하고 cur_len을 ll만큼만 증가시켜 \0 문자가 중간에 들어가지 않도록 해야 합니다.

3. 성능 및 효율성 (Performance & Efficiency)
3-1. 중요: multihead_attention_forward의 비효율적인 데이터 분할
파일: src/transformer.c


문제점: 멀티헤드 어텐션에서 각 헤드별로 Q, K, V 행렬을 생성할 때, 전체 Q, K, V 행렬에서 데이터를 복사하여 Q_head, K_head, V_head라는 새로운 작은 행렬들을 만듭니다.  이 과정은 매 어텐션 계산마다 반복되며 상당한 메모리 할당 및 복사 오버헤드를 발생시킵니다.

수정 제안: 새로운 행렬을 만드는 대신, 포인터 연산을 통해 기존의 큰 행렬(Q, K, V)의 특정 오프셋을 직접 참조하도록 수정해야 합니다. 이를 "view" 또는 "slice" 개념으로 구현하여 불필요한 메모리 복사를 제거할 수 있습니다.

3-2. 보통: CWT 웨이블릿의 반복적인 생성
파일: src/cwt.c


문제점: compute_cwt_features 함수는 각 스케일(scale)에 대해 루프를 돌면서 매번 generate_morlet_wavelet 함수를 호출하여 웨이블릿을 생성합니다.  만약 입력 시퀀스의 길이가 같다면 동일한 스케일에 대해 항상 동일한 웨이블릿이 생성됩니다. 특히 슬라이딩 윈도우 방식에서는 대부분의 윈도우 길이가 동일하므로, 같은 웨이블릿이 수없이 반복 생성됩니다.

수정 제안: 웨이블릿을 미리 계산하여 캐싱(caching)하는 메커니즘을 도입해야 합니다. 특정 스케일과 길이에 대한 웨이블릿을 한 번만 생성하고, 필요할 때마다 재사용하여 계산 비용을 줄일 수 있습니다.

3-3. 보통: layer_norm_forward의 비효율적 계산
파일: src/transformer.c


문제점: 레이어 정규화(Layer Normalization)를 적용할 때, 각 행(row)에 대해 평균과 분산을 계산하는 루프를 돕니다.  이는 직관적이지만 데이터가 메모리에 열(column) 우선이 아닌 행(row) 우선으로 저장되어 있을 때 캐시 효율성이 떨어질 수 있습니다.

수정 제안: SIMD(Single Instruction, Multiple Data) 명령어를 활용하거나 OpenMP 같은 라이브러리를 사용하여 행별 계산을 병렬화하면 성능을 크게 향상시킬 수 있습니다.

4. 기타 문제 및 제안 (Miscellaneous)
4-1. 중요: dropout_rate 파라미터 미사용
파일: src/config.c, src/transformer.c


문제점: TransformerConfig 구조체에 dropout_rate 필드가 정의되어 있고 , TOML 파일에서도 파싱하지만, 실제 모델의


forward 로직 어디에서도 드롭아웃이 적용되지 않습니다. 드롭아웃은 과적합(overfitting)을 방지하는 중요한 규제(regularization) 기법이므로, 이것이 빠지면 모델 성능에 큰 영향을 미칠 수 있습니다.

수정 제안: 어텐션 출력 후나 피드포워드 네트워크의 활성화 함수 이후 등에 드롭아웃 레이어를 구현하고, 학습 시에만 dropout_rate에 따라 일부 뉴런을 비활성화하는 로직을 추가해야 합니다.

4-2. 보통: gff_parser의 제한적인 기능
파일: src/gff_parser.c


문제점: 현재 GFF 파서는 "CDS"라는 피처 타입만 처리하도록 하드코딩되어 있습니다.  또한, GFF 파일의 9번째 속성(attribute) 필드에서 유전자 ID나 부모-자식 관계를 파싱하지 않아 인트론(intron)을 정확하게 정의할 수 없습니다. 현재 로직은 CDS가 아닌 모든 영역을 인트론 또는 유전자 간(intergenic) 영역으로 취급하므로, UTR(untranslated region) 같은 다른 중요한 영역을 구분하지 못합니다.

수정 제안: strcmp(tokens[2], "CDS") != 0 부분을 수정하여 "exon", "gene" 등 다양한 피처 타입을 처리할 수 있도록 확장하고, 속성 필드를 파싱하여 유전자 구조를 더 정확하게 파악한 뒤 레이블을 생성해야 합니다.

이 외에도 코드 전반에 걸쳐 에러 처리 강화, 상수 값(magic number)의 매크로화 등 코드 품질을 개선할 수 있는 부분들이 존재합니다. 전반적으로 C로 직접 구현한 노력이 돋보이지만, 실제 딥러닝 모델의 정확성과 성능을 보장하기 위해서는 위에서 지적된 문제들, 특히 역전파 구현 누락과 Adam 옵티마이저 오류를 해결하는 것이 매우 중요합니다.

# 반드시 지켜야 할 사항:
Code Quality and Optimization
Minimize Redundancy (DRY): Adhere strictly to the "Don't Repeat Yourself" principle. Abstract and reuse code wherever possible to maintain a compact and modular codebase.

Scientific Accuracy: Ensure your Transformer implementation is mathematically and algorithmically correct according to the original paper.

Performance Optimization: The code must be highly optimized. The use of pthreads is a minimum requirement. Analyze and optimize matrix operations and memory access patterns.