==> ./include/cwt.h <==
#ifndef CWT_H
#define CWT_H

#include <complex.h>
#include <stdbool.h>

#include "fft.h"

/**
 * Convert DNA base to complex number on the complex plane.
 * A -> (1+1i), T -> (1-1i), G -> (-1+1i), C -> (-1-1i)
 * @param base DNA base character
 * @return Complex number representation
 */
cplx dna_to_complex(char base);

/**
 * Convert DNA sequence to numerical signal (complex array).
 * @param sequence DNA sequence string
 * @param length Length of sequence
 * @param output Output array (must be pre-allocated)
 */
void dna_to_signal(const char* sequence, int length, cplx* output);

/**
 * Generate Morlet wavelet for a given scale parameter.
 * Formula: ψ(t) = (1/√(s·π^(1/4))) * exp(-1/2 * (t/s)^2) * exp(-j*2π*t/s)
 * @param scale Scale parameter s
 * @param length Length of the wavelet (should be centered at length/2)
 * @param output Output array (must be pre-allocated)
 */
void generate_morlet_wavelet(double scale, int length, cplx* output);

/**
 * Perform convolution using FFT.
 * @param signal Input signal
 * @param signal_len Length of signal
 * @param wavelet Wavelet kernel
 * @param wavelet_len Length of wavelet
 * @param output Output array (must be pre-allocated, size signal_len)
 * @return true on success, false on error
 */
bool convolve_with_wavelet(const cplx* signal, int signal_len,
                           const cplx* wavelet, int wavelet_len,
                           double* output);

/**
 * Compute CWT features for a DNA sequence at multiple scales.
 * @param sequence DNA sequence
 * @param seq_len Length of sequence
 * @param scales Array of scale parameters
 * @param num_scales Number of scales
 * @param features Output 2D array [num_scales][seq_len] (must be pre-allocated)
 * @return true on success, false on error
 */
bool compute_cwt_features(const char* sequence, int seq_len,
                          const double* scales, int num_scales,
                          double** features);


==> ./include/fft.h <==
#ifndef FFT_H
#define FFT_H

#include <complex.h>
#include <stdbool.h>

// Type alias for convenience
typedef double complex cplx;

/**
 * Compute the Fast Fourier Transform (FFT) using Cooley-Tukey algorithm.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 * @param inverse If true, compute inverse FFT
 */
void fft(cplx* x, int N, bool inverse);

/**
 * Compute inverse FFT with proper normalization.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 */
void ifft(cplx* x, int N);

/**
 * Check if a number is a power of 2.
 * @param n Number to check
 * @return true if n is a power of 2, false otherwise
 */
bool is_power_of_2(int n);

/**
 * Find next power of 2 greater than or equal to n.
 * @param n Input number
 * @return Next power of 2
 */
int next_power_of_2(int n);


==> ./include/hmm.h <==
#ifndef HMM_H
#define HMM_H

#include <stdbool.h>

// HMM states
typedef enum {
  STATE_EXON_F0 = 0,
  STATE_EXON_F1 = 1,
  STATE_EXON_F2 = 2,
  STATE_INTRON = 3,
  STATE_INTERGENIC = 4,
  NUM_STATES = 5
} HMMState;

// Maximum number of wavelet scales (features)
#define MAX_NUM_WAVELETS 10

// Gaussian emission parameters for a single state
typedef struct {
  double mean[MAX_NUM_WAVELETS];
  double variance[MAX_NUM_WAVELETS];
  int num_features;
} GaussianEmission;

// HMM model structure
typedef struct {
  // Transition probabilities: transition[i][j] = P(state_j | state_i)
  double transition[NUM_STATES][NUM_STATES];

  // Initial state probabilities
  double initial[NUM_STATES];

  // Emission parameters for each state (multivariate Gaussian with diagonal
  // covariance)
  GaussianEmission emission[NUM_STATES];

  int num_features;

  // Global feature statistics for Z-score normalization
  double global_feature_mean[MAX_NUM_WAVELETS];
  double global_feature_stddev[MAX_NUM_WAVELETS];
} HMMModel;

/**
 * Initialize HMM with default/random parameters.
 * @param model HMM model to initialize
 * @param num_features Number of CWT features (wavelet scales)
 */
void hmm_init(HMMModel* model, int num_features);

/**
 * Compute Gaussian probability density function (PDF) for diagonal covariance.
 * @param observation Feature vector
 * @param mean Mean vector
 * @param variance Variance vector (diagonal of covariance matrix)
 * @param num_features Dimension of vectors
 * @return Log probability
 */
double gaussian_log_pdf(const double* observation, const double* mean,
                        const double* variance, int num_features);

/**
 * Train HMM using Baum-Welch algorithm.
 * @param model HMM model to train
 * @param observations Array of observation sequences (2D:
 * [num_sequences][seq_len][num_features])
 * @param seq_lengths Length of each sequence
 * @param num_sequences Number of training sequences
 * @param max_iterations Maximum number of EM iterations
 * @param convergence_threshold Convergence threshold for log-likelihood change
 * @return true on success, false on error
 */
bool hmm_train_baum_welch(HMMModel* model, double*** observations,
                          int* seq_lengths, int num_sequences,
                          int max_iterations, double convergence_threshold);

/**
 * Predict state sequence using Viterbi algorithm.
 * @param model HMM model
 * @param observations Observation sequence [seq_len][num_features]
 * @param seq_len Length of sequence
 * @param states Output state sequence (must be pre-allocated)
 * @return Log probability of most likely path
 */
double hmm_viterbi(const HMMModel* model, double** observations, int seq_len,
                   int* states);

/**
 * Save HMM model to file.
 * @param model HMM model
 * @param filename Output filename
 * @return true on success, false on error
 */
bool hmm_save_model(const HMMModel* model, const char* filename);

/**
 * Load HMM model from file.
 * @param model HMM model to load into
 * @param filename Input filename
 * @return true on success, false on error
 */
bool hmm_load_model(HMMModel* model, const char* filename);


==> ./include/sunfish.h <==
#ifndef SUNFISH_H
#define SUNFISH_H

#include <stdbool.h>

// Line and buffer sizes
enum { MAX_LINE_LEN = 50000, MAX_PEPTIDE_LEN = 100000, MAX_DNA_LEN = 1000000 };

// Amino acids
enum { NUM_AMINO_ACIDS = 20, NUM_NUCLEOTIDES = 4 };

// Splice site parameters
enum { DONOR_MOTIF_SIZE = 9, ACCEPTOR_MOTIF_SIZE = 15 };

// Data Structures
typedef struct {
  char* id;
  char* sequence;
} FastaRecord;

typedef struct {
  FastaRecord* records;
  int count;
} FastaData;

typedef struct {
  char* seqid;
  int start;
  int end;
  char strand;
  int phase;
} Exon;

typedef struct {
  char* parent_id;
  Exon* exons;
  int exon_count;
} CdsGroup;

typedef struct {
  char* sequence;
  int counts[NUM_AMINO_ACIDS];
  int exon_count;
  int cds_length_nt;
} PeptideInfo;

// PWM Structures
typedef struct {
  double donor_pwm[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  double acceptor_pwm[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  double min_donor_score;
  double min_acceptor_score;
} SplicePWM;

typedef struct {
  int donor_counts[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  int acceptor_counts[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  int total_donor_sites;
  int total_acceptor_sites;
} SpliceCounts;

void free_fasta_data(FastaData* data);
FastaData* parse_fasta(const char* path);
void free_cds_groups(CdsGroup* groups, int count);
CdsGroup* parse_gff_for_cds(const char* path, int* group_count);
char* reverse_complement(const char* sequence);


==> ./include/thread_pool.h <==
#ifndef THREAD_POOL_H
#define THREAD_POOL_H

#include <pthread.h>
#include <stdbool.h>

// Task function signature
typedef void (*task_func_t)(void* arg);

// Task structure
typedef struct task_t {
  task_func_t function;
  void* argument;
  struct task_t* next;
} task_t;

// Thread pool structure
typedef struct {
  pthread_t* threads;
  int thread_count;
  
  task_t* task_queue_head;
  task_t* task_queue_tail;
  
  pthread_mutex_t queue_mutex;
  pthread_cond_t queue_cond;
  pthread_cond_t done_cond;
  
  int active_tasks;
  bool shutdown;
} thread_pool_t;

/**
 * Create a thread pool with specified number of worker threads.
 * @param num_threads Number of worker threads to create
 * @return Pointer to thread pool, or NULL on error
 */
thread_pool_t* thread_pool_create(int num_threads);

/**
 * Add a task to the thread pool's queue.
 * @param pool Thread pool
 * @param function Function to execute
 * @param arg Argument to pass to function
 * @return true on success, false on error
 */
bool thread_pool_add_task(thread_pool_t* pool, task_func_t function, void* arg);

/**
 * Wait for all tasks to complete.
 * @param pool Thread pool
 */
void thread_pool_wait(thread_pool_t* pool);

/**
 * Destroy the thread pool and free all resources.
 * @param pool Thread pool to destroy
 */
void thread_pool_destroy(thread_pool_t* pool);


==> ./src/cwt.c <==
#include <complex.h>
#include <ctype.h>
#include <math.h>
#include <stdbool.h>
#include <stdlib.h>
#include <string.h>

#include "../include/cwt.h"
#include "../include/fft.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

cplx dna_to_complex(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 1.0 + 1.0 * I;
  case 'T':
    return 1.0 + 1.0 * I;
  case 'G':
    return -1.0 + 1.0 * I;
  case 'C':
    return -1.0 - 1.0 * I;
  default:
    // For unknown bases, return zero
    return 0.0 + 0.0 * I;
  }
}

void dna_to_signal(const char* sequence, int length, cplx* output) {
  for (int i = 0; i < length; i++) {
    output[i] = dna_to_complex(sequence[i]);
  }
}

void generate_morlet_wavelet(double scale, int length, cplx* output) {
  // Morlet wavelet: ψ(t) = (1/√(s·π^(1/4))) * exp(-1/2 * (t/s)^2) *
  // exp(-j*2π*t/s)
  double norm_factor = 1.0 / sqrt(scale * pow(M_PI, 0.25));
  int center = length / 2;

  for (int i = 0; i < length; i++) {
    double t = (double)(i - center);
    double t_scaled = t / scale;
    double gaussian = exp(-0.5 * t_scaled * t_scaled);
    double phase = -2.0 * M_PI * t / scale;
    cplx oscillation = cexp(I * phase);
    output[i] = norm_factor * gaussian * oscillation;
  }
}

bool convolve_with_wavelet(const cplx* signal, int signal_len,
                           const cplx* wavelet, int wavelet_len,
                           double* output) {
  // Find common padded length (power of 2)
  int max_len = signal_len + wavelet_len - 1;
  int padded_len = next_power_of_2(max_len);

  // Allocate padded arrays
  cplx* signal_padded = (cplx*)calloc(padded_len, sizeof(cplx));
  cplx* wavelet_padded = (cplx*)calloc(padded_len, sizeof(cplx));

  if (signal_padded == NULL || wavelet_padded == NULL) {
    free(signal_padded);
    free(wavelet_padded);
    return false;
  }

  // Copy data to padded arrays
  memcpy(signal_padded, signal, signal_len * sizeof(cplx));
  memcpy(wavelet_padded, wavelet, wavelet_len * sizeof(cplx));

  // Compute FFT of both
  fft(signal_padded, padded_len, false);
  fft(wavelet_padded, padded_len, false);

  // Element-wise multiplication in frequency domain
  for (int i = 0; i < padded_len; i++) {
    signal_padded[i] = signal_padded[i] * wavelet_padded[i];
  }

  // Inverse FFT
  ifft(signal_padded, padded_len);

  // Extract magnitude (raw, un-normalized)
  // The valid convolution result is in the first signal_len elements
  for (int i = 0; i < signal_len; i++) {
    output[i] = cabs(signal_padded[i]);
  }

  free(signal_padded);
  free(wavelet_padded);

  return true;
}

bool compute_cwt_features(const char* sequence, int seq_len,
                          const double* scales, int num_scales,
                          double** features) {
  // Convert DNA to complex signal
  cplx* signal = (cplx*)malloc(seq_len * sizeof(cplx));
  if (signal == NULL) {
    return false;
  }
  dna_to_signal(sequence, seq_len, signal);

  // For each scale, generate wavelet and convolve
  for (int s = 0; s < num_scales; s++) {
    // Wavelet length should be proportional to scale
    int wavelet_len = (int)(10.0 * scales[s]);
    if (wavelet_len < 10)
      wavelet_len = 10;
    if (wavelet_len > seq_len)
      wavelet_len = seq_len;

    cplx* wavelet = (cplx*)malloc(wavelet_len * sizeof(cplx));
    if (wavelet == NULL) {
      free(signal);
      return false;
    }

    generate_morlet_wavelet(scales[s], wavelet_len, wavelet);

    if (!convolve_with_wavelet(signal, seq_len, wavelet, wavelet_len,
                               features[s])) {
      free(wavelet);
      free(signal);
      return false;
    }

    free(wavelet);
  }

  free(signal);
  return true;

==> ./src/fft.c <==
#include <complex.h>
#include <math.h>
#include <stdbool.h>
#include <stdlib.h>
#include <string.h>

#include "../include/fft.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

bool is_power_of_2(int n) {
  return n > 0 && (n & (n - 1)) == 0;
}

int next_power_of_2(int n) {
  if (n <= 0)
    return 1;
  n--;
  n |= n >> 1;
  n |= n >> 2;
  n |= n >> 4;
  n |= n >> 8;
  n |= n >> 16;
  n++;
  return n;
}

/**
 * Bit-reversal permutation for FFT.
 * @param x Array to permute
 * @param N Length of array (must be power of 2)
 */
static void bit_reverse_copy(cplx* x, int N) {
  int j = 0;
  for (int i = 0; i < N; i++) {
    if (i < j) {
      cplx temp = x[i];
      x[i] = x[j];
      x[j] = temp;
    }
    int m = N / 2;
    while (m >= 1 && j >= m) {
      j -= m;
      m /= 2;
    }
    j += m;
  }
}

/**
 * Cooley-Tukey FFT implementation (iterative, in-place).
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 * @param inverse If true, compute inverse FFT (without normalization)
 */
void fft(cplx* x, int N, bool inverse) {
  if (!is_power_of_2(N)) {
    // For simplicity, we require N to be a power of 2
    return;
  }

  // Bit-reversal permutation
  bit_reverse_copy(x, N);

  // FFT computation
  double direction = inverse ? 1.0 : -1.0;
  
  for (int s = 1; s <= (int)(log2(N)); s++) {
    int m = 1 << s; // 2^s
    double theta = direction * 2.0 * M_PI / m;
    cplx wm = cexp(I * theta);
    
    for (int k = 0; k < N; k += m) {
      cplx w = 1.0;
      for (int j = 0; j < m / 2; j++) {
        cplx t = w * x[k + j + m / 2];
        cplx u = x[k + j];
        x[k + j] = u + t;
        x[k + j + m / 2] = u - t;
        w = w * wm;
      }
    }
  }

  // Normalization for inverse FFT
  if (inverse) {
    for (int i = 0; i < N; i++) {
      x[i] /= N;
    }
  }
}

/**
 * Compute inverse FFT with proper normalization.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 */
void ifft(cplx* x, int N) {
  fft(x, N, true);

==> ./src/hmm.c <==
#include <math.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/hmm.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

void hmm_init(HMMModel* model, int num_features) {
  if (num_features > MAX_NUM_WAVELETS) {
    num_features = MAX_NUM_WAVELETS;
  }

  model->num_features = num_features;

  // Initialize uniform transition probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    double sum = 0.0;
    for (int j = 0; j < NUM_STATES; j++) {
      model->transition[i][j] = 1.0 / NUM_STATES;
      sum += model->transition[i][j];
    }
    // Normalize
    for (int j = 0; j < NUM_STATES; j++) {
      model->transition[i][j] /= sum;
    }
  }

  // Initialize uniform initial probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    model->initial[i] = 1.0 / NUM_STATES;
  }

  // Initialize emission parameters with random values
  for (int i = 0; i < NUM_STATES; i++) {
    model->emission[i].num_features = num_features;
    for (int j = 0; j < num_features; j++) {
      // Random mean between 0 and 1
      model->emission[i].mean[j] = (double)rand() / RAND_MAX;
      // Small variance
      model->emission[i].variance[j] = 0.1;
    }
  }
}

double gaussian_log_pdf(const double* observation, const double* mean,
                        const double* variance, int num_features) {
  double log_prob = 0.0;

  // For diagonal covariance, we can compute the PDF as product of univariate
  // Gaussians
  for (int i = 0; i < num_features; i++) {
    double diff = observation[i] - mean[i];
    double var = variance[i];

    // Prevent numerical issues with very small variance
    if (var < 1e-6) {
      var = 1e-6;
    }

    // Log of univariate Gaussian PDF
    log_prob += -0.5 * log(2.0 * M_PI * var) - 0.5 * (diff * diff) / var;
  }

  return log_prob;
}

// Forward algorithm for Baum-Welch
static double forward_algorithm(const HMMModel* model, double** observations,
                                int seq_len, double** alpha) {
  // alpha[t][i] = P(O_1, O_2, ..., O_t, S_t = i | model)

  // Initialization (t=0)
  for (int i = 0; i < NUM_STATES; i++) {
    alpha[0][i] =
        log(model->initial[i]) +
        gaussian_log_pdf(observations[0], model->emission[i].mean,
                         model->emission[i].variance, model->num_features);
  }

  // Induction (t=1 to T-1)
  for (int t = 1; t < seq_len; t++) {
    for (int j = 0; j < NUM_STATES; j++) {
      double max_val = -INFINITY;
      double sum = 0.0;

      // Log-sum-exp trick for numerical stability
      for (int i = 0; i < NUM_STATES; i++) {
        double val = alpha[t - 1][i] + log(model->transition[i][j]);
        if (val > max_val) {
          max_val = val;
        }
      }

      for (int i = 0; i < NUM_STATES; i++) {
        double val = alpha[t - 1][i] + log(model->transition[i][j]);
        sum += exp(val - max_val);
      }

      alpha[t][j] =
          max_val + log(sum) +
          gaussian_log_pdf(observations[t], model->emission[j].mean,
                           model->emission[j].variance, model->num_features);
    }
  }

  // Termination - compute total log probability
  double max_val = -INFINITY;
  for (int i = 0; i < NUM_STATES; i++) {
    if (alpha[seq_len - 1][i] > max_val) {
      max_val = alpha[seq_len - 1][i];
    }
  }

  double sum = 0.0;
  for (int i = 0; i < NUM_STATES; i++) {
    sum += exp(alpha[seq_len - 1][i] - max_val);
  }

  return max_val + log(sum);
}

// Backward algorithm for Baum-Welch
static void backward_algorithm(const HMMModel* model, double** observations,
                               int seq_len, double** beta) {
  // beta[t][i] = P(O_{t+1}, O_{t+2}, ..., O_T | S_t = i, model)

  // Initialization (t=T-1)
  for (int i = 0; i < NUM_STATES; i++) {
    beta[seq_len - 1][i] = 0.0; // log(1) = 0
  }

  // Induction (t=T-2 down to 0)
  for (int t = seq_len - 2; t >= 0; t--) {
    for (int i = 0; i < NUM_STATES; i++) {
      double max_val = -INFINITY;
      double sum = 0.0;

      // Log-sum-exp trick
      for (int j = 0; j < NUM_STATES; j++) {
        double val =
            log(model->transition[i][j]) + beta[t + 1][j] +
            gaussian_log_pdf(observations[t + 1], model->emission[j].mean,
                             model->emission[j].variance, model->num_features);
        if (val > max_val) {
          max_val = val;
        }
      }

      for (int j = 0; j < NUM_STATES; j++) {
        double val =
            log(model->transition[i][j]) + beta[t + 1][j] +
            gaussian_log_pdf(observations[t + 1], model->emission[j].mean,
                             model->emission[j].variance, model->num_features);
        sum += exp(val - max_val);
      }

      beta[t][i] = max_val + log(sum);
    }
  }
}

bool hmm_train_baum_welch(HMMModel* model, double*** observations,
                          int* seq_lengths, int num_sequences,
                          int max_iterations, double convergence_threshold) {
  double prev_log_likelihood = -INFINITY;

  for (int iter = 0; iter < max_iterations; iter++) {
    double total_log_likelihood = 0.0;

    // Accumulators for M-step
    double initial_acc[NUM_STATES] = {0};
    double transition_acc[NUM_STATES][NUM_STATES] = {{0}};
    double emission_mean_acc[NUM_STATES][MAX_NUM_WAVELETS] = {{0}};
    double emission_var_acc[NUM_STATES][MAX_NUM_WAVELETS] = {{0}};
    double state_count[NUM_STATES] = {0};

    // E-step: compute forward-backward for all sequences
    for (int seq = 0; seq < num_sequences; seq++) {
      int T = seq_lengths[seq];

      // Allocate alpha and beta matrices
      double** alpha = (double**)malloc(T * sizeof(double*));
      double** beta = (double**)malloc(T * sizeof(double*));
      for (int t = 0; t < T; t++) {
        alpha[t] = (double*)malloc(NUM_STATES * sizeof(double));
        beta[t] = (double*)malloc(NUM_STATES * sizeof(double));
      }

      // Run forward-backward
      double log_prob = forward_algorithm(model, observations[seq], T, alpha);
      backward_algorithm(model, observations[seq], T, beta);
      total_log_likelihood += log_prob;

      // Compute gamma and xi
      for (int t = 0; t < T; t++) {
        // gamma[t][i] = P(S_t = i | O, model)
        double gamma_norm = -INFINITY;
        double gamma[NUM_STATES];

        for (int i = 0; i < NUM_STATES; i++) {
          gamma[i] = alpha[t][i] + beta[t][i];
          if (gamma[i] > gamma_norm) {
            gamma_norm = gamma[i];
          }
        }

        double gamma_sum = 0.0;
        for (int i = 0; i < NUM_STATES; i++) {
          gamma[i] = exp(gamma[i] - gamma_norm);
          gamma_sum += gamma[i];
        }

        for (int i = 0; i < NUM_STATES; i++) {
          gamma[i] /= gamma_sum;

          if (t == 0) {
            initial_acc[i] += gamma[i];
          }

          state_count[i] += gamma[i];

          // Accumulate for emission parameters
          for (int f = 0; f < model->num_features; f++) {
            emission_mean_acc[i][f] += gamma[i] * observations[seq][t][f];
            emission_var_acc[i][f] +=
                gamma[i] * observations[seq][t][f] * observations[seq][t][f];
          }
        }

        // Compute xi for transition probabilities (if not last time step)
        if (t < T - 1) {
          double xi[NUM_STATES][NUM_STATES];
          double xi_norm = -INFINITY;

          for (int i = 0; i < NUM_STATES; i++) {
            for (int j = 0; j < NUM_STATES; j++) {
              xi[i][j] = alpha[t][i] + log(model->transition[i][j]) +
                         gaussian_log_pdf(
                             observations[seq][t + 1], model->emission[j].mean,
                             model->emission[j].variance, model->num_features) +
                         beta[t + 1][j];
              if (xi[i][j] > xi_norm) {
                xi_norm = xi[i][j];
              }
            }
          }

          double xi_sum = 0.0;
          for (int i = 0; i < NUM_STATES; i++) {
            for (int j = 0; j < NUM_STATES; j++) {
              xi[i][j] = exp(xi[i][j] - xi_norm);
              xi_sum += xi[i][j];
            }
          }

          for (int i = 0; i < NUM_STATES; i++) {
            for (int j = 0; j < NUM_STATES; j++) {
              transition_acc[i][j] += xi[i][j] / xi_sum;
            }
          }
        }
      }

      // Free alpha and beta
      for (int t = 0; t < T; t++) {
        free(alpha[t]);
        free(beta[t]);
      }
      free(alpha);
      free(beta);
    }

    // M-step: update parameters
    // Update initial probabilities
    double initial_sum = 0.0;
    for (int i = 0; i < NUM_STATES; i++) {
      initial_sum += initial_acc[i];
    }
    for (int i = 0; i < NUM_STATES; i++) {
      model->initial[i] = initial_acc[i] / initial_sum;
      if (model->initial[i] < 1e-10)
        model->initial[i] = 1e-10;
    }

    // Update transition probabilities
    for (int i = 0; i < NUM_STATES; i++) {
      double trans_sum = 0.0;
      for (int j = 0; j < NUM_STATES; j++) {
        trans_sum += transition_acc[i][j];
      }
      for (int j = 0; j < NUM_STATES; j++) {
        if (trans_sum > 0) {
          model->transition[i][j] = transition_acc[i][j] / trans_sum;
        } else {
          model->transition[i][j] = 1.0 / NUM_STATES;
        }
        if (model->transition[i][j] < 1e-10)
          model->transition[i][j] = 1e-10;
      }
    }

    // Update emission parameters
    for (int i = 0; i < NUM_STATES; i++) {
      if (state_count[i] > 0) {
        for (int f = 0; f < model->num_features; f++) {
          double mean = emission_mean_acc[i][f] / state_count[i];
          double mean_sq = emission_var_acc[i][f] / state_count[i];
          double var = mean_sq - mean * mean;

          model->emission[i].mean[f] = mean;
          model->emission[i].variance[f] = var > 1e-6 ? var : 1e-6;
        }
      }
    }

    // Check convergence
    fprintf(stderr, "Iteration %d: Log-likelihood = %.4f\n", iter + 1,
            total_log_likelihood);

    if (iter > 0 && fabs(total_log_likelihood - prev_log_likelihood) <
                        convergence_threshold) {
      fprintf(stderr, "Converged after %d iterations\n", iter + 1);
      break;
    }

    prev_log_likelihood = total_log_likelihood;
  }

  return true;
}

double hmm_viterbi(const HMMModel* model, double** observations, int seq_len,
                   int* states) {
  // Allocate Viterbi matrices
  double** delta = (double**)malloc(seq_len * sizeof(double*));
  int** psi = (int**)malloc(seq_len * sizeof(int*));

  for (int t = 0; t < seq_len; t++) {
    delta[t] = (double*)malloc(NUM_STATES * sizeof(double));
    psi[t] = (int*)malloc(NUM_STATES * sizeof(int));
  }

  // Initialization (t=0)
  for (int i = 0; i < NUM_STATES; i++) {
    delta[0][i] =
        log(model->initial[i]) +
        gaussian_log_pdf(observations[0], model->emission[i].mean,
                         model->emission[i].variance, model->num_features);
    psi[0][i] = 0;
  }

  // Recursion (t=1 to T-1)
  for (int t = 1; t < seq_len; t++) {
    for (int j = 0; j < NUM_STATES; j++) {
      double max_val = -INFINITY;
      int max_state = 0;

      for (int i = 0; i < NUM_STATES; i++) {
        double val = delta[t - 1][i] + log(model->transition[i][j]);
        if (val > max_val) {
          max_val = val;
          max_state = i;
        }
      }

      delta[t][j] =
          max_val + gaussian_log_pdf(observations[t], model->emission[j].mean,
                                     model->emission[j].variance,
                                     model->num_features);
      psi[t][j] = max_state;
    }
  }

  // Termination - find best final state
  double max_prob = -INFINITY;
  int best_state = 0;
  for (int i = 0; i < NUM_STATES; i++) {
    if (delta[seq_len - 1][i] > max_prob) {
      max_prob = delta[seq_len - 1][i];
      best_state = i;
    }
  }

  // Backtrack
  states[seq_len - 1] = best_state;
  for (int t = seq_len - 2; t >= 0; t--) {
    states[t] = psi[t + 1][states[t + 1]];
  }

  // Free matrices
  for (int t = 0; t < seq_len; t++) {
    free(delta[t]);
    free(psi[t]);
  }
  free(delta);
  free(psi);

  return max_prob;
}

bool hmm_save_model(const HMMModel* model, const char* filename) {
  FILE* fp = fopen(filename, "w");
  if (fp == NULL) {
    return false;
  }

  fprintf(fp, "#HMM_MODEL_V1\n");
  fprintf(fp, "#num_features %d\n", model->num_features);
  fprintf(fp, "#num_states %d\n", NUM_STATES);

  // Save initial probabilities
  fprintf(fp, "INITIAL\n");
  for (int i = 0; i < NUM_STATES; i++) {
    fprintf(fp, "%.10f ", model->initial[i]);
  }
  fprintf(fp, "\n");

  // Save transition matrix
  fprintf(fp, "TRANSITION\n");
  for (int i = 0; i < NUM_STATES; i++) {
    for (int j = 0; j < NUM_STATES; j++) {
      fprintf(fp, "%.10f ", model->transition[i][j]);
    }
    fprintf(fp, "\n");
  }

  // Save emission parameters
  fprintf(fp, "EMISSION\n");
  for (int i = 0; i < NUM_STATES; i++) {
    fprintf(fp, "STATE %d\n", i);
    fprintf(fp, "MEAN ");
    for (int j = 0; j < model->num_features; j++) {
      fprintf(fp, "%.10f ", model->emission[i].mean[j]);
    }
    fprintf(fp, "\n");
    fprintf(fp, "VARIANCE ");
    for (int j = 0; j < model->num_features; j++) {
      fprintf(fp, "%.10f ", model->emission[i].variance[j]);
    }
    fprintf(fp, "\n");
  }

  // Save global feature statistics for Z-score normalization
  fprintf(fp, "GLOBAL_STATS\n");
  fprintf(fp, "MEAN ");
  for (int i = 0; i < model->num_features; i++) {
    fprintf(fp, "%.10f ", model->global_feature_mean[i]);
  }
  fprintf(fp, "\n");
  fprintf(fp, "STDDEV ");
  for (int i = 0; i < model->num_features; i++) {
    fprintf(fp, "%.10f ", model->global_feature_stddev[i]);
  }
  fprintf(fp, "\n");

  fclose(fp);
  return true;
}

bool hmm_load_model(HMMModel* model, const char* filename) {
  FILE* fp = fopen(filename, "r");
  if (fp == NULL) {
    return false;
  }

  char line[1024];

  // Read header
  if (fgets(line, sizeof(line), fp) == NULL) {
    fclose(fp);
    return false;
  }

  // Read num_features
  if (fgets(line, sizeof(line), fp) != NULL) {
    sscanf(line, "#num_features %d", &model->num_features);
  }

  // Skip num_states line
  if (fgets(line, sizeof(line), fp) == NULL) {
    fclose(fp);
    return false;
  }

  // Read initial probabilities
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "INITIAL", 7) == 0) {
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = line;
      for (int i = 0; i < NUM_STATES; i++) {
        if (sscanf(ptr, "%lf", &model->initial[i]) != 1)
          break;
        ptr = strchr(ptr, ' ');
        if (ptr)
          ptr++;
        else
          break;
      }
    } else {
      fclose(fp);
      return false;
    }
  }

  // Read transition matrix
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "TRANSITION", 10) == 0) {
    for (int i = 0; i < NUM_STATES; i++) {
      if (fgets(line, sizeof(line), fp) != NULL) {
        char* ptr = line;
        for (int j = 0; j < NUM_STATES; j++) {
          if (sscanf(ptr, "%lf", &model->transition[i][j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      } else {
        fclose(fp);
        return false;
      }
    }
  }

  // Read emission parameters
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "EMISSION", 8) == 0) {
    for (int i = 0; i < NUM_STATES; i++) {
      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }

      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }
      // MEAN
      char* ptr = strstr(line, "MEAN");
      if (ptr) {
        ptr += 5;
        for (int j = 0; j < model->num_features; j++) {
          if (sscanf(ptr, "%lf", &model->emission[i].mean[j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }

      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }
      // VARIANCE
      ptr = strstr(line, "VARIANCE");
      if (ptr) {
        ptr += 9;
        for (int j = 0; j < model->num_features; j++) {
          if (sscanf(ptr, "%lf", &model->emission[i].variance[j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }

      model->emission[i].num_features = model->num_features;
    }
  }

  // Read global feature statistics (optional for backward compatibility)
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "GLOBAL_STATS", 12) == 0) {
    // Read MEAN line
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = strstr(line, "MEAN");
      if (ptr) {
        ptr += 5;
        for (int i = 0; i < model->num_features; i++) {
          if (sscanf(ptr, "%lf", &model->global_feature_mean[i]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }
    }

    // Read STDDEV line
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = strstr(line, "STDDEV");
      if (ptr) {
        ptr += 7;
        for (int i = 0; i < model->num_features; i++) {
          if (sscanf(ptr, "%lf", &model->global_feature_stddev[i]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }
    }
  } else {
    // Initialize to default values if not present (backward compatibility)
    for (int i = 0; i < model->num_features; i++) {
      model->global_feature_mean[i] = 0.0;
      model->global_feature_stddev[i] = 1.0;
    }
  }

  fclose(fp);
  return true;

==> ./src/sunfish.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <errno.h>
#include <limits.h>
#include <math.h>
#include <pthread.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>

#include "../include/cwt.h"
#include "../include/fft.h"
#include "../include/hmm.h"
#include "../include/sunfish.h"
#include "../include/thread_pool.h"

// Global configuration
static int g_num_wavelet_scales = 5;
static double g_wavelet_scales[MAX_NUM_WAVELETS] = {3.0, 9.0, 81.0, 243.0,
                                                    6561.0};
// Default: 0 means "not set"; we'll use number of online processors at runtime
static int g_num_threads = 0;

// Thread-safe output queue
typedef struct output_node_t {
  char* gff_line;
  struct output_node_t* next;
} output_node_t;

typedef struct {
  output_node_t* head;
  output_node_t* tail;
  pthread_mutex_t mutex;
} output_queue_t;

static output_queue_t g_output_queue;
static pthread_mutex_t g_gene_counter_mutex = PTHREAD_MUTEX_INITIALIZER;
static int g_gene_counter = 0;

static int parse_threads_value(const char* arg) {
  if (arg == NULL)
    return -1;

  char* endptr = NULL;
  errno = 0;
  long value = strtol(arg, &endptr, 10);

  if (errno != 0 || endptr == arg || *endptr != '\0')
    return -1;

  if (value < 1 || value > INT_MAX)
    return -1;

  return (int)value;
}

static int detect_hardware_threads(void) {
  long nprocs = sysconf(_SC_NPROCESSORS_ONLN);
  if (nprocs < 1)
    nprocs = 1;
  if (nprocs > INT_MAX)
    nprocs = INT_MAX;
  return (int)nprocs;
}

static void ensure_thread_count(const char* mode, bool threads_specified) {
  bool auto_detected = false;
  if (g_num_threads <= 0) {
    g_num_threads = detect_hardware_threads();
    auto_detected = true;
  }

  const char* source = auto_detected
                           ? "auto-detected"
                           : (threads_specified ? "user-specified" : "default");

  fprintf(stderr, "Using %d threads for %s (%s)\n", g_num_threads, mode,
          source);
}

static const char* get_field_ptr(const char* line, int field_index) {
  if (!line || field_index <= 0)
    return NULL;

  const char* ptr = line;
  int current = 1;

  while (current < field_index && ptr) {
    const char* next_tab = strchr(ptr, '\t');
    if (!next_tab)
      return NULL;
    ptr = next_tab + 1;
    current++;
  }

  return ptr;
}

static long extract_start_coordinate(const char* line) {
  const char* start_ptr = get_field_ptr(line, 4);
  if (!start_ptr)
    return LONG_MAX;

  return strtol(start_ptr, NULL, 10);
}

static int feature_rank(const char* feature) {
  if (!feature)
    return 100;

  if (strncmp(feature, "gene", 4) == 0)
    return 0;
  if (strncmp(feature, "mRNA", 4) == 0)
    return 1;
  if (strncmp(feature, "CDS", 3) == 0)
    return 2;

  return 10;
}

static int compare_gff_lines(const void* a, const void* b) {
  const char* line_a = *(const char* const*)a;
  const char* line_b = *(const char* const*)b;

  const char* seq_a = line_a;
  const char* seq_b = line_b;

  size_t len_a = 0;
  while (seq_a[len_a] != '\t' && seq_a[len_a] != '\0')
    len_a++;

  size_t len_b = 0;
  while (seq_b[len_b] != '\t' && seq_b[len_b] != '\0')
    len_b++;

  size_t min_len = (len_a < len_b) ? len_a : len_b;
  int cmp = strncmp(seq_a, seq_b, min_len);
  if (cmp == 0) {
    if (len_a != len_b)
      cmp = (len_a < len_b) ? -1 : 1;
  }

  if (cmp != 0)
    return cmp;

  long start_a = extract_start_coordinate(line_a);
  long start_b = extract_start_coordinate(line_b);

  if (start_a < start_b)
    return -1;
  if (start_a > start_b)
    return 1;

  const char* feature_a = get_field_ptr(line_a, 3);
  const char* feature_b = get_field_ptr(line_b, 3);

  int rank_a = feature_rank(feature_a);
  int rank_b = feature_rank(feature_b);
  if (rank_a != rank_b)
    return (rank_a < rank_b) ? -1 : 1;

  return strcmp(line_a, line_b);
}

// Initialize output queue
static void output_queue_init(output_queue_t* queue) {
  queue->head = NULL;
  queue->tail = NULL;
  pthread_mutex_init(&queue->mutex, NULL);
}

// Add output to queue (thread-safe)
static void output_queue_add(output_queue_t* queue, const char* gff_line) {
  output_node_t* node = (output_node_t*)malloc(sizeof(output_node_t));
  if (node == NULL)
    return;

  node->gff_line = strdup(gff_line);
  node->next = NULL;

  pthread_mutex_lock(&queue->mutex);
  if (queue->tail == NULL) {
    queue->head = node;
    queue->tail = node;
  } else {
    queue->tail->next = node;
    queue->tail = node;
  }
  pthread_mutex_unlock(&queue->mutex);
}

// Flush output queue to stdout (not thread-safe, call from main thread)
static void output_queue_flush(output_queue_t* queue) {
  pthread_mutex_lock(&queue->mutex);
  output_node_t* node = queue->head;
  int count = 0;
  while (node != NULL) {
    count++;
    node = node->next;
  }

  char** lines = NULL;
  if (count > 0) {
    lines = (char**)malloc(count * sizeof(char*));
  }

  int idx = 0;
  node = queue->head;
  queue->head = NULL;
  queue->tail = NULL;
  pthread_mutex_unlock(&queue->mutex);

  while (node != NULL) {
    if (lines)
      lines[idx++] = node->gff_line;
    output_node_t* next = node->next;
    free(node);
    node = next;
  }

  if (lines) {
    qsort(lines, count, sizeof(char*), compare_gff_lines);

    for (int i = 0; i < count; i++) {
      printf("%s", lines[i]);
      free(lines[i]);
    }

    free(lines);
  }
}

// Destroy output queue
static void output_queue_destroy(output_queue_t* queue) {
  output_queue_flush(queue);
  pthread_mutex_destroy(&queue->mutex);
}

// Parse command-line wavelet scales argument
static int parse_wavelet_scales(const char* arg, double* scales,
                                int max_scales) {
  int count = 0;
  char* arg_copy = strdup(arg);
  char* token = strtok(arg_copy, ",");

  while (token != NULL && count < max_scales) {
    scales[count++] = atof(token);
    token = strtok(NULL, ",");
  }

  free(arg_copy);
  return count;
}

static void free_observation_sequence(double** observations, int seq_len) {
  if (!observations)
    return;

  for (int t = 0; t < seq_len; t++) {
    free(observations[t]);
  }
  free(observations);
}

static bool build_observation_matrix(const char* sequence, int seq_len,
                                     double*** out_observations) {
  if (seq_len <= 0)
    return false;

  double** features = (double**)malloc(g_num_wavelet_scales * sizeof(double*));
  if (!features)
    return false;

  for (int s = 0; s < g_num_wavelet_scales; s++) {
    features[s] = (double*)malloc(seq_len * sizeof(double));
    if (!features[s]) {
      for (int j = 0; j < s; j++) {
        free(features[j]);
      }
      free(features);
      return false;
    }
  }

  if (!compute_cwt_features(sequence, seq_len, g_wavelet_scales,
                            g_num_wavelet_scales, features)) {
    for (int s = 0; s < g_num_wavelet_scales; s++) {
      free(features[s]);
    }
    free(features);
    return false;
  }

  double** observations = (double**)malloc(seq_len * sizeof(double*));
  if (!observations) {
    for (int s = 0; s < g_num_wavelet_scales; s++) {
      free(features[s]);
    }
    free(features);
    return false;
  }

  for (int t = 0; t < seq_len; t++) {
    observations[t] = (double*)malloc(g_num_wavelet_scales * sizeof(double));
    if (!observations[t]) {
      for (int u = 0; u < t; u++) {
        free(observations[u]);
      }
      free(observations);
      for (int s = 0; s < g_num_wavelet_scales; s++) {
        free(features[s]);
      }
      free(features);
      return false;
    }

    for (int f = 0; f < g_num_wavelet_scales; f++) {
      observations[t][f] = features[f][t];
    }
  }

  for (int s = 0; s < g_num_wavelet_scales; s++) {
    free(features[s]);
  }
  free(features);

  *out_observations = observations;
  return true;
}

// Task structure for parallel processing
typedef struct {
  const char* sequence;
  const char* seq_id;
  int seq_len;
  int array_index;
  char strand;
  double*** observations_array;
  int* seq_lengths_array;
  pthread_mutex_t* error_mutex;
  bool* error_flag;
  char* error_message;
  size_t error_message_size;
  int sequence_number;
} training_task_t;

static void training_observation_worker(void* arg) {
  training_task_t* task = (training_task_t*)arg;
  if (task == NULL)
    return;

  const char* sequence = task->sequence;
  char* rc = NULL;
  double** result = NULL;
  bool success = false;

  if (task->strand == '-') {
    rc = reverse_complement(sequence);
    if (!rc)
      goto cleanup;
    sequence = rc;
  }

  if (!build_observation_matrix(sequence, task->seq_len, &result))
    goto cleanup;

  task->observations_array[task->array_index] = result;
  task->seq_lengths_array[task->array_index] = task->seq_len;
  success = true;

cleanup:
  if (!success) {
    if (result)
      free_observation_sequence(result, task->seq_len);

    pthread_mutex_lock(task->error_mutex);
    if (!*(task->error_flag)) {
      *(task->error_flag) = true;
      snprintf(task->error_message, task->error_message_size,
               "Failed to compute CWT features for sequence %s (%c strand, "
               "index %d)",
               task->seq_id ? task->seq_id : "(unknown)", task->strand,
               task->sequence_number);
    }
    pthread_mutex_unlock(task->error_mutex);
  }

  if (rc)
    free(rc);
  if (!success && task->observations_array[task->array_index] == NULL)
    task->seq_lengths_array[task->array_index] = 0;

  free(task);
}

typedef struct {
  char* sequence;
  char* seq_id;
  char strand;
  HMMModel* model;
  int original_length;
} prediction_task_t;

// Worker function for parallel prediction
static void predict_sequence_worker(void* arg) {
  prediction_task_t* task = (prediction_task_t*)arg;

  int seq_len = strlen(task->sequence);

  double** observations = NULL;
  int* states = NULL;

  if (!build_observation_matrix(task->sequence, seq_len, &observations)) {
    fprintf(stderr,
            "Warning: Failed to compute CWT features for %s (%c strand)\n",
            task->seq_id, task->strand);
    goto cleanup;
  }

  // Apply Z-score normalization using global statistics from the model
  for (int t = 0; t < seq_len; t++) {
    for (int f = 0; f < task->model->num_features; f++) {
      double raw_val = observations[t][f];
      double normalized_val = (raw_val - task->model->global_feature_mean[f]) / 
                              task->model->global_feature_stddev[f];
      observations[t][f] = normalized_val;
    }
  }

  states = (int*)malloc(seq_len * sizeof(int));
  if (!states) {
    fprintf(stderr,
            "Warning: Failed to allocate state buffer for %s (%c strand)\n",
            task->seq_id, task->strand);
    goto cleanup;
  }

  double log_prob = hmm_viterbi(task->model, observations, seq_len, states);
  double normalized_score = (seq_len > 0) ? (log_prob / seq_len) : log_prob;
  const int original_length =
      (task->original_length > 0) ? task->original_length : seq_len;

  // Process state sequence to identify genes
  // Find contiguous exon regions and output as GFF3
  int in_gene = 0;
  int gene_start = -1;
  int gene_id;

  for (int i = 0; i < seq_len; i++) {
    int is_exon = (states[i] == STATE_EXON_F0 || states[i] == STATE_EXON_F1 ||
                   states[i] == STATE_EXON_F2);

    if (is_exon && !in_gene) {
      // Start of a new gene
      in_gene = 1;
      gene_start = i;
    } else if (!is_exon && in_gene) {
      // End of gene
      int gene_end = i - 1;

      // Get thread-safe gene counter
      pthread_mutex_lock(&g_gene_counter_mutex);
      gene_id = ++g_gene_counter;
      pthread_mutex_unlock(&g_gene_counter_mutex);

      // Format GFF3 output
      int output_start = gene_start + 1;
      int output_end = gene_end + 1;
      if (task->strand == '-') {
        output_start = original_length - gene_end;
        output_end = original_length - gene_start;
      }

      char gff_line[1024];
      snprintf(gff_line, sizeof(gff_line),
               "%s\tsunfish\tgene\t%d\t%d\t%.2f\t%c\t.\tID=gene%d\n",
               task->seq_id, output_start, output_end, normalized_score,
               task->strand, gene_id);

      output_queue_add(&g_output_queue, gff_line);

      snprintf(gff_line, sizeof(gff_line),
               "%s\tsunfish\tCDS\t%d\t%d\t%.2f\t%c\t0\tParent=gene%d\n",
               task->seq_id, output_start, output_end, normalized_score,
               task->strand, gene_id);

      output_queue_add(&g_output_queue, gff_line);

      in_gene = 0;
    }
  }

  // Handle gene extending to end of sequence
  if (in_gene) {
    pthread_mutex_lock(&g_gene_counter_mutex);
    gene_id = ++g_gene_counter;
    pthread_mutex_unlock(&g_gene_counter_mutex);

    int gene_end = seq_len - 1;
    int output_start = gene_start + 1;
    int output_end = gene_end + 1;
    if (task->strand == '-') {
      output_start = original_length - gene_end;
      output_end = original_length - gene_start;
    }

    char gff_line[1024];
    snprintf(gff_line, sizeof(gff_line),
             "%s\tsunfish\tgene\t%d\t%d\t%.2f\t%c\t.\tID=gene%d\n",
             task->seq_id, output_start, output_end, normalized_score,
             task->strand, gene_id);
    output_queue_add(&g_output_queue, gff_line);

    snprintf(gff_line, sizeof(gff_line),
             "%s\tsunfish\tCDS\t%d\t%d\t%.2f\t%c\t0\tParent=gene%d\n",
             task->seq_id, output_start, output_end, normalized_score,
             task->strand, gene_id);
    output_queue_add(&g_output_queue, gff_line);
  }

cleanup:
  if (states)
    free(states);
  if (observations)
    free_observation_sequence(observations, seq_len);
  free(task->sequence);
  free(task->seq_id);
  free(task);
}

// Training mode: Baum-Welch HMM training
static void print_help(const char* progname) {
  printf("Sunfish HMM-based Gene Annotation Tool\n\n");
  printf("Usage:\n");
  printf("  %s <command> [options]\n\n", progname);
  printf("Commands:\n");
  printf("  help                         Show this help message\n"
         "  train <train.fasta> <train.gff> [--wavelet-scales|-w S1,S2,...]"
         " [--threads|-t N]\n"
         "  predict <target.fasta> [--wavelet-scales|-w S1,S2,...]"
         " [--threads|-t N]\n\n");
  printf("Options:\n");
  printf("  -h, --help                   Show this help message\n");
  printf(
      "  --wavelet-scales, -w        Comma-separated list of wavelet scales\n"
      "  --threads, -t N             Number of worker threads (default: auto-"
      "detected)\n\n");
  printf("Examples:\n");
  printf("  %s train data.fa data.gff --wavelet-scales 3,9,81\n", progname);
  printf("  %s predict genome.fa --threads 8 > predictions.gff3\n\n", progname);
}

static void handle_train(int argc, char* argv[]) {
  if (argc < 4) {
    fprintf(stderr,
            "Usage: %s train <train.fasta> <train.gff> [--wavelet-scales|-w "
            "S1,S2,...] [--threads|-t N]\n",
            argv[0]);
    exit(1);
  }

  const char* fasta_path = argv[2];
  const char* gff_path = argv[3];

  // Parse optional arguments
  bool threads_specified = false;
  for (int i = 4; i < argc; i++) {
    if ((strcmp(argv[i], "--wavelet-scales") == 0 ||
         strcmp(argv[i], "-w") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires an argument\n", argv[i]);
        exit(1);
      }
      g_num_wavelet_scales =
          parse_wavelet_scales(argv[++i], g_wavelet_scales, MAX_NUM_WAVELETS);
      fprintf(stderr, "Using %d wavelet scales\n", g_num_wavelet_scales);
    } else if ((strcmp(argv[i], "--threads") == 0 ||
                strcmp(argv[i], "-t") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int parsed_threads = parse_threads_value(argv[++i]);
      if (parsed_threads < 0) {
        fprintf(stderr, "Error: Invalid thread count '%s'\n", argv[i]);
        exit(1);
      }
      g_num_threads = parsed_threads;
      threads_specified = true;
    }
  }

  ensure_thread_count("training", threads_specified);

  // Load training data
  FastaData* genome = parse_fasta(fasta_path);
  if (!genome) {
    fprintf(stderr, "Failed to load FASTA file\n");
    exit(1);
  }
  fprintf(stderr, "Loaded %d sequences\n", genome->count);

  int group_count;
  CdsGroup* groups = parse_gff_for_cds(gff_path, &group_count);
  if (!groups) {
    fprintf(stderr, "Failed to load GFF3 file\n");
    free_fasta_data(genome);
    exit(1);
  }
  fprintf(stderr, "Loaded %d CDS groups\n", group_count);

  // Extract observation sequences from CDS regions
  // For simplicity, we'll compute CWT features for all sequences in parallel
  int total_sequences = genome->count * 2;
  double*** observations =
      (double***)malloc(total_sequences * sizeof(double**));
  int* seq_lengths = (int*)malloc(total_sequences * sizeof(int));

  if (!observations || !seq_lengths) {
    fprintf(stderr, "Failed to allocate buffers for training observations\n");
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  for (int i = 0; i < total_sequences; i++) {
    observations[i] = NULL;
    seq_lengths[i] = 0;
  }

  fprintf(stderr,
          "Augmenting training data with reverse complements (%d total "
          "sequences)\n",
          total_sequences);
  fprintf(stderr,
          "Computing CWT features for training sequences using up to %d "
          "threads...\n",
          g_num_threads);

  thread_pool_t* pool = thread_pool_create(g_num_threads);
  if (pool == NULL) {
    fprintf(stderr, "Failed to create thread pool for training\n");
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  pthread_mutex_t error_mutex;
  if (pthread_mutex_init(&error_mutex, NULL) != 0) {
    fprintf(stderr, "Failed to initialize training mutex\n");
    thread_pool_destroy(pool);
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  bool worker_error = false;
  char error_message[256] = {0};
  bool scheduling_failed = false;

  for (int i = 0; i < genome->count && !scheduling_failed; i++) {
    const char* seq = genome->records[i].sequence;
    const char* seq_id = genome->records[i].id;
    int seq_len = strlen(seq);
    int forward_idx = i * 2;
    int reverse_idx = forward_idx + 1;

    training_task_t* forward_task =
        (training_task_t*)malloc(sizeof(training_task_t));
    if (!forward_task) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to allocate training task for %s (+ strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      scheduling_failed = true;
      break;
    }

    forward_task->sequence = seq;
    forward_task->seq_id = seq_id;
    forward_task->seq_len = seq_len;
    forward_task->array_index = forward_idx;
    forward_task->strand = '+';
    forward_task->observations_array = observations;
    forward_task->seq_lengths_array = seq_lengths;
    forward_task->error_mutex = &error_mutex;
    forward_task->error_flag = &worker_error;
    forward_task->error_message = error_message;
    forward_task->error_message_size = sizeof(error_message);
    forward_task->sequence_number = i + 1;

    if (!thread_pool_add_task(pool, training_observation_worker,
                              forward_task)) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to enqueue training task for %s (+ strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      free(forward_task);
      scheduling_failed = true;
      break;
    }

    training_task_t* reverse_task =
        (training_task_t*)malloc(sizeof(training_task_t));
    if (!reverse_task) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to allocate training task for %s (- strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      scheduling_failed = true;
      break;
    }

    reverse_task->sequence = seq;
    reverse_task->seq_id = seq_id;
    reverse_task->seq_len = seq_len;
    reverse_task->array_index = reverse_idx;
    reverse_task->strand = '-';
    reverse_task->observations_array = observations;
    reverse_task->seq_lengths_array = seq_lengths;
    reverse_task->error_mutex = &error_mutex;
    reverse_task->error_flag = &worker_error;
    reverse_task->error_message = error_message;
    reverse_task->error_message_size = sizeof(error_message);
    reverse_task->sequence_number = i + 1;

    if (!thread_pool_add_task(pool, training_observation_worker,
                              reverse_task)) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to enqueue training task for %s (- strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      free(reverse_task);
      scheduling_failed = true;
      break;
    }
  }

  thread_pool_wait(pool);
  thread_pool_destroy(pool);
  pthread_mutex_destroy(&error_mutex);

  if (worker_error || scheduling_failed) {
    fprintf(stderr, "%s\n",
            error_message[0] ? error_message
                             : "Failed to prepare training observations");
    for (int i = 0; i < total_sequences; i++) {
      if (observations[i]) {
        free_observation_sequence(observations[i], seq_lengths[i]);
      }
    }
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  fprintf(stderr, "Computed CWT features for %d training sequences\n",
          total_sequences);

  // Initialize HMM model
  HMMModel model;
  hmm_init(&model, g_num_wavelet_scales);

  fprintf(stderr, "Starting supervised training with two passes...\n");

  // =========================================================================
  // PASS 1: Calculate global statistics for Z-score normalization
  // =========================================================================
  fprintf(stderr, "Pass 1: Computing global feature statistics...\n");

  double sum[MAX_NUM_WAVELETS] = {0};
  double sum_sq[MAX_NUM_WAVELETS] = {0};
  long long total_count = 0;

  for (int seq_idx = 0; seq_idx < total_sequences; seq_idx++) {
    if (!observations[seq_idx] || seq_lengths[seq_idx] == 0) {
      continue;
    }

    int seq_len = seq_lengths[seq_idx];
    for (int t = 0; t < seq_len; t++) {
      for (int f = 0; f < g_num_wavelet_scales; f++) {
        double val = observations[seq_idx][t][f];
        sum[f] += val;
        sum_sq[f] += val * val;
      }
      total_count++;
    }
  }

  // Calculate mean and standard deviation
  for (int f = 0; f < g_num_wavelet_scales; f++) {
    model.global_feature_mean[f] = sum[f] / total_count;
    double variance = (sum_sq[f] / total_count) - 
                      (model.global_feature_mean[f] * model.global_feature_mean[f]);
    model.global_feature_stddev[f] = sqrt(variance > 1e-10 ? variance : 1e-10);
  }

  fprintf(stderr, "Global statistics computed from %lld observations\n", total_count);

  // =========================================================================
  // PASS 2: Supervised parameter estimation using GFF annotations
  // =========================================================================
  fprintf(stderr, "Pass 2: Learning HMM parameters from annotations...\n");

  // Initialize accumulators
  long long transition_counts[NUM_STATES][NUM_STATES] = {{0}};
  double emission_sum[NUM_STATES][MAX_NUM_WAVELETS] = {{0}};
  double emission_sum_sq[NUM_STATES][MAX_NUM_WAVELETS] = {{0}};
  long long state_observation_counts[NUM_STATES] = {0};
  long long initial_counts[NUM_STATES] = {0};

  // Process each sequence to accumulate statistics
  for (int seq_idx = 0; seq_idx < genome->count; seq_idx++) {
    const char* seq_id = genome->records[seq_idx].id;
    int seq_len = strlen(genome->records[seq_idx].sequence);

    // Process both forward and reverse strand
    for (int strand_idx = 0; strand_idx < 2; strand_idx++) {
      int obs_idx = seq_idx * 2 + strand_idx;
      
      if (!observations[obs_idx] || seq_lengths[obs_idx] == 0) {
        continue;
      }

      // Create state labels array for this sequence
      int* state_labels = (int*)malloc(seq_len * sizeof(int));
      if (!state_labels) {
        fprintf(stderr, "Warning: Failed to allocate state labels for %s\n", seq_id);
        continue;
      }

      // Initialize all positions as intergenic
      for (int i = 0; i < seq_len; i++) {
        state_labels[i] = STATE_INTERGENIC;
      }

      // Label positions based on GFF annotations
      char strand_char = (strand_idx == 0) ? '+' : '-';
      
      // Find CDS groups for this sequence/strand
      for (int g = 0; g < group_count; g++) {
        if (groups[g].exon_count == 0)
          continue;
        
        // Check if this group belongs to the current sequence
        if (strcmp(groups[g].exons[0].seqid, seq_id) != 0)
          continue;
        
        // Check if strand matches
        if (groups[g].exons[0].strand != strand_char)
          continue;

        // Sort exons by start position
        for (int i = 0; i < groups[g].exon_count - 1; i++) {
          for (int j = i + 1; j < groups[g].exon_count; j++) {
            if (groups[g].exons[j].start < groups[g].exons[i].start) {
              Exon temp = groups[g].exons[i];
              groups[g].exons[i] = groups[g].exons[j];
              groups[g].exons[j] = temp;
            }
          }
        }

        // Label exons and introns
        for (int e = 0; e < groups[g].exon_count; e++) {
          int start = groups[g].exons[e].start - 1;  // Convert to 0-based
          int end = groups[g].exons[e].end;          // Inclusive, 1-based -> exclusive 0-based
          int phase = groups[g].exons[e].phase;

          // Label exon positions with appropriate frame
          for (int pos = start; pos < end && pos < seq_len; pos++) {
            int offset_in_exon = pos - start;
            int reading_frame = (phase + offset_in_exon) % 3;
            
            if (reading_frame == 0) {
              state_labels[pos] = STATE_EXON_F0;
            } else if (reading_frame == 1) {
              state_labels[pos] = STATE_EXON_F1;
            } else {
              state_labels[pos] = STATE_EXON_F2;
            }
          }

          // Label intron between this exon and the next
          if (e < groups[g].exon_count - 1) {
            int intron_start = end;
            int intron_end = groups[g].exons[e + 1].start - 1;
            for (int pos = intron_start; pos < intron_end && pos < seq_len; pos++) {
              state_labels[pos] = STATE_INTRON;
            }
          }
        }
      }

      // Accumulate transition counts and emission statistics
      for (int t = 0; t < seq_len; t++) {
        int state = state_labels[t];
        
        // Count initial state
        if (t == 0) {
          initial_counts[state]++;
        }

        // Count transitions
        if (t < seq_len - 1) {
          int next_state = state_labels[t + 1];
          transition_counts[state][next_state]++;
        }

        // Apply Z-score normalization and accumulate emission statistics
        for (int f = 0; f < g_num_wavelet_scales; f++) {
          double raw_val = observations[obs_idx][t][f];
          double normalized_val = (raw_val - model.global_feature_mean[f]) / 
                                  model.global_feature_stddev[f];
          
          emission_sum[state][f] += normalized_val;
          emission_sum_sq[state][f] += normalized_val * normalized_val;
        }
        state_observation_counts[state]++;
      }

      free(state_labels);
    }
  }

  fprintf(stderr, "Finalizing HMM parameters...\n");

  // Finalize initial probabilities
  long long total_initial = 0;
  for (int i = 0; i < NUM_STATES; i++) {
    total_initial += initial_counts[i];
  }
  for (int i = 0; i < NUM_STATES; i++) {
    if (total_initial > 0) {
      model.initial[i] = (double)initial_counts[i] / total_initial;
    } else {
      model.initial[i] = 1.0 / NUM_STATES;
    }
    // Ensure minimum probability
    if (model.initial[i] < 1e-10) {
      model.initial[i] = 1e-10;
    }
  }

  // Finalize transition probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    long long row_sum = 0;
    for (int j = 0; j < NUM_STATES; j++) {
      row_sum += transition_counts[i][j];
    }
    
    for (int j = 0; j < NUM_STATES; j++) {
      if (row_sum > 0) {
        model.transition[i][j] = (double)transition_counts[i][j] / row_sum;
      } else {
        model.transition[i][j] = 1.0 / NUM_STATES;
      }
      // Ensure minimum probability
      if (model.transition[i][j] < 1e-10) {
        model.transition[i][j] = 1e-10;
      }
    }
  }

  // Finalize emission parameters (mean and variance)
  for (int i = 0; i < NUM_STATES; i++) {
    model.emission[i].num_features = g_num_wavelet_scales;
    
    for (int f = 0; f < g_num_wavelet_scales; f++) {
      if (state_observation_counts[i] > 0) {
        double mean = emission_sum[i][f] / state_observation_counts[i];
        double mean_sq = emission_sum_sq[i][f] / state_observation_counts[i];
        double variance = mean_sq - mean * mean;
        
        model.emission[i].mean[f] = mean;
        model.emission[i].variance[f] = (variance > 1e-6) ? variance : 1e-6;
      } else {
        // No observations for this state, use defaults
        model.emission[i].mean[f] = 0.0;
        model.emission[i].variance[f] = 1.0;
      }
    }
    
    fprintf(stderr, "State %d: %lld observations\n", i, state_observation_counts[i]);
  }

  fprintf(stderr, "Supervised training complete.\n");

  // Save model
  if (!hmm_save_model(&model, "sunfish.model")) {
    fprintf(stderr, "Failed to save model\n");
    exit(1);
  }
  fprintf(stderr, "Model saved to sunfish.model\n");

  // Cleanup
  for (int i = 0; i < total_sequences; i++) {
    if (observations[i]) {
      free_observation_sequence(observations[i], seq_lengths[i]);
    }
  }
  free(observations);
  free(seq_lengths);

  free_cds_groups(groups, group_count);
  free_fasta_data(genome);
}

// Prediction mode: Parallel Viterbi prediction
static void handle_predict(int argc, char* argv[]) {
  if (argc < 3) {
    fprintf(stderr,
            "Usage: %s predict <target.fasta> [--wavelet-scales|-w S1,S2,...] "
            "[--threads|-t N]\n",
            argv[0]);
    exit(1);
  }

  const char* fasta_path = argv[2];

  bool threads_specified = false;
  for (int i = 3; i < argc; i++) {
    if ((strcmp(argv[i], "--wavelet-scales") == 0 ||
         strcmp(argv[i], "-w") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires an argument\n", argv[i]);
        exit(1);
      }
      g_num_wavelet_scales =
          parse_wavelet_scales(argv[++i], g_wavelet_scales, MAX_NUM_WAVELETS);
      fprintf(stderr, "Using %d wavelet scales\n", g_num_wavelet_scales);
    } else if ((strcmp(argv[i], "--threads") == 0 ||
                strcmp(argv[i], "-t") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int parsed_threads = parse_threads_value(argv[++i]);
      if (parsed_threads < 0) {
        fprintf(stderr, "Error: Invalid thread count '%s'\n", argv[i]);
        exit(1);
      }
      g_num_threads = parsed_threads;
      threads_specified = true;
    }
  }

  ensure_thread_count("prediction", threads_specified);

  // Load HMM model
  HMMModel model;
  if (!hmm_load_model(&model, "sunfish.model")) {
    fprintf(stderr, "Failed to load model. Run 'train' first.\n");
    exit(1);
  }
  fprintf(stderr, "Loaded HMM model with %d features\n", model.num_features);

  // Initialize output queue
  output_queue_init(&g_output_queue);
  g_gene_counter = 0;

  // Create thread pool
  thread_pool_t* pool = thread_pool_create(g_num_threads);
  if (pool == NULL) {
    fprintf(stderr, "Failed to create thread pool\n");
    exit(1);
  }

  // Load FASTA
  FastaData* genome = parse_fasta(fasta_path);
  if (!genome) {
    fprintf(stderr, "Failed to load FASTA file\n");
    thread_pool_destroy(pool);
    exit(1);
  }

  printf("##gff-version 3\n");

  // Submit prediction tasks to thread pool
  for (int i = 0; i < genome->count; i++) {
    // Process forward strand
    {
      prediction_task_t* task =
          (prediction_task_t*)malloc(sizeof(prediction_task_t));
      if (!task) {
        fprintf(stderr, "Warning: Failed to allocate task for %s (+ strand)\n",
                genome->records[i].id);
      } else {
        task->sequence = strdup(genome->records[i].sequence);
        task->seq_id = strdup(genome->records[i].id);
        task->strand = '+';
        task->model = &model;
        task->original_length = strlen(genome->records[i].sequence);

        if (!task->sequence || !task->seq_id) {
          fprintf(stderr,
                  "Warning: Failed to duplicate inputs for %s (+ strand)\n",
                  genome->records[i].id);
          free(task->sequence);
          free(task->seq_id);
          free(task);
        } else {
          thread_pool_add_task(pool, predict_sequence_worker, task);
          fprintf(stderr, "Processing %s (+ strand)...\n", task->seq_id);
        }
      }
    }

    // Process reverse strand
    char* rc_sequence = reverse_complement(genome->records[i].sequence);
    if (!rc_sequence) {
      fprintf(stderr, "Warning: Failed to generate reverse complement for %s\n",
              genome->records[i].id);
      continue;
    }

    prediction_task_t* task =
        (prediction_task_t*)malloc(sizeof(prediction_task_t));
    if (!task) {
      fprintf(stderr, "Warning: Failed to allocate task for %s (- strand)\n",
              genome->records[i].id);
      free(rc_sequence);
      continue;
    }

    task->sequence = rc_sequence;
    task->seq_id = strdup(genome->records[i].id);
    task->strand = '-';
    task->model = &model;
    task->original_length = strlen(genome->records[i].sequence);

    if (!task->seq_id) {
      fprintf(stderr,
              "Warning: Failed to duplicate sequence ID for %s (- strand)\n",
              genome->records[i].id);
      free(task->sequence);
      free(task);
      continue;
    }

    thread_pool_add_task(pool, predict_sequence_worker, task);
    fprintf(stderr, "Processing %s (- strand)...\n", task->seq_id);
  }

  // Wait for all tasks to complete
  thread_pool_wait(pool);

  // Flush output
  output_queue_flush(&g_output_queue);

  fprintf(stderr, "Prediction complete. Found %d genes.\n", g_gene_counter);

  // Cleanup
  thread_pool_destroy(pool);
  output_queue_destroy(&g_output_queue);
  free_fasta_data(genome);
}

int main(int argc, char* argv[]) {
  // Ensure real-time output behavior
  setvbuf(stdout, NULL, _IOLBF, 0);
  setvbuf(stderr, NULL, _IONBF, 0);

  if (argc < 2) {
    print_help(argv[0]);
    return 0;
  }

  if (strcmp(argv[1], "help") == 0 || strcmp(argv[1], "--help") == 0 ||
      strcmp(argv[1], "-h") == 0) {
    print_help(argv[0]);
    return 0;
  }

  if (strcmp(argv[1], "train") == 0) {
    handle_train(argc, argv);
  } else if (strcmp(argv[1], "predict") == 0) {
    handle_predict(argc, argv);
  } else {
    fprintf(stderr, "Error: Unknown mode '%s'\n", argv[1]);
    fprintf(stderr, "Valid commands: help, train, predict\n");
    print_help(argv[0]);
    return 1;
  }

  return 0;

==> ./src/thread_pool.c <==
#include <pthread.h>
#include <stdbool.h>
#include <stdlib.h>

#include "../include/thread_pool.h"

// Worker thread function
static void* worker_thread(void* arg) {
  thread_pool_t* pool = (thread_pool_t*)arg;
  
  while (true) {
    pthread_mutex_lock(&pool->queue_mutex);
    
    // Wait for a task or shutdown signal
    while (pool->task_queue_head == NULL && !pool->shutdown) {
      pthread_cond_wait(&pool->queue_cond, &pool->queue_mutex);
    }
    
    // Check for shutdown
    if (pool->shutdown && pool->task_queue_head == NULL) {
      pthread_mutex_unlock(&pool->queue_mutex);
      break;
    }
    
    // Dequeue task
    task_t* task = pool->task_queue_head;
    if (task != NULL) {
      pool->task_queue_head = task->next;
      if (pool->task_queue_head == NULL) {
        pool->task_queue_tail = NULL;
      }
      pool->active_tasks++;
    }
    
    pthread_mutex_unlock(&pool->queue_mutex);
    
    // Execute task
    if (task != NULL) {
      task->function(task->argument);
      free(task);
      
      pthread_mutex_lock(&pool->queue_mutex);
      pool->active_tasks--;
      if (pool->active_tasks == 0 && pool->task_queue_head == NULL) {
        pthread_cond_broadcast(&pool->done_cond);
      }
      pthread_mutex_unlock(&pool->queue_mutex);
    }
  }
  
  return NULL;
}

thread_pool_t* thread_pool_create(int num_threads) {
  if (num_threads <= 0) {
    return NULL;
  }
  
  thread_pool_t* pool = (thread_pool_t*)malloc(sizeof(thread_pool_t));
  if (pool == NULL) {
    return NULL;
  }
  
  pool->thread_count = num_threads;
  pool->task_queue_head = NULL;
  pool->task_queue_tail = NULL;
  pool->active_tasks = 0;
  pool->shutdown = false;
  
  // Initialize mutex and condition variables
  if (pthread_mutex_init(&pool->queue_mutex, NULL) != 0) {
    free(pool);
    return NULL;
  }
  
  if (pthread_cond_init(&pool->queue_cond, NULL) != 0) {
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  if (pthread_cond_init(&pool->done_cond, NULL) != 0) {
    pthread_cond_destroy(&pool->queue_cond);
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  // Allocate thread array
  pool->threads = (pthread_t*)malloc(sizeof(pthread_t) * num_threads);
  if (pool->threads == NULL) {
    pthread_cond_destroy(&pool->done_cond);
    pthread_cond_destroy(&pool->queue_cond);
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  // Create worker threads
  for (int i = 0; i < num_threads; i++) {
    if (pthread_create(&pool->threads[i], NULL, worker_thread, pool) != 0) {
      // Failed to create thread, cleanup
      pool->shutdown = true;
      pthread_cond_broadcast(&pool->queue_cond);
      for (int j = 0; j < i; j++) {
        pthread_join(pool->threads[j], NULL);
      }
      free(pool->threads);
      pthread_cond_destroy(&pool->done_cond);
      pthread_cond_destroy(&pool->queue_cond);
      pthread_mutex_destroy(&pool->queue_mutex);
      free(pool);
      return NULL;
    }
  }
  
  return pool;
}

bool thread_pool_add_task(thread_pool_t* pool, task_func_t function, void* arg) {
  if (pool == NULL || function == NULL) {
    return false;
  }
  
  task_t* task = (task_t*)malloc(sizeof(task_t));
  if (task == NULL) {
    return false;
  }
  
  task->function = function;
  task->argument = arg;
  task->next = NULL;
  
  pthread_mutex_lock(&pool->queue_mutex);
  
  if (pool->shutdown) {
    pthread_mutex_unlock(&pool->queue_mutex);
    free(task);
    return false;
  }
  
  // Enqueue task
  if (pool->task_queue_tail == NULL) {
    pool->task_queue_head = task;
    pool->task_queue_tail = task;
  } else {
    pool->task_queue_tail->next = task;
    pool->task_queue_tail = task;
  }
  
  pthread_cond_signal(&pool->queue_cond);
  pthread_mutex_unlock(&pool->queue_mutex);
  
  return true;
}

void thread_pool_wait(thread_pool_t* pool) {
  if (pool == NULL) {
    return;
  }
  
  pthread_mutex_lock(&pool->queue_mutex);
  
  while (pool->active_tasks > 0 || pool->task_queue_head != NULL) {
    pthread_cond_wait(&pool->done_cond, &pool->queue_mutex);
  }
  
  pthread_mutex_unlock(&pool->queue_mutex);
}

void thread_pool_destroy(thread_pool_t* pool) {
  if (pool == NULL) {
    return;
  }
  
  pthread_mutex_lock(&pool->queue_mutex);
  pool->shutdown = true;
  pthread_cond_broadcast(&pool->queue_cond);
  pthread_mutex_unlock(&pool->queue_mutex);
  
  // Join all threads
  for (int i = 0; i < pool->thread_count; i++) {
    pthread_join(pool->threads[i], NULL);
  }
  
  // Free remaining tasks in queue
  task_t* task = pool->task_queue_head;
  while (task != NULL) {
    task_t* next = task->next;
    free(task);
    task = next;
  }
  
  free(pool->threads);
  pthread_cond_destroy(&pool->done_cond);
  pthread_cond_destroy(&pool->queue_cond);
  pthread_mutex_destroy(&pool->queue_mutex);
  free(pool);

==> ./src/utils.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/sunfish.h"

static char complement_base(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 'T';
  case 'T':
    return 'A';
  case 'G':
    return 'C';
  case 'C':
    return 'G';
  default:
    return 'N';
  }
}

void free_fasta_data(FastaData* data) {
  if (!data)
    return;
  for (int i = 0; i < data->count; i++) {
    free(data->records[i].id);
    free(data->records[i].sequence);
  }
  free(data->records);
  free(data);
}

FastaData* parse_fasta(const char* path) {
  FILE* fp = fopen(path, "r");
  if (!fp) {
    fprintf(stderr, "Error: Cannot open FASTA file: %s\n", path);
    return NULL;
  }
  FastaData* data = (FastaData*)calloc(1, sizeof(FastaData));
  if (!data) {
    fclose(fp);
    return NULL;
  }
  int cap = 16;
  data->records = (FastaRecord*)malloc(cap * sizeof(FastaRecord));
  data->count = 0;
  char line[MAX_LINE_LEN];
  char* cur = NULL;
  size_t cur_cap = 0;
  size_t cur_len = 0;
  while (fgets(line, sizeof(line), fp)) {
    size_t len = strlen(line);
    while (len && (line[len - 1] == '\n' || line[len - 1] == '\r'))
      line[--len] = '\0';
    if (line[0] == '>') {
      if (cur) {
        data->records[data->count - 1].sequence = cur;
        cur = NULL;
      }
      if (data->count >= cap) {
        cap *= 2;
        data->records =
            (FastaRecord*)realloc(data->records, cap * sizeof(FastaRecord));
      }
      const char* header = line + 1;
      size_t id_len = 0;
      while (header[id_len] && !isspace((unsigned char)header[id_len]))
        id_len++;
      char* id = (char*)malloc(id_len + 1);
      memcpy(id, header, id_len);
      id[id_len] = '\0';
      data->records[data->count].id = id;
      data->records[data->count].sequence = NULL;
      data->count++;
      cur_cap = 8192;
      cur_len = 0;
      cur = (char*)malloc(cur_cap);
      cur[0] = '\0';
    } else if (cur) {
      size_t ll = strlen(line);
      while (cur_len + ll + 1 > cur_cap) {
        cur_cap *= 2;
        cur = (char*)realloc(cur, cur_cap);
      }
      memcpy(cur + cur_len, line, ll + 1);
      cur_len += ll;
    }
  }
  if (cur && data->count > 0)
    data->records[data->count - 1].sequence = cur;
  fclose(fp);
  return data;
}

void free_cds_groups(CdsGroup* groups, int count) {
  if (!groups)
    return;
  for (int i = 0; i < count; i++) {
    free(groups[i].parent_id);
    free(groups[i].exons);
  }
  free(groups);
}

CdsGroup* parse_gff_for_cds(const char* path, int* group_count) {
  FILE* fp = fopen(path, "r");
  if (!fp) {
    fprintf(stderr, "Error: Cannot open GFF3 file: %s\n", path);
    *group_count = 0;
    return NULL;
  }
  typedef struct {
    char* parent;
    char* seqid;
    int start;
    int end;
    char strand;
    int phase;
  } CdsTemp;
  int temp_cap = 128, temp_cnt = 0;
  CdsTemp* tmp = (CdsTemp*)malloc(temp_cap * sizeof(CdsTemp));
  char line[MAX_LINE_LEN];
  while (fgets(line, sizeof(line), fp)) {
    if (line[0] == '#' || line[0] == '\n')
      continue;
    char seqid[256], source[256], type[256], strand_char, phase_char;
    int start, end;
    char score[256], attrs[MAX_LINE_LEN];
    int n = sscanf(line, "%255s\t%255s\t%255s\t%d\t%d\t%255s\t%c\t%c\t%[^\n]",
                   seqid, source, type, &start, &end, score, &strand_char,
                   &phase_char, attrs);
    if (n < 9 || strcmp(type, "CDS") != 0)
      continue;
    char* p = strstr(attrs, "Parent=");
    if (!p)
      continue;
    p += 7;
    char* sc = strchr(p, ';');
    size_t plen = sc ? (size_t)(sc - p) : strlen(p);
    char parent[256];
    if (plen >= sizeof(parent))
      plen = sizeof(parent) - 1;
    memcpy(parent, p, plen);
    parent[plen] = '\0';
    if (temp_cnt >= temp_cap) {
      temp_cap *= 2;
      tmp = (CdsTemp*)realloc(tmp, temp_cap * sizeof(CdsTemp));
    }
    tmp[temp_cnt].parent = strdup(parent);
    tmp[temp_cnt].seqid = strdup(seqid);
    tmp[temp_cnt].start = start;
    tmp[temp_cnt].end = end;
    tmp[temp_cnt].strand = strand_char;
    tmp[temp_cnt].phase = phase_char - '0';
    temp_cnt++;
  }
  fclose(fp);
  int grp_cap = 64, grp_cnt = 0;
  CdsGroup* groups = (CdsGroup*)malloc(grp_cap * sizeof(CdsGroup));
  for (int i = 0; i < temp_cnt; i++) {
    int gi = -1;
    for (int j = 0; j < grp_cnt; j++) {
      if (strcmp(groups[j].parent_id, tmp[i].parent) == 0) {
        gi = j;
        break;
      }
    }
    if (gi == -1) {
      if (grp_cnt >= grp_cap) {
        grp_cap *= 2;
        groups = (CdsGroup*)realloc(groups, grp_cap * sizeof(CdsGroup));
      }
      gi = grp_cnt++;
      groups[gi].parent_id = strdup(tmp[i].parent);
      groups[gi].exons = NULL;
      groups[gi].exon_count = 0;
    }
    int ei = groups[gi].exon_count++;
    groups[gi].exons =
        (Exon*)realloc(groups[gi].exons, groups[gi].exon_count * sizeof(Exon));
    groups[gi].exons[ei].seqid = strdup(tmp[i].seqid);
    groups[gi].exons[ei].start = tmp[i].start;
    groups[gi].exons[ei].end = tmp[i].end;
    groups[gi].exons[ei].strand = tmp[i].strand;
    groups[gi].exons[ei].phase = tmp[i].phase;
  }
  for (int i = 0; i < temp_cnt; i++) {
    free(tmp[i].parent);
    free(tmp[i].seqid);
  }
  free(tmp);
  *group_count = grp_cnt;
  return groups;
}

char* reverse_complement(const char* sequence) {
  if (sequence == NULL) {
    return NULL;
  }

  size_t len = strlen(sequence);
  char* rc = (char*)malloc(len + 1);
  if (!rc) {
    return NULL;
  }

  for (size_t i = 0; i < len; i++) {
    rc[i] = complement_base(sequence[len - 1 - i]);
  }
  rc[len] = '\0';

  return rc;
