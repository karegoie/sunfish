==> include/cwt.h <==
#ifndef CWT_H
#define CWT_H

#include <complex.h>
#include <stdbool.h>

#include "fft.h"

/**
 * Convert DNA base to complex number on the complex plane.
 * A -> (1+1i), T -> (1-1i), G -> (-1+1i), C -> (-1-1i)
 * @param base DNA base character
 * @return Complex number representation
 */
cplx dna_to_complex(char base);

/**
 * Convert DNA sequence to numerical signal (complex array).
 * @param sequence DNA sequence string
 * @param length Length of sequence
 * @param output Output array (must be pre-allocated)
 */
void dna_to_signal(const char* sequence, int length, cplx* output);

/**
 * Generate Morlet wavelet for a given scale parameter.
 * Formula: ψ(t) = (1/√(s·π^(1/4))) * exp(-1/2 * (t/s)^2) * exp(-j*2π*t/s)
 * @param scale Scale parameter s
 * @param length Length of the wavelet (should be centered at length/2)
 * @param output Output array (must be pre-allocated)
 */
void generate_morlet_wavelet(double scale, int length, cplx* output);

/**
 * Perform convolution using FFT.
 * @param signal Input signal
 * @param signal_len Length of signal
 * @param wavelet Wavelet kernel
 * @param wavelet_len Length of wavelet
 * @param output Output array (must be pre-allocated, size signal_len)
 * @return true on success, false on error
 */
bool convolve_with_wavelet(const cplx* signal, int signal_len,
                           const cplx* wavelet, int wavelet_len,
                           cplx* output);

/**
 * Compute CWT features for a DNA sequence at multiple scales.
 * @param sequence DNA sequence
 * @param seq_len Length of sequence
 * @param scales Array of scale parameters
 * @param num_scales Number of scales
 * @param features Output 2D array [num_scales][seq_len] (must be pre-allocated)
 * @return true on success, false on error
 */
bool compute_cwt_features(const char* sequence, int seq_len,
                          const double* scales, int num_scales,
                          double** features);


==> include/fasta_parser.h <==
#ifndef FASTA_PARSER_H
#define FASTA_PARSER_H

// Data Structures
typedef struct {
  char* id;
  char* sequence;
} FastaRecord;

typedef struct {
  FastaRecord* records;
  int count;
} FastaData;

void free_fasta_data(FastaData* data);
FastaData* parse_fasta(const char* path);


==> include/fft.h <==
#ifndef FFT_H
#define FFT_H

#include <complex.h>
#include <stdbool.h>

// Type alias for convenience
typedef double complex cplx;

/**
 * Compute the Fast Fourier Transform (FFT) using Cooley-Tukey algorithm.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 * @param inverse If true, compute inverse FFT
 */
void fft(cplx* x, int N, bool inverse);

/**
 * Compute inverse FFT with proper normalization.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 */
void ifft(cplx* x, int N);

/**
 * Check if a number is a power of 2.
 * @param n Number to check
 * @return true if n is a power of 2, false otherwise
 */
bool is_power_of_2(int n);

/**
 * Find next power of 2 greater than or equal to n.
 * @param n Input number
 * @return Next power of 2
 */
int next_power_of_2(int n);


==> include/gff_parser.h <==
#ifndef GFF_PARSER_H
#define GFF_PARSER_H

// Data Structures
typedef struct {
  char* seqid;
  int start;
  int end;
  char strand;
  int phase;
} Exon;

typedef struct {
  char* parent_id;
  Exon* exons;
  int exon_count;
} CdsGroup;

void free_cds_groups(CdsGroup* groups, int count);
CdsGroup* parse_gff_for_cds(const char* path, int* group_count);


==> include/hmm.h <==
#ifndef HMM_H
#define HMM_H

#include <stdbool.h>

// HMM states
typedef enum {
  STATE_EXON_F0 = 0,
  STATE_EXON_F1 = 1,
  STATE_EXON_F2 = 2,
  STATE_INTRON = 3,
  STATE_INTERGENIC = 4,
  NUM_STATES = 5
} HMMState;

// Maximum number of wavelet scales (features)
// Increased to support user-specified ranges up to 100 scales.
#define MAX_NUM_WAVELETS 100

// Maximum dimensionality of feature vectors (wavelet)
#define MAX_NUM_FEATURES 8192

// Number of GMM components per state (fixed)
#define GMM_COMPONENTS 2

// Mixture-of-Gaussians emission (fixed K=2)
typedef struct {
  double weight[GMM_COMPONENTS];
  double mean[GMM_COMPONENTS][MAX_NUM_FEATURES];
  double variance[GMM_COMPONENTS][MAX_NUM_FEATURES];
  int num_features;
} MixtureEmission;

// PWM structures for splice site scoring
#define DONOR_MOTIF_SIZE 9
#define ACCEPTOR_MOTIF_SIZE 15
#define NUM_NUCLEOTIDES 4

typedef struct {
  double donor_pwm[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  double acceptor_pwm[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  double min_donor_score;
  double min_acceptor_score;
  int has_donor;
  int has_acceptor;
  double pwm_weight;
} PWMModel;

// Duration distribution parameters for HSMM
typedef struct {
  double mean_log_duration;   // mean of log(duration)
  double stddev_log_duration; // standard deviation of log(duration)
} StateDuration;

// HMM model structure
typedef struct {
  // Transition probabilities: transition[i][j] = P(state_j | state_i)
  double transition[NUM_STATES][NUM_STATES];

  // Initial state probabilities
  double initial[NUM_STATES];

  // Emission parameters for each state (mixture of diagonal Gaussians)
  MixtureEmission emission[NUM_STATES];

  int num_features;
  int wavelet_feature_count;
  int num_wavelet_scales;
  double wavelet_scales[MAX_NUM_WAVELETS];

  // Global feature statistics for Z-score normalization
  double global_feature_mean[MAX_NUM_FEATURES];
  double global_feature_stddev[MAX_NUM_FEATURES];

  // PWM model for splice site scoring
  PWMModel pwm;

  // Duration distribution parameters for HSMM (log-normal distribution)
  StateDuration duration[NUM_STATES];

  // Chunking configuration stored with the model so prediction can reuse
  // the chunk size and overlap that were used during training.
  int chunk_size;    // recommended chunk size in bases (0 = unspecified)
  int chunk_overlap; // recommended chunk overlap in bases
  int use_chunking; // boolean (0/1) whether chunking was enabled when model was
                    // trained
} HMMModel;

/**
 * Initialize HMM with default/random parameters.
 * @param model HMM model to initialize
 * @param num_features Number of CWT features (wavelet scales)
 */
void hmm_init(HMMModel* model, int num_features);

/**
 * Compute Gaussian probability density function (PDF) for diagonal covariance.
 * @param observation Feature vector
 * @param mean Mean vector
 * @param variance Variance vector (diagonal of covariance matrix)
 * @param num_features Dimension of vectors
 * @return Log probability
 */
/* Diagonal Gaussian log-PDF used internally by GMM routines */
double diag_gaussian_logpdf(const double* observation, const double* mean,
                            const double* variance, int num_features);

/* Mixture log-PDF for emission models */
double mixture_log_pdf(const MixtureEmission* emission,
                       const double* observation);

/**
 * Train HMM using Baum-Welch algorithm.
 * @param model HMM model to train
 * @param observations Array of observation sequences (2D:
 * [num_sequences][seq_len][num_features])
 * @param seq_lengths Length of each sequence
 * @param num_sequences Number of training sequences
 * @param max_iterations Maximum number of EM iterations
 * @param convergence_threshold Convergence threshold for log-likelihood change
 * @return true on success, false on error
 */
bool hmm_train_baum_welch(HMMModel* model, double*** observations,
                          int* seq_lengths, int num_sequences,
                          int max_iterations, double convergence_threshold);

/**
 * Predict state sequence using Viterbi algorithm.
 * @param model HMM model
 * @param observations Observation sequence [seq_len][num_features]
 * @param seq_len Length of sequence
 * @param states Output state sequence (must be pre-allocated)
 * @return Log probability of most likely path
 */
double hmm_viterbi(const HMMModel* model, double** observations,
                   const char* sequence, int seq_len, int* states);

/**
 * Save HMM model to file.
 * @param model HMM model
 * @param filename Output filename
 * @return true on success, false on error
 */
bool hmm_save_model(const HMMModel* model, const char* filename);

/**
 * Load HMM model from file.
 * @param model HMM model to load into
 * @param filename Input filename
 * @return true on success, false on error
 */
bool hmm_load_model(HMMModel* model, const char* filename);


==> include/sunfish.h <==
#ifndef SUNFISH_H
#define SUNFISH_H

#include <stdbool.h>

#include "fasta_parser.h"
#include "gff_parser.h"
#include "hmm.h"

// Line and buffer sizes
enum { MAX_LINE_LEN = 50000, MAX_PEPTIDE_LEN = 100000, MAX_DNA_LEN = 1000000 };

// Amino acids
enum { NUM_AMINO_ACIDS = 20 };

typedef struct {
  char* sequence;
  int counts[NUM_AMINO_ACIDS];
  int exon_count;
  int cds_length_nt;
} PeptideInfo;

// PWM Structures
typedef struct {
  double donor_pwm[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  double acceptor_pwm[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  double min_donor_score;
  double min_acceptor_score;
} SplicePWM;

typedef struct {
  int donor_counts[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  int acceptor_counts[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  int total_donor_sites;
  int total_acceptor_sites;
} SpliceCounts;

char* reverse_complement(const char* sequence);


==> include/thread_pool.h <==
#ifndef THREAD_POOL_H
#define THREAD_POOL_H

#include <pthread.h>
#include <stdbool.h>

// Task function signature
typedef void (*task_func_t)(void* arg);

// Task structure
typedef struct task_t {
  task_func_t function;
  void* argument;
  struct task_t* next;
} task_t;

// Thread pool structure
typedef struct {
  pthread_t* threads;
  int thread_count;
  
  task_t* task_queue_head;
  task_t* task_queue_tail;
  
  pthread_mutex_t queue_mutex;
  pthread_cond_t queue_cond;
  pthread_cond_t done_cond;
  
  int active_tasks;
  bool shutdown;
} thread_pool_t;

/**
 * Create a thread pool with specified number of worker threads.
 * @param num_threads Number of worker threads to create
 * @return Pointer to thread pool, or NULL on error
 */
thread_pool_t* thread_pool_create(int num_threads);

/**
 * Add a task to the thread pool's queue.
 * @param pool Thread pool
 * @param function Function to execute
 * @param arg Argument to pass to function
 * @return true on success, false on error
 */
bool thread_pool_add_task(thread_pool_t* pool, task_func_t function, void* arg);

/**
 * Wait for all tasks to complete.
 * @param pool Thread pool
 */
void thread_pool_wait(thread_pool_t* pool);

/**
 * Destroy the thread pool and free all resources.
 * @param pool Thread pool to destroy
 */
void thread_pool_destroy(thread_pool_t* pool);


==> src/cwt.c <==
#include <complex.h>
#include <ctype.h>
#include <math.h>
#include <stdbool.h>
#include <stdlib.h>
#include <string.h>

#include "../include/cwt.h"
#include "../include/fft.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

cplx dna_to_complex(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 1.0 + 1.0 * I;
  case 'T':
    return 1.0 - 1.0 * I;
  case 'G':
    return -1.0 + 1.0 * I;
  case 'C':
    return -1.0 - 1.0 * I;
  default:
    // For unknown bases, return zero
    return 0.0 + 0.0 * I;
  }
}

void dna_to_signal(const char* sequence, int length, cplx* output) {
  for (int i = 0; i < length; i++) {
    output[i] = dna_to_complex(sequence[i]);
  }
}

void generate_morlet_wavelet(double scale, int length, cplx* output) {
  // Morlet wavelet: ψ(t) = (1/√(s·π^(1/4))) * exp(-1/2 * (t/s)^2) *
  // exp(-j*2π*t/s)
  double norm_factor = 1.0 / sqrt(scale * pow(M_PI, 0.25));
  int center = length / 2;

  for (int i = 0; i < length; i++) {
    double t = (double)(i - center);
    double t_scaled = t / scale;
    double gaussian = exp(-0.5 * t_scaled * t_scaled);
    double phase = -2.0 * M_PI * t / scale;
    cplx oscillation = cexp(I * phase);
    output[i] = norm_factor * gaussian * oscillation;
  }
}

bool convolve_with_wavelet(const cplx* signal, int signal_len,
                           const cplx* wavelet, int wavelet_len, cplx* output) {
  // Find common padded length (power of 2)
  int max_len = signal_len + wavelet_len - 1;
  int padded_len = next_power_of_2(max_len);

  // Allocate padded arrays
  cplx* signal_padded = (cplx*)calloc(padded_len, sizeof(cplx));
  cplx* wavelet_padded = (cplx*)calloc(padded_len, sizeof(cplx));

  if (signal_padded == NULL || wavelet_padded == NULL) {
    free(signal_padded);
    free(wavelet_padded);
    return false;
  }

  // Copy data to padded arrays
  memcpy(signal_padded, signal, signal_len * sizeof(cplx));
  memcpy(wavelet_padded, wavelet, wavelet_len * sizeof(cplx));

  // Compute FFT of both
  fft(signal_padded, padded_len, false);
  fft(wavelet_padded, padded_len, false);

  // Element-wise multiplication in frequency domain
  for (int i = 0; i < padded_len; i++) {
    signal_padded[i] = signal_padded[i] * wavelet_padded[i];
  }

  // Inverse FFT
  ifft(signal_padded, padded_len);

  // Calculate offset to correct for convolution delay
  int offset = wavelet_len / 2;

  // Extract complex values with offset correction
  for (int i = 0; i < signal_len; i++) {
    output[i] = signal_padded[i + offset];
  }

  free(signal_padded);
  free(wavelet_padded);

  return true;
}

bool compute_cwt_features(const char* sequence, int seq_len,
                          const double* scales, int num_scales,
                          double** features) {
  // Convert DNA to complex signal
  cplx* signal = (cplx*)malloc(seq_len * sizeof(cplx));
  if (signal == NULL) {
    return false;
  }
  dna_to_signal(sequence, seq_len, signal);

  // For each scale, generate wavelet and convolve
  for (int s = 0; s < num_scales; s++) {
    // Wavelet length equals the given scale (no longer using 10*s)
    int wavelet_len = (int)(scales[s]);
    if (wavelet_len < 1)
      wavelet_len = 1;
    if (wavelet_len > seq_len)
      wavelet_len = seq_len;

    cplx* wavelet = (cplx*)malloc(wavelet_len * sizeof(cplx));
    if (wavelet == NULL) {
      free(signal);
      return false;
    }

    generate_morlet_wavelet(scales[s], wavelet_len, wavelet);

    // Allocate temporary buffer for complex results
    cplx* cwt_result = (cplx*)malloc(seq_len * sizeof(cplx));
    if (cwt_result == NULL) {
      free(wavelet);
      free(signal);
      return false;
    }

    if (!convolve_with_wavelet(signal, seq_len, wavelet, wavelet_len,
                               cwt_result)) {
      free(cwt_result);
      free(wavelet);
      free(signal);
      return false;
    }

    // Store real and imaginary parts only
    // features[s * 2] = real part
    // features[s * 2 + 1] = imaginary part
    for (int i = 0; i < seq_len; i++) {
      features[s * 2][i] = creal(cwt_result[i]);
      features[s * 2 + 1][i] = cimag(cwt_result[i]);
    }

    free(cwt_result);
    free(wavelet);
  }

  free(signal);
  return true;

==> src/fasta_parser.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/fasta_parser.h"
#include "../include/sunfish.h"

void free_fasta_data(FastaData* data) {
  if (!data)
    return;
  for (int i = 0; i < data->count; i++) {
    free(data->records[i].id);
    free(data->records[i].sequence);
  }
  free(data->records);
  free(data);
}

FastaData* parse_fasta(const char* path) {
  FILE* fp = fopen(path, "r");
  if (!fp) {
    fprintf(stderr, "Error: Cannot open FASTA file: %s\n", path);
    return NULL;
  }
  FastaData* data = (FastaData*)calloc(1, sizeof(FastaData));
  if (!data) {
    fclose(fp);
    return NULL;
  }
  int cap = 16;
  data->records = (FastaRecord*)malloc(cap * sizeof(FastaRecord));
  data->count = 0;
  char line[MAX_LINE_LEN];
  char* cur = NULL;
  size_t cur_cap = 0;
  size_t cur_len = 0;
  while (fgets(line, sizeof(line), fp)) {
    size_t len = strlen(line);
    while (len && (line[len - 1] == '\n' || line[len - 1] == '\r'))
      line[--len] = '\0';
    if (line[0] == '>') {
      if (cur) {
        data->records[data->count - 1].sequence = cur;
        cur = NULL;
      }
      if (data->count >= cap) {
        cap *= 2;
        data->records =
            (FastaRecord*)realloc(data->records, cap * sizeof(FastaRecord));
      }
      const char* header = line + 1;
      size_t id_len = 0;
      while (header[id_len] && !isspace((unsigned char)header[id_len]))
        id_len++;
      char* id = (char*)malloc(id_len + 1);
      memcpy(id, header, id_len);
      id[id_len] = '\0';
      data->records[data->count].id = id;
      data->records[data->count].sequence = NULL;
      data->count++;
      cur_cap = 8192;
      cur_len = 0;
      cur = (char*)malloc(cur_cap);
      cur[0] = '\0';
    } else if (cur) {
      size_t ll = strlen(line);
      while (cur_len + ll + 1 > cur_cap) {
        cur_cap *= 2;
        cur = (char*)realloc(cur, cur_cap);
      }
      memcpy(cur + cur_len, line, ll + 1);
      cur_len += ll;
    }
  }
  if (cur && data->count > 0)
    data->records[data->count - 1].sequence = cur;
  fclose(fp);
  return data;

==> src/fft.c <==
#include <complex.h>
#include <math.h>
#include <stdbool.h>
#include <stdlib.h>
#include <string.h>

#include "../include/fft.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

bool is_power_of_2(int n) {
  return n > 0 && (n & (n - 1)) == 0;
}

int next_power_of_2(int n) {
  if (n <= 0)
    return 1;
  n--;
  n |= n >> 1;
  n |= n >> 2;
  n |= n >> 4;
  n |= n >> 8;
  n |= n >> 16;
  n++;
  return n;
}

/**
 * Bit-reversal permutation for FFT.
 * @param x Array to permute
 * @param N Length of array (must be power of 2)
 */
static void bit_reverse_copy(cplx* x, int N) {
  int j = 0;
  for (int i = 0; i < N; i++) {
    if (i < j) {
      cplx temp = x[i];
      x[i] = x[j];
      x[j] = temp;
    }
    int m = N / 2;
    while (m >= 1 && j >= m) {
      j -= m;
      m /= 2;
    }
    j += m;
  }
}

/**
 * Cooley-Tukey FFT implementation (iterative, in-place).
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 * @param inverse If true, compute inverse FFT (without normalization)
 */
void fft(cplx* x, int N, bool inverse) {
  if (!is_power_of_2(N)) {
    // For simplicity, we require N to be a power of 2
    return;
  }

  // Bit-reversal permutation
  bit_reverse_copy(x, N);

  // FFT computation
  double direction = inverse ? 1.0 : -1.0;
  
  for (int s = 1; s <= (int)(log2(N)); s++) {
    int m = 1 << s; // 2^s
    double theta = direction * 2.0 * M_PI / m;
    cplx wm = cexp(I * theta);
    
    for (int k = 0; k < N; k += m) {
      cplx w = 1.0;
      for (int j = 0; j < m / 2; j++) {
        cplx t = w * x[k + j + m / 2];
        cplx u = x[k + j];
        x[k + j] = u + t;
        x[k + j + m / 2] = u - t;
        w = w * wm;
      }
    }
  }

  // Normalization for inverse FFT
  if (inverse) {
    for (int i = 0; i < N; i++) {
      x[i] /= N;
    }
  }
}

/**
 * Compute inverse FFT with proper normalization.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 */
void ifft(cplx* x, int N) {
  fft(x, N, true);

==> src/gff_parser.c <==
#define _POSIX_C_SOURCE 200809L

#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/gff_parser.h"
#include "../include/sunfish.h"

void free_cds_groups(CdsGroup* groups, int count) {
  if (!groups)
    return;
  for (int i = 0; i < count; i++) {
    free(groups[i].parent_id);
    if (groups[i].exons) {
      for (int j = 0; j < groups[i].exon_count; j++) {
        free(groups[i].exons[j].seqid);
      }
      free(groups[i].exons);
    }
  }
  free(groups);
}

CdsGroup* parse_gff_for_cds(const char* path, int* group_count) {
  FILE* fp = fopen(path, "r");
  if (!fp) {
    fprintf(stderr, "Error: Cannot open GFF3 file: %s\n", path);
    *group_count = 0;
    return NULL;
  }
  typedef struct {
    char* parent;
    char* seqid;
    int start;
    int end;
    char strand;
    int phase;
  } CdsTemp;
  int temp_cap = 128, temp_cnt = 0;
  CdsTemp* tmp = (CdsTemp*)malloc(temp_cap * sizeof(CdsTemp));
  char line[MAX_LINE_LEN];
  while (fgets(line, sizeof(line), fp)) {
    if (line[0] == '#' || line[0] == '\n')
      continue;
    char seqid[256], source[256], type[256], strand_char, phase_char;
    int start, end;
    char score[256], attrs[MAX_LINE_LEN];
    int n = sscanf(line, "%255s\t%255s\t%255s\t%d\t%d\t%255s\t%c\t%c\t%[^\n]",
                   seqid, source, type, &start, &end, score, &strand_char,
                   &phase_char, attrs);
    if (n < 9 || strcmp(type, "CDS") != 0)
      continue;
    char* p = strstr(attrs, "Parent=");
    if (!p)
      continue;
    p += 7;
    char* sc = strchr(p, ';');
    size_t plen = sc ? (size_t)(sc - p) : strlen(p);
    char parent[256];
    if (plen >= sizeof(parent))
      plen = sizeof(parent) - 1;
    memcpy(parent, p, plen);
    parent[plen] = '\0';
    if (temp_cnt >= temp_cap) {
      temp_cap *= 2;
      tmp = (CdsTemp*)realloc(tmp, temp_cap * sizeof(CdsTemp));
    }
    tmp[temp_cnt].parent = strdup(parent);
    tmp[temp_cnt].seqid = strdup(seqid);
    tmp[temp_cnt].start = start;
    tmp[temp_cnt].end = end;
    tmp[temp_cnt].strand = strand_char;
    tmp[temp_cnt].phase = phase_char - '0';
    temp_cnt++;
  }
  fclose(fp);
  int grp_cap = 64, grp_cnt = 0;
  CdsGroup* groups = (CdsGroup*)malloc(grp_cap * sizeof(CdsGroup));
  for (int i = 0; i < temp_cnt; i++) {
    int gi = -1;
    for (int j = 0; j < grp_cnt; j++) {
      if (strcmp(groups[j].parent_id, tmp[i].parent) == 0) {
        gi = j;
        break;
      }
    }
    if (gi == -1) {
      if (grp_cnt >= grp_cap) {
        grp_cap *= 2;
        groups = (CdsGroup*)realloc(groups, grp_cap * sizeof(CdsGroup));
      }
      gi = grp_cnt++;
      groups[gi].parent_id = strdup(tmp[i].parent);
      groups[gi].exons = NULL;
      groups[gi].exon_count = 0;
    }
    int ei = groups[gi].exon_count++;
    groups[gi].exons =
        (Exon*)realloc(groups[gi].exons, groups[gi].exon_count * sizeof(Exon));
    groups[gi].exons[ei].seqid = strdup(tmp[i].seqid);
    groups[gi].exons[ei].start = tmp[i].start;
    groups[gi].exons[ei].end = tmp[i].end;
    groups[gi].exons[ei].strand = tmp[i].strand;
    groups[gi].exons[ei].phase = tmp[i].phase;
  }
  for (int i = 0; i < temp_cnt; i++) {
    free(tmp[i].parent);
    free(tmp[i].seqid);
  }
  free(tmp);
  *group_count = grp_cnt;
  return groups;

==> src/hmm.c <==
#include <math.h>
#include <pthread.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>

#include "../include/hmm.h"
#include "../include/thread_pool.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

static inline bool hmm_is_exon_state(int state) {
  return state == STATE_EXON_F0 || state == STATE_EXON_F1 ||
         state == STATE_EXON_F2;
}

static inline int hmm_duration_state_index(int state) {
  return hmm_is_exon_state(state) ? STATE_EXON_F0 : state;
}

static inline const StateDuration*
hmm_get_duration_params(const HMMModel* model, int state) {
  return &model->duration[hmm_duration_state_index(state)];
}

static void hmm_sync_exon_duration(HMMModel* model) {
  const StateDuration* exon_duration =
      hmm_get_duration_params(model, STATE_EXON_F0);
  model->duration[STATE_EXON_F1] = *exon_duration;
  model->duration[STATE_EXON_F2] = *exon_duration;
}

static inline int hmm_exon_cycle_index(int state) {
  switch (state) {
  case STATE_EXON_F0:
    return 0;
  case STATE_EXON_F1:
    return 1;
  case STATE_EXON_F2:
    return 2;
  default:
    return -1;
  }
}

static const HMMState kExonCycleStates[3] = {STATE_EXON_F0, STATE_EXON_F1,
                                             STATE_EXON_F2};

// Variance flooring used throughout emission probability calculations and
// training. Keep this small but non-zero to avoid numerical issues when
// computing Gaussian log-PDFs. This value is referenced in multiple places
// in this translation unit, so changing it ensures consistent behavior.
static const double kVarianceFloor = 1e-2;

// Use GMM_COMPONENTS from header
#ifndef GMM_COMPONENTS
#define GMM_COMPONENTS 2
#endif

typedef struct {
  HMMModel* model;
  double*** observations;
  int* seq_lengths;
  double* initial_acc;
  double (*transition_acc)[NUM_STATES];
  /* emission accumulators: [state][component][feature] */
  double (*emission_mean_acc)[GMM_COMPONENTS][MAX_NUM_FEATURES];
  double (*emission_var_acc)[GMM_COMPONENTS][MAX_NUM_FEATURES];
  /* component weight accumulators per state: [state][component] */
  double (*component_weight_acc)[GMM_COMPONENTS];
  double* state_count; /* sum of gamma per state */
  double* total_log_likelihood;
  pthread_mutex_t initial_mutex;
  pthread_mutex_t transition_mutexes[NUM_STATES];
  pthread_mutex_t emission_mutexes[NUM_STATES];
  pthread_mutex_t log_likelihood_mutex;
  pthread_mutex_t error_mutex;
  int error_flag;
} EStepSharedData;

typedef struct {
  EStepSharedData* shared;
  int sequence_index;
} EStepTask;

static void hmm_mark_error(EStepSharedData* shared);
static int hmm_determine_thread_count(int num_sequences);
static void hmm_e_step_task(void* arg);

static inline int hmm_positive_mod(int value, int mod) {
  int result = value % mod;
  if (result < 0)
    result += mod;
  return result;
}

static inline int hmm_exon_entry_index(int end_index, int duration) {
  if (duration <= 0)
    return end_index;
  int offset = (duration - 1) % 3;
  return hmm_positive_mod(end_index - offset, 3);
}

static inline int hmm_exon_next_index(int current_index) {
  return (current_index + 1) % 3;
}

static inline double hmm_safe_log(double value) {
  const double kMinProb = 1e-300;
  if (value < kMinProb)
    value = kMinProb;
  return log(value);
}

static inline char normalize_base(char base) {
  if (base >= 'a' && base <= 'z') {
    return (char)(base - ('a' - 'A'));
  }
  return base;
}

static inline bool is_strict_dna_base(char base) {
  switch (base) {
  case 'A':
  case 'C':
  case 'G':
  case 'T':
    return true;
  default:
    return false;
  }
}

static inline int base_to_index(char base) {
  switch (base) {
  case 'A':
    return 0;
  case 'C':
    return 1;
  case 'G':
    return 2;
  case 'T':
    return 3;
  default:
    return -1;
  }
}

static double pwm_score_at(const double pwm[][DONOR_MOTIF_SIZE], int pwm_len,
                           const char* sequence, int seq_len, int start_pos) {
  if (!sequence || start_pos < 0 || start_pos + pwm_len > seq_len) {
    return 0.0;
  }

  double score = 0.0;
  for (int i = 0; i < pwm_len; i++) {
    char base = normalize_base(sequence[start_pos + i]);
    int idx = base_to_index(base);
    if (idx < 0) {
      return 0.0; // Invalid base, no contribution
    }
    score += pwm[idx][i];
  }
  return score;
}

static double pwm_score_acceptor(const double pwm[][ACCEPTOR_MOTIF_SIZE],
                                 const char* sequence, int seq_len,
                                 int start_pos) {
  if (!sequence || start_pos < 0 || start_pos + ACCEPTOR_MOTIF_SIZE > seq_len) {
    return 0.0;
  }

  double score = 0.0;
  for (int i = 0; i < ACCEPTOR_MOTIF_SIZE; i++) {
    char base = normalize_base(sequence[start_pos + i]);
    int idx = base_to_index(base);
    if (idx < 0) {
      return 0.0; // Invalid base, no contribution
    }
    score += pwm[idx][i];
  }
  return score;
}

static double splice_signal_adjustment(const char* sequence, int seq_len,
                                       int prev_state, int curr_state,
                                       int position, const PWMModel* pwm) {
  if (!sequence || seq_len <= 0) {
    return 0.0;
  }

  // Empirically chosen log-scale bonuses and penalties
  static const double kMatchBonus = 1e-3;
  static const double kMismatchPenalty = -1e-3;

  double adjustment = 0.0;

  // Exon -> Intron transition (donor site)
  if (hmm_is_exon_state(prev_state) && curr_state == STATE_INTRON) {
    if (position + 1 >= seq_len) {
      return 0.0;
    }

    // Simple GT check
    char first = normalize_base(sequence[position]);
    char second = normalize_base(sequence[position + 1]);
    if (is_strict_dna_base(first) && is_strict_dna_base(second)) {
      adjustment +=
          (first == 'G' && second == 'T') ? kMatchBonus : kMismatchPenalty;
    }

    // Add PWM score if available
    if (pwm && pwm->has_donor) {
      int donor_start = position;
      double pwm_score =
          pwm_score_at((const double (*)[DONOR_MOTIF_SIZE])pwm->donor_pwm,
                       DONOR_MOTIF_SIZE, sequence, seq_len, donor_start);
      adjustment += pwm_score * pwm->pwm_weight;
    }
  }

  // Intron -> Exon transition (acceptor site)
  if (prev_state == STATE_INTRON && hmm_is_exon_state(curr_state)) {
    if (position - 2 < 0 || position - 1 < 0) {
      return 0.0;
    }

    // Simple AG check
    char penultimate = normalize_base(sequence[position - 2]);
    char ultimate = normalize_base(sequence[position - 1]);
    if (is_strict_dna_base(penultimate) && is_strict_dna_base(ultimate)) {
      adjustment += (penultimate == 'A' && ultimate == 'G') ? kMatchBonus
                                                            : kMismatchPenalty;
    }

    // Add PWM score if available
    if (pwm && pwm->has_acceptor) {
      int acceptor_start = position - ACCEPTOR_MOTIF_SIZE;
      double pwm_score = pwm_score_acceptor(
          (const double (*)[ACCEPTOR_MOTIF_SIZE])pwm->acceptor_pwm, sequence,
          seq_len, acceptor_start);
      adjustment += pwm_score * pwm->pwm_weight;
    }
  }

  return adjustment;
}

void hmm_init(HMMModel* model, int num_features) {
  if (num_features > MAX_NUM_FEATURES) {
    num_features = MAX_NUM_FEATURES;
  }

  model->num_features = num_features;
  model->wavelet_feature_count = 0;

  // Initialize uniform transition probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    double sum = 0.0;
    for (int j = 0; j < NUM_STATES; j++) {
      model->transition[i][j] = 1.0 / NUM_STATES;
      sum += model->transition[i][j];
    }
    // Normalize
    for (int j = 0; j < NUM_STATES; j++) {
      model->transition[i][j] /= sum;
    }
  }

  // Initialize uniform initial probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    model->initial[i] = 1.0 / NUM_STATES;
  }

  // Initialize emission parameters as 2-component diagonal GMMs
  for (int s = 0; s < NUM_STATES; s++) {
    model->emission[s].num_features = num_features;
    // Initialize equal weights
    for (int k = 0; k < GMM_COMPONENTS; k++)
      model->emission[s].weight[k] = 1.0 / (double)GMM_COMPONENTS;

    for (int f = 0; f < num_features; f++) {
      // Small random means for component 0 and shifted for component 1
      model->emission[s].mean[0][f] = (double)rand() / RAND_MAX;
      model->emission[s].mean[1][f] = model->emission[s].mean[0][f] + 0.1;
      model->emission[s].variance[0][f] = 0.1;
      model->emission[s].variance[1][f] = 0.2;
    }
  }

  for (int f = 0; f < num_features; f++) {
    model->global_feature_mean[f] = 0.0;
    model->global_feature_stddev[f] = 1.0;
  }

  // Initialize PWM model
  model->pwm.has_donor = 0;
  model->pwm.has_acceptor = 0;
  model->pwm.pwm_weight = 1.0;
  model->pwm.min_donor_score = 0.0;
  model->pwm.min_acceptor_score = 0.0;
  for (int i = 0; i < NUM_NUCLEOTIDES; i++) {
    for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
      model->pwm.donor_pwm[i][j] = 0.0;
    }
    for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
      model->pwm.acceptor_pwm[i][j] = 0.0;
    }
  }

  // Initialize chunking metadata defaults
  model->chunk_size = 0;
  model->chunk_overlap = 0;
  model->use_chunking = 0;

  // Initialize duration parameters with defaults
  for (int i = 0; i < NUM_STATES; i++) {
    model->duration[i].mean_log_duration = 0.0;   // log(1) = 0
    model->duration[i].stddev_log_duration = 1.0; // default stddev
  }

  hmm_sync_exon_duration(model);

  // Initialize wavelet scales metadata
  model->num_wavelet_scales = 0;
  for (int i = 0; i < MAX_NUM_WAVELETS; i++)
    model->wavelet_scales[i] = 0.0;
}

double diag_gaussian_logpdf(const double* observation, const double* mean,
                            const double* variance, int num_features) {
  double log_prob = 0.0;

  for (int i = 0; i < num_features; i++) {
    double diff = observation[i] - mean[i];
    double var = variance[i];

    if (!isfinite(var) || var < kVarianceFloor) {
      var = kVarianceFloor;
    }

    log_prob += -0.5 * log(2.0 * M_PI * var) - 0.5 * (diff * diff) / var;
  }

  return log_prob;
}

double mixture_log_pdf(const MixtureEmission* emission,
                       const double* observation) {
  if (emission == NULL || observation == NULL)
    return -INFINITY;

  double max_lp = -INFINITY;
  double comp_lp[GMM_COMPONENTS];
  for (int k = 0; k < GMM_COMPONENTS; k++) {
    double w = emission->weight[k];
    if (w <= 0.0 || !isfinite(w)) {
      comp_lp[k] = -INFINITY;
      continue;
    }
    comp_lp[k] = log(w) + diag_gaussian_logpdf(observation, emission->mean[k],
                                               emission->variance[k],
                                               emission->num_features);
    if (comp_lp[k] > max_lp)
      max_lp = comp_lp[k];
  }

  if (!isfinite(max_lp))
    return -INFINITY;

  double sum = 0.0;
  for (int k = 0; k < GMM_COMPONENTS; k++) {
    if (!isfinite(comp_lp[k]))
      continue;
    sum += exp(comp_lp[k] - max_lp);
  }
  if (sum <= 0.0)
    return -INFINITY;
  return max_lp + log(sum);
}

// Forward algorithm for Baum-Welch
static double forward_algorithm(const HMMModel* model, double** observations,
                                int seq_len, double** alpha) {
  // alpha[t][i] = P(O_1, O_2, ..., O_t, S_t = i | model)

  // Initialization (t=0)
  for (int i = 0; i < NUM_STATES; i++) {
    alpha[0][i] = log(model->initial[i]) +
                  mixture_log_pdf(&model->emission[i], observations[0]);
  }

  // Induction (t=1 to T-1)
  for (int t = 1; t < seq_len; t++) {
    for (int j = 0; j < NUM_STATES; j++) {
      double max_val = -INFINITY;
      double sum = 0.0;

      // Log-sum-exp trick for numerical stability
      for (int i = 0; i < NUM_STATES; i++) {
        double val = alpha[t - 1][i] + log(model->transition[i][j]);
        if (val > max_val) {
          max_val = val;
        }
      }

      for (int i = 0; i < NUM_STATES; i++) {
        double val = alpha[t - 1][i] + log(model->transition[i][j]);
        sum += exp(val - max_val);
      }

      alpha[t][j] = max_val + log(sum) +
                    mixture_log_pdf(&model->emission[j], observations[t]);
    }
  }

  // Termination - compute total log probability
  double max_val = -INFINITY;
  for (int i = 0; i < NUM_STATES; i++) {
    if (alpha[seq_len - 1][i] > max_val) {
      max_val = alpha[seq_len - 1][i];
    }
  }

  double sum = 0.0;
  for (int i = 0; i < NUM_STATES; i++) {
    sum += exp(alpha[seq_len - 1][i] - max_val);
  }

  return max_val + log(sum);
}

// Backward algorithm for Baum-Welch
static void backward_algorithm(const HMMModel* model, double** observations,
                               int seq_len, double** beta) {
  // beta[t][i] = P(O_{t+1}, O_{t+2}, ..., O_T | S_t = i, model)

  // Initialization (t=T-1)
  for (int i = 0; i < NUM_STATES; i++) {
    beta[seq_len - 1][i] = 0.0; // log(1) = 0
  }

  // Induction (t=T-2 down to 0)
  for (int t = seq_len - 2; t >= 0; t--) {
    for (int i = 0; i < NUM_STATES; i++) {
      double max_val = -INFINITY;
      double sum = 0.0;

      // Log-sum-exp trick
      for (int j = 0; j < NUM_STATES; j++) {
        double val = log(model->transition[i][j]) + beta[t + 1][j] +
                     mixture_log_pdf(&model->emission[j], observations[t + 1]);
        if (val > max_val) {
          max_val = val;
        }
      }

      for (int j = 0; j < NUM_STATES; j++) {
        double val = log(model->transition[i][j]) + beta[t + 1][j] +
                     mixture_log_pdf(&model->emission[j], observations[t + 1]);
        sum += exp(val - max_val);
      }

      beta[t][i] = max_val + log(sum);
    }
  }
}

static void hmm_mark_error(EStepSharedData* shared) {
  if (shared == NULL)
    return;
  pthread_mutex_lock(&shared->error_mutex);
  shared->error_flag = 1;
  pthread_mutex_unlock(&shared->error_mutex);
}

static int hmm_determine_thread_count(int num_sequences) {
  if (num_sequences <= 0) {
    return 1;
  }

  long cpu_count = sysconf(_SC_NPROCESSORS_ONLN);
  int threads = (cpu_count > 0) ? (int)cpu_count : 1;
  if (threads > num_sequences) {
    threads = num_sequences;
  }
  if (threads <= 0) {
    threads = 1;
  }
  return threads;
}

static void hmm_e_step_task(void* arg) {
  EStepTask* task = (EStepTask*)arg;
  if (task == NULL) {
    return;
  }

  EStepSharedData* shared = task->shared;
  double** alpha = NULL;
  double** beta = NULL;
  int allocated_rows = 0;
  int seq_len = 0;

  if (shared == NULL) {
    free(task);
    return;
  }

  pthread_mutex_lock(&shared->error_mutex);
  int has_error = shared->error_flag;
  pthread_mutex_unlock(&shared->error_mutex);

  if (has_error || shared->model == NULL || shared->observations == NULL ||
      shared->seq_lengths == NULL) {
    free(task);
    return;
  }

  seq_len = shared->seq_lengths[task->sequence_index];
  double** sequence = shared->observations[task->sequence_index];

  if (seq_len <= 0 || sequence == NULL) {
    free(task);
    return;
  }

  alpha = (double**)malloc(sizeof(double*) * seq_len);
  beta = (double**)malloc(sizeof(double*) * seq_len);
  if (alpha == NULL || beta == NULL) {
    hmm_mark_error(shared);
    goto cleanup;
  }

  for (int t = 0; t < seq_len; ++t) {
    alpha[t] = (double*)malloc(sizeof(double) * NUM_STATES);
    if (alpha[t] == NULL) {
      hmm_mark_error(shared);
      goto cleanup;
    }
    beta[t] = (double*)malloc(sizeof(double) * NUM_STATES);
    if (beta[t] == NULL) {
      free(alpha[t]);
      alpha[t] = NULL;
      hmm_mark_error(shared);
      goto cleanup;
    }
    allocated_rows++;
  }

  double log_prob = forward_algorithm(shared->model, sequence, seq_len, alpha);
  backward_algorithm(shared->model, sequence, seq_len, beta);

  pthread_mutex_lock(&shared->log_likelihood_mutex);
  *shared->total_log_likelihood += log_prob;
  pthread_mutex_unlock(&shared->log_likelihood_mutex);

  double initial_contrib[NUM_STATES] = {0.0};

  for (int t = 0; t < seq_len; ++t) {
    double gamma[NUM_STATES];
    double gamma_norm = -INFINITY;

    for (int i = 0; i < NUM_STATES; i++) {
      gamma[i] = alpha[t][i] + beta[t][i];
      if (gamma[i] > gamma_norm) {
        gamma_norm = gamma[i];
      }
    }

    double gamma_sum = 0.0;
    for (int i = 0; i < NUM_STATES; i++) {
      gamma[i] = exp(gamma[i] - gamma_norm);
      gamma_sum += gamma[i];
    }

    if (gamma_sum <= 0.0) {
      continue;
    }

    const double* observation = sequence[t];

    for (int i = 0; i < NUM_STATES; i++) {
      gamma[i] /= gamma_sum;

      if (t == 0) {
        initial_contrib[i] = gamma[i];
      }

      if (gamma[i] <= 0.0 || observation == NULL) {
        continue;
      }

      /* For state i, compute responsibilities for each GMM component */
      double comp_lp[GMM_COMPONENTS];
      double comp_w[GMM_COMPONENTS];
      double maxc = -INFINITY;
      for (int k = 0; k < GMM_COMPONENTS; k++) {
        comp_lp[k] = log(shared->model->emission[i].weight[k]) +
                     diag_gaussian_logpdf(
                         observation, shared->model->emission[i].mean[k],
                         shared->model->emission[i].variance[k],
                         shared->model->emission[i].num_features);
        if (comp_lp[k] > maxc)
          maxc = comp_lp[k];
      }
      double compsum = 0.0;
      for (int k = 0; k < GMM_COMPONENTS; k++) {
        comp_w[k] = exp(comp_lp[k] - maxc);
        compsum += comp_w[k];
      }
      if (compsum <= 0.0)
        continue;

      pthread_mutex_lock(&shared->emission_mutexes[i]);
      shared->state_count[i] += gamma[i];
      for (int k = 0; k < GMM_COMPONENTS; k++) {
        double r = (comp_w[k] / compsum) * gamma[i];
        shared->component_weight_acc[i][k] += r;
        for (int f = 0; f < shared->model->num_features; f++) {
          double val = observation[f];
          shared->emission_mean_acc[i][k][f] += r * val;
          shared->emission_var_acc[i][k][f] += r * val * val;
        }
      }
      pthread_mutex_unlock(&shared->emission_mutexes[i]);
    }

    if (t < seq_len - 1) {
      const double* next_observation = sequence[t + 1];
      if (next_observation == NULL) {
        continue;
      }

      double xi[NUM_STATES][NUM_STATES];
      double xi_norm = -INFINITY;

      for (int i = 0; i < NUM_STATES; i++) {
        for (int j = 0; j < NUM_STATES; j++) {
          xi[i][j] =
              alpha[t][i] + log(shared->model->transition[i][j]) +
              mixture_log_pdf(&shared->model->emission[j], next_observation) +
              beta[t + 1][j];
          if (xi[i][j] > xi_norm) {
            xi_norm = xi[i][j];
          }
        }
      }

      double xi_sum = 0.0;
      for (int i = 0; i < NUM_STATES; i++) {
        for (int j = 0; j < NUM_STATES; j++) {
          xi[i][j] = exp(xi[i][j] - xi_norm);
          xi_sum += xi[i][j];
        }
      }

      if (xi_sum > 0.0) {
        for (int i = 0; i < NUM_STATES; i++) {
          pthread_mutex_lock(&shared->transition_mutexes[i]);
          for (int j = 0; j < NUM_STATES; j++) {
            shared->transition_acc[i][j] += xi[i][j] / xi_sum;
          }
          pthread_mutex_unlock(&shared->transition_mutexes[i]);
        }
      }
    }
  }

  if (seq_len > 0) {
    pthread_mutex_lock(&shared->initial_mutex);
    for (int i = 0; i < NUM_STATES; i++) {
      shared->initial_acc[i] += initial_contrib[i];
    }
    pthread_mutex_unlock(&shared->initial_mutex);
  }

cleanup:
  if (alpha != NULL) {
    for (int t = 0; t < allocated_rows; ++t) {
      free(alpha[t]);
    }
    free(alpha);
  }
  if (beta != NULL) {
    for (int t = 0; t < allocated_rows; ++t) {
      free(beta[t]);
    }
    free(beta);
  }
  free(task);
}

bool hmm_train_baum_welch(HMMModel* model, double*** observations,
                          int* seq_lengths, int num_sequences,
                          int max_iterations, double convergence_threshold) {
  if (model == NULL || observations == NULL || seq_lengths == NULL ||
      num_sequences <= 0 || max_iterations <= 0) {
    return false;
  }

  int thread_count = hmm_determine_thread_count(num_sequences);
  thread_pool_t* pool = thread_pool_create(thread_count);
  if (pool == NULL) {
    return false;
  }

  double initial_acc[NUM_STATES];
  double transition_acc[NUM_STATES][NUM_STATES];
  double emission_mean_acc[NUM_STATES][GMM_COMPONENTS][MAX_NUM_FEATURES];
  double emission_var_acc[NUM_STATES][GMM_COMPONENTS][MAX_NUM_FEATURES];
  double component_weight_acc[NUM_STATES][GMM_COMPONENTS];
  double state_count[NUM_STATES];
  double total_log_likelihood = 0.0;

  EStepSharedData shared = {.model = model,
                            .observations = observations,
                            .seq_lengths = seq_lengths,
                            .initial_acc = initial_acc,
                            .transition_acc = transition_acc,
                            .emission_mean_acc = emission_mean_acc,
                            .emission_var_acc = emission_var_acc,
                            .component_weight_acc = component_weight_acc,
                            .state_count = state_count,
                            .total_log_likelihood = &total_log_likelihood,
                            .error_flag = 0};

  bool success = true;
  bool initial_mutex_created = false;
  bool log_mutex_created = false;
  bool error_mutex_created = false;
  int transition_init_count = 0;
  int emission_init_count = 0;

  if (pthread_mutex_init(&shared.initial_mutex, NULL) != 0) {
    success = false;
    goto cleanup;
  }
  initial_mutex_created = true;

  if (pthread_mutex_init(&shared.log_likelihood_mutex, NULL) != 0) {
    success = false;
    goto cleanup;
  }
  log_mutex_created = true;

  if (pthread_mutex_init(&shared.error_mutex, NULL) != 0) {
    success = false;
    goto cleanup;
  }
  error_mutex_created = true;

  for (; transition_init_count < NUM_STATES; ++transition_init_count) {
    if (pthread_mutex_init(&shared.transition_mutexes[transition_init_count],
                           NULL) != 0) {
      success = false;
      goto cleanup;
    }
  }

  for (; emission_init_count < NUM_STATES; ++emission_init_count) {
    if (pthread_mutex_init(&shared.emission_mutexes[emission_init_count],
                           NULL) != 0) {
      success = false;
      goto cleanup;
    }
  }

  double prev_log_likelihood = -INFINITY;

  for (int iter = 0; iter < max_iterations; iter++) {
    for (int i = 0; i < NUM_STATES; i++) {
      initial_acc[i] = 0.0;
      state_count[i] = 0.0;
      for (int j = 0; j < NUM_STATES; j++) {
        transition_acc[i][j] = 0.0;
      }
      for (int k = 0; k < GMM_COMPONENTS; k++) {
        component_weight_acc[i][k] = 0.0;
        for (int f = 0; f < model->num_features; f++) {
          emission_mean_acc[i][k][f] = 0.0;
          emission_var_acc[i][k][f] = 0.0;
        }
      }
    }
    total_log_likelihood = 0.0;

    pthread_mutex_lock(&shared.error_mutex);
    shared.error_flag = 0;
    pthread_mutex_unlock(&shared.error_mutex);

    for (int seq = 0; seq < num_sequences; seq++) {
      EStepTask* task = (EStepTask*)malloc(sizeof(EStepTask));
      if (task == NULL) {
        hmm_mark_error(&shared);
        break;
      }
      task->shared = &shared;
      task->sequence_index = seq;

      if (!thread_pool_add_task(pool, hmm_e_step_task, task)) {
        free(task);
        hmm_mark_error(&shared);
        break;
      }
    }

    thread_pool_wait(pool);

    pthread_mutex_lock(&shared.error_mutex);
    int has_error = shared.error_flag;
    pthread_mutex_unlock(&shared.error_mutex);
    if (has_error) {
      success = false;
      break;
    }

    double initial_sum = 0.0;
    for (int i = 0; i < NUM_STATES; i++) {
      initial_sum += initial_acc[i];
    }
    if (initial_sum <= 0.0) {
      double uniform = 1.0 / NUM_STATES;
      for (int i = 0; i < NUM_STATES; i++) {
        model->initial[i] = uniform;
      }
    } else {
      for (int i = 0; i < NUM_STATES; i++) {
        model->initial[i] = initial_acc[i] / initial_sum;
        if (model->initial[i] < 1e-10)
          model->initial[i] = 1e-10;
      }
    }

    for (int i = 0; i < NUM_STATES; i++) {
      double trans_sum = 0.0;
      for (int j = 0; j < NUM_STATES; j++) {
        trans_sum += transition_acc[i][j];
      }
      for (int j = 0; j < NUM_STATES; j++) {
        if (trans_sum > 0.0) {
          model->transition[i][j] = transition_acc[i][j] / trans_sum;
        } else {
          model->transition[i][j] = 1.0 / NUM_STATES;
        }
        if (model->transition[i][j] < 1e-10)
          model->transition[i][j] = 1e-10;
      }
    }

    for (int i = 0; i < NUM_STATES; i++) {
      if (state_count[i] > 0.0) {
        double weight_sum = 0.0;
        for (int k = 0; k < GMM_COMPONENTS; k++) {
          weight_sum += component_weight_acc[i][k];
        }
        for (int k = 0; k < GMM_COMPONENTS; k++) {
          double comp_w = component_weight_acc[i][k];
          if (comp_w > 0.0) {
            for (int f = 0; f < model->num_features; f++) {
              double mean = emission_mean_acc[i][k][f] / comp_w;
              double mean_sq = emission_var_acc[i][k][f] / comp_w;
              double var = mean_sq - mean * mean;
              if (!isfinite(var) || var < kVarianceFloor)
                var = kVarianceFloor;
              model->emission[i].mean[k][f] = mean;
              model->emission[i].variance[k][f] = var;
            }
          } else {
            /* Reinitialize tiny variance if component had no responsibility */
            for (int f = 0; f < model->num_features; f++) {
              model->emission[i].variance[k][f] = kVarianceFloor;
            }
          }
          /* Update weight (normalize later) */
          if (weight_sum > 0.0)
            model->emission[i].weight[k] =
                component_weight_acc[i][k] / weight_sum;
          else
            model->emission[i].weight[k] = 1.0 / (double)GMM_COMPONENTS;
        }
      }
      model->emission[i].num_features = model->num_features;
    }

    double total_log_likelihood_iter = total_log_likelihood;

    fprintf(stderr, "Iteration %d: Log-likelihood = %.4f\n", iter + 1,
            total_log_likelihood_iter);

    if (iter > 0 && fabs(total_log_likelihood_iter - prev_log_likelihood) <
                        convergence_threshold) {
      fprintf(stderr, "Converged after %d iterations\n", iter + 1);
      break;
    }

    prev_log_likelihood = total_log_likelihood_iter;
  }

cleanup:
  for (int i = transition_init_count - 1; i >= 0; --i) {
    pthread_mutex_destroy(&shared.transition_mutexes[i]);
  }
  for (int i = emission_init_count - 1; i >= 0; --i) {
    pthread_mutex_destroy(&shared.emission_mutexes[i]);
  }
  if (error_mutex_created) {
    pthread_mutex_destroy(&shared.error_mutex);
  }
  if (log_mutex_created) {
    pthread_mutex_destroy(&shared.log_likelihood_mutex);
  }
  if (initial_mutex_created) {
    pthread_mutex_destroy(&shared.initial_mutex);
  }

  thread_pool_destroy(pool);

  return success;
}

// Helper function to compute log probability of duration d under log-normal
// distribution
static double lognormal_log_pdf(int duration, double mean_log_duration,
                                double stddev_log_duration) {
  if (duration <= 0) {
    return -INFINITY;
  }

  if (stddev_log_duration < 1e-6) {
    stddev_log_duration = 1e-6; // Prevent numerical issues
  }

  double log_d = log((double)duration);
  double diff = log_d - mean_log_duration;
  double var = stddev_log_duration * stddev_log_duration;

  // Log-PDF of log-normal distribution:
  // -log(d) - 0.5*log(2*pi*var) - (log(d) - mu)^2 / (2*var)
  return -log_d - 0.5 * log(2.0 * M_PI * var) - (diff * diff) / (2.0 * var);
}

double hmm_viterbi(const HMMModel* model, double** observations,
                   const char* sequence, int seq_len, int* states) {
  // HSMM Viterbi with segment-based processing
  const int MAX_DURATION = 2000; // Maximum segment duration to consider

  // Allocate Viterbi matrices
  // delta[t][j] = max log-probability of path ending at position t in state j
  double** delta = (double**)malloc(seq_len * sizeof(double*));
  // psi[t][j] stores the best previous state for ending at t in state j
  int** psi = (int**)malloc(seq_len * sizeof(int*));
  // duration[t][j] stores the optimal duration of state j ending at position t
  int** duration = (int**)malloc(seq_len * sizeof(int*));
  // emission_log_sum[t][j] stores cumulative emission log-probability up to t
  double** emission_log_sum = (double**)malloc(seq_len * sizeof(double*));

  for (int t = 0; t < seq_len; t++) {
    delta[t] = (double*)malloc(NUM_STATES * sizeof(double));
    psi[t] = (int*)malloc(NUM_STATES * sizeof(int));
    duration[t] = (int*)malloc(NUM_STATES * sizeof(int));
    emission_log_sum[t] = (double*)malloc(NUM_STATES * sizeof(double));

    for (int j = 0; j < NUM_STATES; j++) {
      delta[t][j] = -INFINITY;
      psi[t][j] = 0;
      duration[t][j] = 1;
    }
  }

  for (int t = 0; t < seq_len; t++) {
    for (int j = 0; j < NUM_STATES; j++) {
      double emission_log =
          mixture_log_pdf(&model->emission[j], observations[t]);
      if (t == 0) {
        emission_log_sum[t][j] = emission_log;
      } else {
        emission_log_sum[t][j] = emission_log_sum[t - 1][j] + emission_log;
      }
    }
  }

  double* exon_internal_transition_log_sum =
      (double*)calloc(seq_len, sizeof(double));
  if (exon_internal_transition_log_sum != NULL) {
    for (int t = 1; t < seq_len; t++) {
      int prev_frame_idx = (t - 1) % 3;
      int curr_frame_idx = t % 3;
      HMMState prev_state = kExonCycleStates[prev_frame_idx];
      HMMState curr_state = kExonCycleStates[curr_frame_idx];

      exon_internal_transition_log_sum[t] =
          exon_internal_transition_log_sum[t - 1] +
          hmm_safe_log(model->transition[prev_state][curr_state]);
    }
  }

  // Initialization (t=0): start with segments of length 1
  for (int j = 0; j < NUM_STATES; j++) {
    const StateDuration* duration_params = hmm_get_duration_params(model, j);
    delta[0][j] = hmm_safe_log(model->initial[j]) +
                  mixture_log_pdf(&model->emission[j], observations[0]) +
                  lognormal_log_pdf(1, duration_params->mean_log_duration,
                                    duration_params->stddev_log_duration);
    psi[0][j] = -1; // No previous state
    duration[0][j] = 1;
  }

  // Recursion: for each position t and state j, consider all possible durations
  for (int t = 1; t < seq_len; t++) {
    for (int j = 0; j < NUM_STATES; j++) {
      const StateDuration* duration_params = hmm_get_duration_params(model, j);
      double best_score = -INFINITY;
      int best_prev_state = 0;
      int best_duration = 1;

      bool j_is_exon = hmm_is_exon_state(j);
      int j_end_index = hmm_exon_cycle_index(j);

      // Try different segment durations d
      int max_d = (t + 1 < MAX_DURATION) ? (t + 1) : MAX_DURATION;

      for (int d = 1; d <= max_d && d <= t + 1; d++) {
        // Determine entry state for this segment
        HMMState segment_entry_state = j;
        int entry_index = j_end_index;
        if (j_is_exon) {
          entry_index = hmm_exon_entry_index(j_end_index, d);
          segment_entry_state = kExonCycleStates[entry_index];
        }

        // Compute log probability (emission + internal transitions) for
        // segment [t-d+1, t]
        double segment_log_prob = 0.0;
        int start_pos = t - d + 1;
        if (j_is_exon) {
          double exon_emission_sum = 0.0;
          for (int frame = 0; frame < 3; ++frame) {
            HMMState frame_state = kExonCycleStates[frame];
            double frame_sum = emission_log_sum[t][frame_state];
            if (start_pos > 0) {
              frame_sum -= emission_log_sum[start_pos - 1][frame_state];
            }
            exon_emission_sum += frame_sum;
          }
          segment_log_prob = exon_emission_sum / 3.0;

          if (d > 1 && exon_internal_transition_log_sum != NULL) {
            segment_log_prob += exon_internal_transition_log_sum[t] -
                                exon_internal_transition_log_sum[start_pos];
          }
        } else {
          double segment_emission;
          if (start_pos == 0) {
            segment_emission = emission_log_sum[t][j];
          } else {
            segment_emission =
                emission_log_sum[t][j] - emission_log_sum[start_pos - 1][j];
          }
          segment_log_prob += segment_emission;
        }

        // Compute duration probability
        double duration_prob =
            lognormal_log_pdf(d, duration_params->mean_log_duration,
                              duration_params->stddev_log_duration);

        // Consider transitions from all previous states
        if (d == t + 1) {
          // Segment starts from position 0 (initial state)
          double score = hmm_safe_log(model->initial[segment_entry_state]) +
                         segment_log_prob + duration_prob;
          if (score > best_score) {
            best_score = score;
            best_prev_state = -1;
            best_duration = d;
          }
        } else {
          // Segment starts after position t-d
          int prev_pos = t - d;
          for (int i = 0; i < NUM_STATES; i++) {
            if (delta[prev_pos][i] <= -INFINITY)
              continue;

            double transition_log =
                hmm_safe_log(model->transition[i][segment_entry_state]);
            // Add splice signal adjustment at the transition point (t-d+1)
            transition_log += splice_signal_adjustment(sequence, seq_len, i,
                                                       segment_entry_state,
                                                       t - d + 1, &model->pwm);

            double score = delta[prev_pos][i] + transition_log +
                           segment_log_prob + duration_prob;

            if (score > best_score) {
              best_score = score;
              best_prev_state = i;
              best_duration = d;
            }
          }
        }
      }

      delta[t][j] = best_score;
      psi[t][j] = best_prev_state;
      duration[t][j] = best_duration;
    }
  }

  // Termination - find best final state
  double max_prob = -INFINITY;
  int best_state = 0;
  for (int i = 0; i < NUM_STATES; i++) {
    if (delta[seq_len - 1][i] > max_prob) {
      max_prob = delta[seq_len - 1][i];
      best_state = i;
    }
  }

  // Backtrack using segment information
  int t = seq_len - 1;
  int current_state = best_state;

  while (t >= 0) {
    int d = duration[t][current_state];
    int prev_state = psi[t][current_state];

    // Fill in the states for the segment
    if (d <= 0)
      d = 1;

    int start_pos = t - d + 1;
    if (start_pos < 0)
      start_pos = 0;

    if (hmm_is_exon_state(current_state)) {
      int end_index = hmm_exon_cycle_index(current_state);
      int entry_index = hmm_exon_entry_index(end_index, d);
      int current_index = entry_index;
      HMMState state_for_pos = kExonCycleStates[current_index];

      for (int pos = start_pos; pos <= t && pos < seq_len; pos++) {
        states[pos] = state_for_pos;
        if (pos < t) {
          current_index = hmm_exon_next_index(current_index);
          state_for_pos = kExonCycleStates[current_index];
        }
      }
    } else {
      for (int pos = start_pos; pos <= t && pos < seq_len; pos++) {
        states[pos] = current_state;
      }
    }

    // Move to previous segment
    t = start_pos - 1;
    if (prev_state >= 0) {
      current_state = prev_state;
    } else {
      break;
    }
  }

  // Free matrices
  for (int t = 0; t < seq_len; t++) {
    free(delta[t]);
    free(psi[t]);
    free(duration[t]);
    free(emission_log_sum[t]);
  }
  free(delta);
  free(psi);
  free(duration);
  free(emission_log_sum);
  free(exon_internal_transition_log_sum);

  return max_prob;
}

bool hmm_save_model(const HMMModel* model, const char* filename) {
  FILE* fp = fopen(filename, "w");
  if (fp == NULL) {
    return false;
  }

  // Ensure exon frames share the same duration parameters when persisting.
  HMMModel tmp_model = *model;
  hmm_sync_exon_duration(&tmp_model);

  fprintf(fp, "#HMM_MODEL_V1\n");
  fprintf(fp, "#num_features %d\n", model->num_features);
  fprintf(fp, "#wavelet_features %d\n", model->wavelet_feature_count);
  fprintf(fp, "#num_states %d\n", NUM_STATES);

  // Save initial probabilities
  fprintf(fp, "INITIAL\n");
  for (int i = 0; i < NUM_STATES; i++) {
    fprintf(fp, "%.10f ", model->initial[i]);
  }
  fprintf(fp, "\n");

  // Save transition matrix
  fprintf(fp, "TRANSITION\n");
  for (int i = 0; i < NUM_STATES; i++) {
    for (int j = 0; j < NUM_STATES; j++) {
      fprintf(fp, "%.10f ", model->transition[i][j]);
    }
    fprintf(fp, "\n");
  }

  // Save emission parameters (per-component)
  fprintf(fp, "EMISSION\n");
  for (int i = 0; i < NUM_STATES; i++) {
    fprintf(fp, "STATE %d\n", i);
    for (int k = 0; k < GMM_COMPONENTS; k++) {
      fprintf(fp, "WEIGHT %d %.10f\n", k, model->emission[i].weight[k]);
      fprintf(fp, "MEAN_%d ", k);
      for (int j = 0; j < model->num_features; j++) {
        fprintf(fp, "%.10f ", model->emission[i].mean[k][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "VARIANCE_%d ", k);
      for (int j = 0; j < model->num_features; j++) {
        fprintf(fp, "%.10f ", model->emission[i].variance[k][j]);
      }
      fprintf(fp, "\n");
    }
  }

  // Save global feature statistics for Z-score normalization
  fprintf(fp, "GLOBAL_STATS\n");
  fprintf(fp, "MEAN ");
  for (int i = 0; i < model->num_features; i++) {
    fprintf(fp, "%.10f ", model->global_feature_mean[i]);
  }
  fprintf(fp, "\n");
  fprintf(fp, "STDDEV ");
  for (int i = 0; i < model->num_features; i++) {
    fprintf(fp, "%.10f ", model->global_feature_stddev[i]);
  }
  fprintf(fp, "\n");

  // Save duration parameters (HSMM)
  fprintf(fp, "DURATION\n");
  for (int i = 0; i < NUM_STATES; i++) {
    const StateDuration* duration_params =
        hmm_get_duration_params(&tmp_model, i);
    fprintf(fp, "%.10f %.10f\n", duration_params->mean_log_duration,
            duration_params->stddev_log_duration);
  }

  // Save PWM if present
  if (model->pwm.has_donor || model->pwm.has_acceptor) {
    fprintf(fp, "PWM\n");
    fprintf(fp, "WEIGHT %.10f\n", model->pwm.pwm_weight);

    if (model->pwm.has_donor) {
      fprintf(fp, "DONOR %d\n", DONOR_MOTIF_SIZE);
      fprintf(fp, "A:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[0][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "C:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[1][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "G:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[2][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "T:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[3][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "MIN_SCORE %.10f\n", model->pwm.min_donor_score);
    }

    if (model->pwm.has_acceptor) {
      fprintf(fp, "ACCEPTOR %d\n", ACCEPTOR_MOTIF_SIZE);
      fprintf(fp, "A:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[0][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "C:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[1][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "G:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[2][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "T:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[3][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "MIN_SCORE %.10f\n", model->pwm.min_acceptor_score);
    }
  }

  // Save chunking metadata
  fprintf(fp, "#chunk_size %d\n", model->chunk_size);
  fprintf(fp, "#chunk_overlap %d\n", model->chunk_overlap);
  fprintf(fp, "#use_chunking %d\n", model->use_chunking);

  // Save wavelet scales metadata (if present)
  if (model->num_wavelet_scales > 0) {
    fprintf(fp, "#num_wavelet_scales %d\n", model->num_wavelet_scales);
    fprintf(fp, "#wavelet_scales");
    for (int i = 0; i < model->num_wavelet_scales; i++) {
      fprintf(fp, " %.10f", model->wavelet_scales[i]);
    }
    fprintf(fp, "\n");
  }

  fclose(fp);
  return true;
}

bool hmm_load_model(HMMModel* model, const char* filename) {
  FILE* fp = fopen(filename, "r");
  if (fp == NULL) {
    return false;
  }

  char line[1024];

  // Read header
  if (fgets(line, sizeof(line), fp) == NULL) {
    fclose(fp);
    return false;
  }

  model->num_features = 0;
  model->wavelet_feature_count = 0;
  model->chunk_size = 0;
  model->chunk_overlap = 0;
  model->use_chunking = 0;
  model->num_wavelet_scales = 0;
  for (int i = 0; i < MAX_NUM_WAVELETS; i++)
    model->wavelet_scales[i] = 0.0;

  int tmp_num_states = NUM_STATES;

  while (true) {
    long pos = ftell(fp);
    if (fgets(line, sizeof(line), fp) == NULL) {
      fclose(fp);
      return false;
    }

    if (line[0] != '#') {
      // Rewind so the next read starts at this non-metadata line
      fseek(fp, pos, SEEK_SET);
      break;
    }

    if (sscanf(line, "#num_features %d", &model->num_features) == 1)
      continue;
    if (sscanf(line, "#wavelet_features %d", &model->wavelet_feature_count) ==
        1)
      continue;
    // Legacy k-mer metadata is ignored (no longer used).
    if (sscanf(line, "#chunk_size %d", &model->chunk_size) == 1)
      continue;
    if (sscanf(line, "#chunk_overlap %d", &model->chunk_overlap) == 1)
      continue;
    if (sscanf(line, "#use_chunking %d", &model->use_chunking) == 1)
      continue;
    if (sscanf(line, "#num_wavelet_scales %d", &model->num_wavelet_scales) == 1)
      continue;
    if (strncmp(line, "#wavelet_scales", 15) == 0) {
      // parse space separated doubles after tag
      char* ptr = line + 15;
      int idx = 0;
      while (ptr && *ptr != '\0' && idx < MAX_NUM_WAVELETS) {
        double v = 0.0;
        if (sscanf(ptr, "%lf", &v) != 1)
          break;
        model->wavelet_scales[idx++] = v;
        char* next = strchr(ptr, ' ');
        if (!next)
          break;
        ptr = next + 1;
      }
      // if num_wavelet_scales wasn't set earlier, infer from parsed values
      if (model->num_wavelet_scales == 0)
        model->num_wavelet_scales =
            0; // will set later based on wavelet_feature_count
      continue;
    }
    (void)sscanf(line, "#num_states %d", &tmp_num_states);
  }

  if (model->num_features > MAX_NUM_FEATURES)
    model->num_features = MAX_NUM_FEATURES;

  if (model->wavelet_feature_count < 0)
    model->wavelet_feature_count = 0;

  if (model->wavelet_feature_count == 0) {
    model->wavelet_feature_count = model->num_features;
  }

  if (model->wavelet_feature_count > model->num_features)
    model->wavelet_feature_count = model->num_features;

  // Read initial probabilities
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "INITIAL", 7) == 0) {
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = line;
      for (int i = 0; i < NUM_STATES; i++) {
        if (sscanf(ptr, "%lf", &model->initial[i]) != 1)
          break;
        ptr = strchr(ptr, ' ');
        if (ptr)
          ptr++;
        else
          break;
      }
    } else {
      fclose(fp);
      return false;
    }
  }

  // Read transition matrix
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "TRANSITION", 10) == 0) {
    for (int i = 0; i < NUM_STATES; i++) {
      if (fgets(line, sizeof(line), fp) != NULL) {
        char* ptr = line;
        for (int j = 0; j < NUM_STATES; j++) {
          if (sscanf(ptr, "%lf", &model->transition[i][j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      } else {
        fclose(fp);
        return false;
      }
    }
  }

  // Read emission parameters (support new per-component format and legacy)
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "EMISSION", 8) == 0) {
    for (int i = 0; i < NUM_STATES; i++) {
      // Expect a "STATE <i>" line
      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }

      // Peek ahead to detect whether per-component blocks are present
      long save_pos = ftell(fp);
      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }

      if (strncmp(line, "MEAN", 4) == 0) {
        // Legacy format: MEAN / VARIANCE lines
        char* ptr = line + 5;
        for (int j = 0; j < model->num_features; j++) {
          if (sscanf(ptr, "%lf", &model->emission[i].mean[0][j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
        if (fgets(line, sizeof(line), fp) == NULL) {
          fclose(fp);
          return false;
        }
        ptr = strstr(line, "VARIANCE");
        if (ptr) {
          ptr += 9;
          for (int j = 0; j < model->num_features; j++) {
            if (sscanf(ptr, "%lf", &model->emission[i].variance[0][j]) != 1)
              break;
            ptr = strchr(ptr, ' ');
            if (ptr)
              ptr++;
            else
              break;
          }
        }
        // Populate other components with small perturbation
        for (int k = 1; k < GMM_COMPONENTS; k++) {
          for (int j = 0; j < model->num_features; j++) {
            model->emission[i].mean[k][j] = model->emission[i].mean[0][j] + 0.1;
            model->emission[i].variance[k][j] =
                model->emission[i].variance[0][j] + 0.1;
            model->emission[i].weight[k] = 1.0 / (double)GMM_COMPONENTS;
          }
        }
      } else {
        // New per-component format: rewind and parse per-component blocks
        fseek(fp, save_pos, SEEK_SET);
        for (int k = 0; k < GMM_COMPONENTS; k++) {
          if (fgets(line, sizeof(line), fp) == NULL) {
            fclose(fp);
            return false;
          }
          // Expect WEIGHT <k> <value>
          double w = 0.0;
          sscanf(line, "WEIGHT %*d %lf", &w);
          model->emission[i].weight[k] = w;

          if (fgets(line, sizeof(line), fp) == NULL) {
            fclose(fp);
            return false;
          }
          char* ptr = strstr(line, "MEAN_");
          if (ptr) {
            ptr = strchr(ptr, ' ');
            if (ptr)
              ptr++;
            for (int j = 0; j < model->num_features; j++) {
              if (sscanf(ptr, "%lf", &model->emission[i].mean[k][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }

          if (fgets(line, sizeof(line), fp) == NULL) {
            fclose(fp);
            return false;
          }
          ptr = strstr(line, "VARIANCE_");
          if (ptr) {
            ptr = strchr(ptr, ' ');
            if (ptr)
              ptr++;
            for (int j = 0; j < model->num_features; j++) {
              if (sscanf(ptr, "%lf", &model->emission[i].variance[k][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
        }
      }

      model->emission[i].num_features = model->num_features;
    }
  }

  // Enforce variance flooring for numerical stability
  for (int i = 0; i < NUM_STATES; i++) {
    for (int k = 0; k < GMM_COMPONENTS; k++) {
      for (int j = 0; j < model->num_features; j++) {
        if (!isfinite(model->emission[i].variance[k][j]) ||
            model->emission[i].variance[k][j] < kVarianceFloor) {
          model->emission[i].variance[k][j] = kVarianceFloor;
        }
      }
      if (model->emission[i].weight[k] <= 0.0 ||
          !isfinite(model->emission[i].weight[k])) {
        model->emission[i].weight[k] = 1.0 / (double)GMM_COMPONENTS;
      }
    }
  }

  // Read global feature statistics (optional for backward compatibility)
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "GLOBAL_STATS", 12) == 0) {
    // Read MEAN line
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = strstr(line, "MEAN");
      if (ptr) {
        ptr += 5;
        for (int i = 0; i < model->num_features; i++) {
          if (sscanf(ptr, "%lf", &model->global_feature_mean[i]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }
    }

    // Read STDDEV line
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = strstr(line, "STDDEV");
      if (ptr) {
        ptr += 7;
        for (int i = 0; i < model->num_features; i++) {
          if (sscanf(ptr, "%lf", &model->global_feature_stddev[i]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }
    }
  } else {
    // Initialize to default values if not present (backward compatibility)
    for (int i = 0; i < model->num_features; i++) {
      model->global_feature_mean[i] = 0.0;
      model->global_feature_stddev[i] = 1.0;
    }
  }

  // Initialize PWM with defaults
  model->pwm.has_donor = 0;
  model->pwm.has_acceptor = 0;
  model->pwm.pwm_weight = 1.0;
  model->pwm.min_donor_score = 0.0;
  model->pwm.min_acceptor_score = 0.0;

  // Read PWM block if present (optional for backward compatibility)
  if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "PWM", 3) == 0) {
    // Read WEIGHT line
    if (fgets(line, sizeof(line), fp) != NULL) {
      if (sscanf(line, "WEIGHT %lf", &model->pwm.pwm_weight) != 1) {
        model->pwm.pwm_weight = 1.0;
      }
    }

    // Read DONOR or ACCEPTOR blocks
    while (fgets(line, sizeof(line), fp) != NULL) {
      if (strncmp(line, "DONOR", 5) == 0) {
        int donor_size = 0;
        if (sscanf(line, "DONOR %d", &donor_size) == 1 &&
            donor_size == DONOR_MOTIF_SIZE) {
          model->pwm.has_donor = 1;

          // Read A: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "A:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[0][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read C: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "C:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[1][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read G: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "G:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[2][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read T: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "T:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[3][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read MIN_SCORE line
          if (fgets(line, sizeof(line), fp) != NULL) {
            sscanf(line, "MIN_SCORE %lf", &model->pwm.min_donor_score);
          }
        }
      } else if (strncmp(line, "ACCEPTOR", 8) == 0) {
        int acceptor_size = 0;
        if (sscanf(line, "ACCEPTOR %d", &acceptor_size) == 1 &&
            acceptor_size == ACCEPTOR_MOTIF_SIZE) {
          model->pwm.has_acceptor = 1;

          // Read A: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "A:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[0][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read C: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "C:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[1][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read G: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "G:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[2][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read T: line
          if (fgets(line, sizeof(line), fp) != NULL &&
              strncmp(line, "T:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[3][j]) != 1)
                break;
              ptr = strchr(ptr, ' ');
              if (ptr)
                ptr++;
              else
                break;
            }
          }
          // Read MIN_SCORE line
          if (fgets(line, sizeof(line), fp) != NULL) {
            sscanf(line, "MIN_SCORE %lf", &model->pwm.min_acceptor_score);
          }
        }
      }
    }
  }

  // Initialize duration parameters with defaults (for backward compatibility)
  for (int i = 0; i < NUM_STATES; i++) {
    model->duration[i].mean_log_duration = 0.0;
    model->duration[i].stddev_log_duration = 1.0;
  }

  // Read DURATION block if present (optional for backward compatibility)
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "DURATION", 8) == 0) {
    for (int i = 0; i < NUM_STATES; i++) {
      if (fgets(line, sizeof(line), fp) != NULL) {
        if (sscanf(line, "%lf %lf", &model->duration[i].mean_log_duration,
                   &model->duration[i].stddev_log_duration) != 2) {
          // If parsing fails, keep defaults
          model->duration[i].mean_log_duration = 0.0;
          model->duration[i].stddev_log_duration = 1.0;
        }
      }
    }
  }

  hmm_sync_exon_duration(model);

  // Compute num_wavelet_scales from wavelet_feature_count if not set
  // Some model metadata (chunk_size, chunk_overlap, use_chunking,
  // wavelet_scales) may be written at the end of the file by
  // hmm_save_model. The initial metadata pass only handled leading
  // '#' lines; ensure we also scan the entire file to pick up trailing
  // metadata so prediction can faithfully reproduce training settings.
  if (fseek(fp, 0, SEEK_SET) == 0) {
    while (fgets(line, sizeof(line), fp) != NULL) {
      if (line[0] != '#')
        continue;
      int tmp_int = 0;
      if (sscanf(line, "#chunk_size %d", &tmp_int) == 1) {
        model->chunk_size = tmp_int;
        continue;
      }
      if (sscanf(line, "#chunk_overlap %d", &tmp_int) == 1) {
        model->chunk_overlap = tmp_int;
        continue;
      }
      if (sscanf(line, "#use_chunking %d", &tmp_int) == 1) {
        model->use_chunking = tmp_int;
        continue;
      }
      if (sscanf(line, "#num_wavelet_scales %d", &tmp_int) == 1) {
        model->num_wavelet_scales = tmp_int;
        continue;
      }
      if (strncmp(line, "#wavelet_scales", 15) == 0) {
        // parse space separated doubles after tag
        char* ptr = line + 15;
        int idx = 0;
        while (ptr && *ptr != '\0' && idx < MAX_NUM_WAVELETS) {
          double v = 0.0;
          if (sscanf(ptr, "%lf", &v) != 1)
            break;
          model->wavelet_scales[idx++] = v;
          char* next = strchr(ptr, ' ');
          if (!next)
            break;
          ptr = next + 1;
        }
        if (model->num_wavelet_scales == 0)
          model->num_wavelet_scales = idx;
        continue;
      }
    }
    // rewind to original file end for subsequent reads/close
    fseek(fp, 0, SEEK_END);
  }

  if (model->num_wavelet_scales == 0 && model->wavelet_feature_count > 0) {
    model->num_wavelet_scales = model->wavelet_feature_count / 2;
  }

  fclose(fp);
  return true;

==> src/sunfish.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <errno.h>
#include <limits.h>
#include <math.h>
#include <pthread.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>

#include "../include/cwt.h"
#include "../include/fft.h"
#include "../include/hmm.h"
#include "../include/sunfish.h"
#include "../include/thread_pool.h"

// Global configuration
// Default wavelet scales: powers of 3 from 3
static int g_num_wavelet_scales = 8;
static double g_wavelet_scales[MAX_NUM_WAVELETS] = {
    3.0, 9.0, 27.0, 81.0, 243.0, 729.0, 2187.0, 6561.0};
// Default: 0 means "not set"; we'll use number of online processors at runtime
static int g_num_threads = 0;
static int g_total_feature_count = 16; // 8 scales * 2 (real + imaginary)

// Chunk-based prediction configuration
static int g_chunk_size = 50000;   // Default chunk size: 50kb
static int g_chunk_overlap = 5000; // Default overlap: 5kb
static bool g_use_chunking = true;

static int get_env_thread_override(void);

// Thread-safe output queue
typedef struct output_node_t {
  char* gff_line;
  struct output_node_t* next;
} output_node_t;

typedef struct {
  output_node_t* head;
  output_node_t* tail;
  pthread_mutex_t mutex;
} output_queue_t;

static output_queue_t g_output_queue;
static pthread_mutex_t g_gene_counter_mutex = PTHREAD_MUTEX_INITIALIZER;
static int g_gene_counter = 0;

static int parse_threads_value(const char* arg) {
  if (arg == NULL)
    return -1;

  char* endptr = NULL;
  errno = 0;
  long value = strtol(arg, &endptr, 10);

  if (errno != 0 || endptr == arg || *endptr != '\0')
    return -1;

  if (value < 1 || value > INT_MAX)
    return -1;

  return (int)value;
}

static bool parse_non_negative_int(const char* arg, int* out_value) {
  if (arg == NULL || out_value == NULL)
    return false;

  char* endptr = NULL;
  errno = 0;
  long value = strtol(arg, &endptr, 10);

  if (errno != 0 || endptr == arg || *endptr != '\0')
    return false;

  if (value < 0 || value > INT_MAX)
    return false;

  *out_value = (int)value;
  return true;
}

static int detect_hardware_threads(void) {
  long nprocs = sysconf(_SC_NPROCESSORS_ONLN);
  if (nprocs < 1)
    nprocs = 1;
  if (nprocs > INT_MAX)
    nprocs = INT_MAX;
  return (int)nprocs;
}

static int get_env_thread_override(void) {
  const char* env_vars[] = {"SUNFISH_THREADS", "OMP_NUM_THREADS"};
  const size_t env_count = sizeof(env_vars) / sizeof(env_vars[0]);

  for (size_t i = 0; i < env_count; i++) {
    const char* value = getenv(env_vars[i]);
    if (value == NULL || *value == '\0')
      continue;

    int parsed = parse_threads_value(value);
    if (parsed > 0)
      return parsed;

    fprintf(stderr,
            "Warning: Ignoring invalid thread count '%s' from %s. Expected a "
            "positive integer.\n",
            value, env_vars[i]);
  }

  return -1;
}

static void ensure_thread_count(const char* mode, bool threads_specified) {
  const char* source = threads_specified ? "user-specified" : "default";

  if (!threads_specified && g_num_threads <= 0) {
    int env_threads = get_env_thread_override();
    if (env_threads > 0) {
      g_num_threads = env_threads;
      source = "env";
    }
  }

  if (g_num_threads <= 0) {
    g_num_threads = detect_hardware_threads();
    source = "auto-detected";
  }

  fprintf(stderr, "Using %d threads for %s (%s)\n", g_num_threads, mode,
          source);
}

static bool update_feature_counts(void) {
  int wavelet_features = g_num_wavelet_scales * 2;

  if (wavelet_features > MAX_NUM_FEATURES)
    return false;

  g_total_feature_count = wavelet_features;
  if (g_total_feature_count <= 0)
    return false;
  return true;
}

static const char* get_field_ptr(const char* line, int field_index) {
  if (!line || field_index <= 0)
    return NULL;

  const char* ptr = line;
  int current = 1;

  while (current < field_index && ptr) {
    const char* next_tab = strchr(ptr, '\t');
    if (!next_tab)
      return NULL;
    ptr = next_tab + 1;
    current++;
  }

  return ptr;
}

static long extract_start_coordinate(const char* line) {
  const char* start_ptr = get_field_ptr(line, 4);
  if (!start_ptr)
    return LONG_MAX;

  return strtol(start_ptr, NULL, 10);
}

static int feature_rank(const char* feature) {
  if (!feature)
    return 100;

  if (strncmp(feature, "gene", 4) == 0)
    return 0;
  if (strncmp(feature, "mRNA", 4) == 0)
    return 1;
  if (strncmp(feature, "CDS", 3) == 0)
    return 2;

  return 10;
}

static int compare_gff_lines(const void* a, const void* b) {
  const char* line_a = *(const char* const*)a;
  const char* line_b = *(const char* const*)b;

  const char* seq_a = line_a;
  const char* seq_b = line_b;

  size_t len_a = 0;
  while (seq_a[len_a] != '\t' && seq_a[len_a] != '\0')
    len_a++;

  size_t len_b = 0;
  while (seq_b[len_b] != '\t' && seq_b[len_b] != '\0')
    len_b++;

  size_t min_len = (len_a < len_b) ? len_a : len_b;
  int cmp = strncmp(seq_a, seq_b, min_len);
  if (cmp == 0) {
    if (len_a != len_b)
      cmp = (len_a < len_b) ? -1 : 1;
  }

  if (cmp != 0)
    return cmp;

  long start_a = extract_start_coordinate(line_a);
  long start_b = extract_start_coordinate(line_b);

  if (start_a < start_b)
    return -1;
  if (start_a > start_b)
    return 1;

  const char* feature_a = get_field_ptr(line_a, 3);
  const char* feature_b = get_field_ptr(line_b, 3);

  int rank_a = feature_rank(feature_a);
  int rank_b = feature_rank(feature_b);
  if (rank_a != rank_b)
    return (rank_a < rank_b) ? -1 : 1;

  return strcmp(line_a, line_b);
}

// Initialize output queue
static void output_queue_init(output_queue_t* queue) {
  queue->head = NULL;
  queue->tail = NULL;
  pthread_mutex_init(&queue->mutex, NULL);
}

// Add output to queue (thread-safe)
static void output_queue_add(output_queue_t* queue, const char* gff_line) {
  output_node_t* node = (output_node_t*)malloc(sizeof(output_node_t));
  if (node == NULL)
    return;

  node->gff_line = strdup(gff_line);
  node->next = NULL;

  pthread_mutex_lock(&queue->mutex);
  if (queue->tail == NULL) {
    queue->head = node;
    queue->tail = node;
  } else {
    queue->tail->next = node;
    queue->tail = node;
  }
  pthread_mutex_unlock(&queue->mutex);
}

// Flush output queue to stdout (not thread-safe, call from main thread)
static void output_queue_flush(output_queue_t* queue) {
  pthread_mutex_lock(&queue->mutex);
  output_node_t* node = queue->head;
  int count = 0;
  while (node != NULL) {
    count++;
    node = node->next;
  }

  char** lines = NULL;
  if (count > 0) {
    lines = (char**)malloc(count * sizeof(char*));
  }

  int idx = 0;
  node = queue->head;
  queue->head = NULL;
  queue->tail = NULL;
  pthread_mutex_unlock(&queue->mutex);

  while (node != NULL) {
    if (lines)
      lines[idx++] = node->gff_line;
    output_node_t* next = node->next;
    free(node);
    node = next;
  }

  if (lines) {
    qsort(lines, count, sizeof(char*), compare_gff_lines);

    for (int i = 0; i < count; i++) {
      printf("%s", lines[i]);
      /* Ensure output is flushed immediately so redirected output (e.g., to a
         file or a pipe) receives records in real time. */
      fflush(stdout);
      free(lines[i]);
    }

    free(lines);
  }
}

// Destroy output queue
static void output_queue_destroy(output_queue_t* queue) {
  output_queue_flush(queue);
  pthread_mutex_destroy(&queue->mutex);
}

typedef struct {
  int start;
  int end;
  int phase;
} OutputExon;

typedef struct {
  char* seq_id;
  char strand;
  int start; // 1-based inclusive
  int end;   // 1-based inclusive
  double score;
  OutputExon* exons;
  size_t exon_count;
} PredictedGeneRecord;

typedef struct {
  PredictedGeneRecord* genes;
  size_t count;
  size_t capacity;
  pthread_mutex_t mutex;
} predicted_gene_store_t;

static predicted_gene_store_t g_predicted_gene_store;

static void free_predicted_gene_record(PredictedGeneRecord* gene) {
  if (!gene)
    return;

  free(gene->seq_id);
  if (gene->exons) {
    free(gene->exons);
    gene->exons = NULL;
  }
  gene->exon_count = 0;
}

static void predicted_gene_store_init(predicted_gene_store_t* store) {
  if (!store)
    return;

  store->genes = NULL;
  store->count = 0;
  store->capacity = 0;
  pthread_mutex_init(&store->mutex, NULL);
}

static void predicted_gene_store_destroy(predicted_gene_store_t* store) {
  if (!store)
    return;

  pthread_mutex_lock(&store->mutex);
  for (size_t i = 0; i < store->count; i++) {
    free_predicted_gene_record(&store->genes[i]);
  }
  free(store->genes);
  store->genes = NULL;
  store->count = 0;
  store->capacity = 0;
  pthread_mutex_unlock(&store->mutex);
  pthread_mutex_destroy(&store->mutex);
}

static bool predicted_gene_store_reserve(predicted_gene_store_t* store,
                                         size_t desired) {
  if (!store)
    return false;

  if (desired <= store->capacity)
    return true;

  size_t new_capacity = store->capacity ? store->capacity * 2 : 16;
  if (new_capacity < desired)
    new_capacity = desired;

  PredictedGeneRecord* resized = (PredictedGeneRecord*)realloc(
      store->genes, new_capacity * sizeof(PredictedGeneRecord));
  if (!resized)
    return false;

  store->genes = resized;
  store->capacity = new_capacity;
  return true;
}

/* Removed unused helper functions (predicted_gene_store_remove_at,
   predicted_gene_intervals_overlap, compare_gene_score) which were
   formerly used by a simpler merge strategy. The current implementation
   collects all candidates and applies weighted interval scheduling when
   emitting, so these helpers are unnecessary and caused unused-function
   compiler warnings. */

static bool predicted_gene_store_add(predicted_gene_store_t* store,
                                     const char* seq_id, char strand,
                                     int gene_start, int gene_end, double score,
                                     OutputExon* exons, size_t exon_count) {
  if (!store || !seq_id || !exons || exon_count == 0)
    return false;

  // Create record and append it to the store without removing existing
  PredictedGeneRecord record;
  record.seq_id = strdup(seq_id);
  if (!record.seq_id) {
    free(exons);
    return false;
  }
  record.strand = strand;
  record.start = gene_start;
  record.end = gene_end;
  record.score = score;
  record.exons = exons;
  record.exon_count = exon_count;

  pthread_mutex_lock(&store->mutex);
  if (!predicted_gene_store_reserve(store, store->count + 1)) {
    pthread_mutex_unlock(&store->mutex);
    free_predicted_gene_record(&record);
    return false;
  }

  store->genes[store->count++] = record;
  pthread_mutex_unlock(&store->mutex);
  return true;
}

static int compare_gene_records_for_output(const void* a, const void* b) {
  const PredictedGeneRecord* const* ga = (const PredictedGeneRecord* const*)a;
  const PredictedGeneRecord* const* gb = (const PredictedGeneRecord* const*)b;

  int cmp = strcmp((*ga)->seq_id, (*gb)->seq_id);
  if (cmp != 0)
    return cmp;

  if ((*ga)->start < (*gb)->start)
    return -1;
  if ((*ga)->start > (*gb)->start)
    return 1;

  if ((*ga)->end < (*gb)->end)
    return -1;
  if ((*ga)->end > (*gb)->end)
    return 1;

  if ((*ga)->score > (*gb)->score)
    return -1;
  if ((*ga)->score < (*gb)->score)
    return 1;

  return 0;
}

static void predicted_gene_store_emit_to_queue(predicted_gene_store_t* store) {
  if (!store)
    return;

  pthread_mutex_lock(&store->mutex);
  size_t count = store->count;
  if (count == 0) {
    pthread_mutex_unlock(&store->mutex);
    return;
  }

  PredictedGeneRecord** order =
      (PredictedGeneRecord**)malloc(count * sizeof(PredictedGeneRecord*));
  if (!order) {
    pthread_mutex_unlock(&store->mutex);
    return;
  }

  for (size_t i = 0; i < count; i++) {
    order[i] = &store->genes[i];
  }

  qsort(order, count, sizeof(PredictedGeneRecord*),
        compare_gene_records_for_output);
  // Perform weighted interval scheduling per (seq_id, strand)
  g_gene_counter = 0;

  // Group contiguous records by seq_id+strand considering order is sorted by
  // seq_id then start
  size_t idx = 0;
  while (idx < count) {
    PredictedGeneRecord* base = order[idx];
    if (!base) {
      idx++;
      continue;
    }

    const char* cur_seq = base->seq_id;
    char cur_strand = base->strand;

    // Collect group indices
    size_t group_start = idx;
    size_t group_end = idx + 1;
    while (group_end < count) {
      PredictedGeneRecord* r = order[group_end];
      if (!r)
        break;
      if (strcmp(r->seq_id, cur_seq) != 0 || r->strand != cur_strand)
        break;
      group_end++;
    }

    size_t group_count = group_end - group_start;
    if (group_count == 0) {
      idx = group_end;
      continue;
    }

    // Build arrays for weighted interval scheduling
    // intervals: [start,end] inclusive as stored
    int* starts = (int*)malloc(group_count * sizeof(int));
    int* ends = (int*)malloc(group_count * sizeof(int));
    double* weights = (double*)malloc(group_count * sizeof(double));
    PredictedGeneRecord** items = (PredictedGeneRecord**)malloc(
        group_count * sizeof(PredictedGeneRecord*));

    if (!starts || !ends || !weights || !items) {
      free(starts);
      free(ends);
      free(weights);
      free(items);
      // fallback: emit sequentially
      for (size_t j = group_start; j < group_end; j++) {
        PredictedGeneRecord* gene = order[j];
        if (!gene)
          continue;
        int gene_id = 0;
        pthread_mutex_lock(&g_gene_counter_mutex);
        gene_id = ++g_gene_counter;
        pthread_mutex_unlock(&g_gene_counter_mutex);

        char gff_line[1024];
        snprintf(gff_line, sizeof(gff_line),
                 "%s\tsunfish\tgene\t%d\t%d\t%.2f\t%c\t.\tID=gene%d\n",
                 gene->seq_id, gene->start, gene->end, gene->score,
                 gene->strand, gene_id);
        output_queue_add(&g_output_queue, gff_line);
        char mrna_id[64];
        snprintf(mrna_id, sizeof(mrna_id), "mRNA-gene%d", gene_id);
        snprintf(
            gff_line, sizeof(gff_line),
            "%s\tsunfish\tmRNA\t%d\t%d\t%.2f\t%c\t.\tID=%s;Parent=gene%d\n",
            gene->seq_id, gene->start, gene->end, gene->score, gene->strand,
            mrna_id, gene_id);
        output_queue_add(&g_output_queue, gff_line);
        for (size_t exon_idx = 0; exon_idx < gene->exon_count; exon_idx++) {
          const OutputExon* exon = &gene->exons[exon_idx];
          snprintf(gff_line, sizeof(gff_line),
                   "%s\tsunfish\texon\t%d\t%d\t%.2f\t%c\t.\tID=exon-%s-%zu;"
                   "Parent=%s\n",
                   gene->seq_id, exon->start, exon->end, gene->score,
                   gene->strand, mrna_id, exon_idx + 1, mrna_id);
          output_queue_add(&g_output_queue, gff_line);
          snprintf(gff_line, sizeof(gff_line),
                   "%s\tsunfish\tCDS\t%d\t%d\t%.2f\t%c\t%d\tID=cds%d.%zu;"
                   "Parent=gene%d\n",
                   gene->seq_id, exon->start, exon->end, gene->score,
                   gene->strand, exon->phase, gene_id, exon_idx + 1, gene_id);
          output_queue_add(&g_output_queue, gff_line);
        }
      }
      idx = group_end;
      continue;
    }

    // Fill arrays
    for (size_t j = 0; j < group_count; j++) {
      PredictedGeneRecord* g = order[group_start + j];
      items[j] = g;
      starts[j] = g->start;
      ends[j] = g->end;
      // Weight: combine score and span to prefer confident longer models
      int span = g->end - g->start + 1;
      weights[j] = g->score * (double)span;
      if (weights[j] < 0.0)
        weights[j] = 0.0;
    }

    // For scheduling we need intervals sorted by end; they already are sorted
    // by start then end; create index array and sort by end
    int* order_by_end = (int*)malloc(group_count * sizeof(int));
    for (size_t j = 0; j < group_count; j++)
      order_by_end[j] = (int)j;

    // simple insertion sort for small groups
    for (size_t a = 1; a < group_count; a++) {
      int key = order_by_end[a];
      size_t b = a;
      while (b > 0 && ends[order_by_end[b - 1]] > ends[key]) {
        order_by_end[b] = order_by_end[b - 1];
        b--;
      }
      order_by_end[b] = key;
    }

    // Compute p[j] (the last index before j that doesn't overlap)
    int* p = (int*)malloc(group_count * sizeof(int));
    for (size_t jj = 0; jj < group_count; jj++) {
      int jidx = order_by_end[jj];
      p[jj] = -1;
      for (int kk = (int)jj - 1; kk >= 0; kk--) {
        int kidx = order_by_end[kk];
        if (ends[kidx] < starts[jidx]) { // non-overlapping (exclusive)
          p[jj] = kk;
          break;
        }
      }
    }

    // DP array
    double* M = (double*)calloc(group_count, sizeof(double));
    if (!M) {
      free(starts);
      free(ends);
      free(weights);
      free(items);
      free(order_by_end);
      free(p);
      idx = group_end;
      continue;
    }

    for (size_t jj = 0; jj < group_count; jj++) {
      int jidx = order_by_end[jj];
      double incl = weights[jidx];
      if (p[jj] != -1)
        incl += M[p[jj]];
      double excl = (jj == 0) ? 0.0 : M[jj - 1];
      M[jj] = (incl > excl) ? incl : excl;
    }

    // Reconstruct solution
    bool* take = (bool*)calloc(group_count, sizeof(bool));
    int jj = (int)group_count - 1;
    while (jj >= 0) {
      int jidx = order_by_end[jj];
      double incl = weights[jidx];
      if (p[jj] != -1)
        incl += M[p[jj]];
      double excl = (jj == 0) ? 0.0 : M[jj - 1];
      if (incl > excl) {
        take[jj] = true;
        jj = (p[jj] == -1) ? -1 : p[jj];
      } else {
        take[jj] = false;
        jj--;
      }
    }

    // Emit selected items in genomic order (sort selected by start)
    // Collect selected pointers
    PredictedGeneRecord** selected = (PredictedGeneRecord**)malloc(
        group_count * sizeof(PredictedGeneRecord*));
    size_t sel_count = 0;
    for (size_t jj2 = 0; jj2 < group_count; jj2++) {
      if (take[jj2]) {
        selected[sel_count++] = items[order_by_end[jj2]];
      }
    }

    // sort selected by start (simple insertion since usually small)
    for (size_t a = 1; a < sel_count; a++) {
      PredictedGeneRecord* key = selected[a];
      size_t b = a;
      while (b > 0 && selected[b - 1]->start > key->start) {
        selected[b] = selected[b - 1];
        b--;
      }
      selected[b] = key;
    }

    for (size_t sidx = 0; sidx < sel_count; sidx++) {
      PredictedGeneRecord* gene = selected[sidx];
      if (!gene)
        continue;
      int gene_id = 0;
      pthread_mutex_lock(&g_gene_counter_mutex);
      gene_id = ++g_gene_counter;
      pthread_mutex_unlock(&g_gene_counter_mutex);

      char gff_line[1024];
      snprintf(gff_line, sizeof(gff_line),
               "%s\tsunfish\tgene\t%d\t%d\t%.2f\t%c\t.\tID=gene%d\n",
               gene->seq_id, gene->start, gene->end, gene->score, gene->strand,
               gene_id);
      output_queue_add(&g_output_queue, gff_line);

      char mrna_id[64];
      snprintf(mrna_id, sizeof(mrna_id), "mRNA-gene%d", gene_id);
      snprintf(gff_line, sizeof(gff_line),
               "%s\tsunfish\tmRNA\t%d\t%d\t%.2f\t%c\t.\tID=%s;Parent=gene%d\n",
               gene->seq_id, gene->start, gene->end, gene->score, gene->strand,
               mrna_id, gene_id);
      output_queue_add(&g_output_queue, gff_line);

      for (size_t exon_idx = 0; exon_idx < gene->exon_count; exon_idx++) {
        const OutputExon* exon = &gene->exons[exon_idx];
        snprintf(gff_line, sizeof(gff_line),
                 "%s\tsunfish\texon\t%d\t%d\t%.2f\t%c\t.\tID=exon-%s-%zu;"
                 "Parent=%s\n",
                 gene->seq_id, exon->start, exon->end, gene->score,
                 gene->strand, mrna_id, exon_idx + 1, mrna_id);
        output_queue_add(&g_output_queue, gff_line);

        snprintf(gff_line, sizeof(gff_line),
                 "%s\tsunfish\tCDS\t%d\t%d\t%.2f\t%c\t%d\tID=cds%d.%zu;Parent="
                 "gene%d\n",
                 gene->seq_id, exon->start, exon->end, gene->score,
                 gene->strand, exon->phase, gene_id, exon_idx + 1, gene_id);
        output_queue_add(&g_output_queue, gff_line);
      }
    }

    free(selected);
    free(starts);
    free(ends);
    free(weights);
    free(items);
    free(order_by_end);
    free(p);
    free(M);
    free(take);

    idx = group_end;
  }

  free(order);
  pthread_mutex_unlock(&store->mutex);
}

// Parse command-line wavelet scales argument
static int parse_wavelet_scales(const char* arg, double* scales,
                                int max_scales) {
  int count = 0;
  char* arg_copy = strdup(arg);
  char* token = strtok(arg_copy, ",");

  while (token != NULL && count < max_scales) {
    scales[count++] = atof(token);
    token = strtok(NULL, ",");
  }

  free(arg_copy);
  return count;
}

// Parse range in the form start:end:step and populate scales (up to max_scales)
// Returns number of scales parsed, or -1 on error.
static int parse_wavelet_range(const char* arg, double* scales,
                               int max_scales) {
  if (!arg || !scales || max_scales <= 0)
    return -1;

  // Copy and split by ':'
  char* copy = strdup(arg);
  if (!copy)
    return -1;

  char* saveptr = NULL;
  char* token = strtok_r(copy, ":", &saveptr);
  if (!token) {
    free(copy);
    return -1;
  }
  char* endptr = NULL;
  double start = strtod(token, &endptr);
  if (endptr == token) {
    free(copy);
    return -1;
  }

  token = strtok_r(NULL, ":", &saveptr);
  if (!token) {
    free(copy);
    return -1;
  }
  double endv = strtod(token, &endptr);
  if (endptr == token) {
    free(copy);
    return -1;
  }

  token = strtok_r(NULL, ":", &saveptr);
  if (!token) {
    free(copy);
    return -1;
  }
  double step = strtod(token, &endptr);
  if (endptr == token || step <= 0.0) {
    free(copy);
    return -1;
  }

  int count = 0;
  // Support increasing or decreasing ranges
  if (start <= endv) {
    for (double v = start; v <= endv && count < max_scales; v += step) {
      scales[count++] = v;
    }
  } else {
    for (double v = start; v >= endv && count < max_scales; v -= step) {
      scales[count++] = v;
    }
  }

  free(copy);
  return count;
}

static void free_observation_sequence(double** observations, int seq_len) {
  if (!observations)
    return;

  for (int t = 0; t < seq_len; t++) {
    free(observations[t]);
  }
  free(observations);
}

static bool build_observation_matrix(const char* sequence, int seq_len,
                                     double*** out_observations) {
  if (seq_len <= 0)
    return false;

  int wavelet_feature_rows = g_num_wavelet_scales * 2;
  int num_feature_rows = g_total_feature_count;

  if (wavelet_feature_rows < 0)
    return false;

  if (wavelet_feature_rows != num_feature_rows) {
    // Fallback to recomputing from trusted pieces to avoid mismatches that
    // would otherwise corrupt memory when writing feature rows.
    num_feature_rows = wavelet_feature_rows;
  }

  if (num_feature_rows <= 0 || num_feature_rows > MAX_NUM_FEATURES)
    return false;

  double** features = (double**)malloc(num_feature_rows * sizeof(double*));
  if (!features)
    return false;

  for (int s = 0; s < num_feature_rows; s++) {
    features[s] = (double*)calloc(seq_len, sizeof(double));
    if (!features[s]) {
      for (int j = 0; j < s; j++) {
        free(features[j]);
      }
      free(features);
      return false;
    }
  }

  if (wavelet_feature_rows > 0) {
    if (!compute_cwt_features(sequence, seq_len, g_wavelet_scales,
                              g_num_wavelet_scales, features)) {
      for (int s = 0; s < num_feature_rows; s++) {
        free(features[s]);
      }
      free(features);
      return false;
    }
  }

  double** observations = (double**)malloc(seq_len * sizeof(double*));
  if (!observations) {
    for (int s = 0; s < num_feature_rows; s++) {
      free(features[s]);
    }
    free(features);
    return false;
  }

  for (int t = 0; t < seq_len; t++) {
    observations[t] = (double*)malloc(num_feature_rows * sizeof(double));
    if (!observations[t]) {
      for (int u = 0; u < t; u++) {
        free(observations[u]);
      }
      free(observations);
      for (int s = 0; s < num_feature_rows; s++) {
        free(features[s]);
      }
      free(features);
      return false;
    }

    for (int f = 0; f < num_feature_rows; f++) {
      observations[t][f] = features[f][t];
    }
  }

  for (int s = 0; s < num_feature_rows; s++) {
    free(features[s]);
  }
  free(features);

  *out_observations = observations;
  return true;
}

// Task structure for parallel processing
typedef struct {
  const char* sequence;
  const char* seq_id;
  int seq_len;
  int array_index;
  char strand;
  double*** observations_array;
  int* seq_lengths_array;
  pthread_mutex_t* error_mutex;
  bool* error_flag;
  char* error_message;
  size_t error_message_size;
  int sequence_number;
  // Chunk-specific fields
  int chunk_start; // Start position in original sequence
  int chunk_end;   // End position in original sequence
  bool is_chunk;   // Whether this is a chunk or full sequence
} training_task_t;

typedef struct {
  int genome_index;
  const char* seq_id;
  int seq_len;
  char strand;
  int chunk_start;
  int chunk_end;
  int chunk_index;
  int chunk_count;
  int orientation_start;
  int effective_start;
  int effective_length;
  int state_offset;
} training_segment_meta_t;

typedef struct {
  int* plus_indices;
  int plus_count;
  int plus_capacity;
  int* minus_indices;
  int minus_count;
  int minus_capacity;
} sequence_segment_collection_t;

static training_segment_meta_t* g_training_segment_meta_for_sort = NULL;

static int compare_training_segment_indices(const void* lhs, const void* rhs) {
  const int idx_a = *(const int*)lhs;
  const int idx_b = *(const int*)rhs;

  if (!g_training_segment_meta_for_sort)
    return 0;

  const training_segment_meta_t* meta = g_training_segment_meta_for_sort;
  int start_a = meta[idx_a].orientation_start;
  int start_b = meta[idx_b].orientation_start;

  if (start_a < start_b)
    return -1;
  if (start_a > start_b)
    return 1;
  return 0;
}

static bool append_segment_index(int** array, int* count, int* capacity,
                                 int value) {
  if (!array || !count || !capacity)
    return false;

  if (*count >= *capacity) {
    int new_capacity = (*capacity == 0) ? 8 : (*capacity * 2);
    int* resized = (int*)realloc(*array, new_capacity * sizeof(int));
    if (!resized)
      return false;
    *array = resized;
    *capacity = new_capacity;
  }

  (*array)[(*count)++] = value;
  return true;
}

static void
free_sequence_segment_collections(sequence_segment_collection_t* collections,
                                  int count) {
  if (!collections || count <= 0)
    return;

  for (int i = 0; i < count; i++) {
    free(collections[i].plus_indices);
    free(collections[i].minus_indices);
    collections[i].plus_indices = NULL;
    collections[i].minus_indices = NULL;
    collections[i].plus_count = 0;
    collections[i].minus_count = 0;
    collections[i].plus_capacity = 0;
    collections[i].minus_capacity = 0;
  }
  free(collections);
}

static void training_observation_worker(void* arg) {
  training_task_t* task = (training_task_t*)arg;
  if (task == NULL)
    return;

  const char* sequence = task->sequence;
  char* rc = NULL;
  char* chunk_seq = NULL;
  double** result = NULL;
  bool success = false;

  // Extract chunk if needed
  int effective_len = task->seq_len;
  if (task->is_chunk) {
    effective_len = task->chunk_end - task->chunk_start;
    chunk_seq = (char*)malloc((effective_len + 1) * sizeof(char));
    if (!chunk_seq)
      goto cleanup;
    memcpy(chunk_seq, sequence + task->chunk_start, effective_len);
    chunk_seq[effective_len] = '\0';
    sequence = chunk_seq;
  }

  if (task->strand == '-') {
    rc = reverse_complement(sequence);
    if (!rc)
      goto cleanup;
    sequence = rc;
  }

  if (!build_observation_matrix(sequence, effective_len, &result))
    goto cleanup;

  task->observations_array[task->array_index] = result;
  task->seq_lengths_array[task->array_index] = effective_len;
  success = true;

cleanup:
  if (!success) {
    if (result)
      free_observation_sequence(result, effective_len);

    pthread_mutex_lock(task->error_mutex);
    if (!(*(task->error_flag))) {
      *(task->error_flag) = true;
      if (task->is_chunk) {
        snprintf(task->error_message, task->error_message_size,
                 "Failed to compute feature matrix for chunk [%d-%d] of "
                 "sequence %s (%c strand)",
                 task->chunk_start, task->chunk_end,
                 task->seq_id ? task->seq_id : "(unknown)", task->strand);
      } else {
        snprintf(task->error_message, task->error_message_size,
                 "Failed to compute feature matrix for sequence %s (%c strand, "
                 "index %d)",
                 task->seq_id ? task->seq_id : "(unknown)", task->strand,
                 task->sequence_number);
      }
    }
    pthread_mutex_unlock(task->error_mutex);
  }

  if (rc)
    free(rc);
  if (chunk_seq)
    free(chunk_seq);
  if (!success && task->observations_array[task->array_index] == NULL)
    task->seq_lengths_array[task->array_index] = 0;

  free(task);
}

// Helper function to calculate number of chunks for a sequence
static int calculate_num_chunks(int seq_len, int chunk_size, int overlap) {
  if (!g_use_chunking || seq_len <= chunk_size) {
    return 1; // No chunking needed
  }
  int step = chunk_size - overlap;
  if (step <= 0) {
    return 1; // Invalid configuration, treat as single chunk
  }
  return (seq_len - overlap + step - 1) / step;
}

// Helper function to get chunk boundaries
static void get_chunk_bounds(int seq_len, int chunk_size, int overlap,
                             int chunk_idx, int* start, int* end) {
  if (!g_use_chunking || seq_len <= chunk_size) {
    *start = 0;
    *end = seq_len;
    return;
  }

  int step = chunk_size - overlap;
  *start = chunk_idx * step;
  *end = *start + chunk_size;

  // Adjust last chunk to include remainder
  if (*end > seq_len) {
    *end = seq_len;
  }
}

static void validate_chunk_configuration_or_exit(const char* context) {
  if (!g_use_chunking)
    return;

  if (g_chunk_size <= 0) {
    fprintf(stderr, "Error (%s): chunk size must be greater than zero\n",
            context);
    exit(1);
  }

  if (g_chunk_overlap < 0) {
    fprintf(stderr,
            "Error (%s): chunk overlap must be a non-negative integer\n",
            context);
    exit(1);
  }

  if (g_chunk_overlap >= g_chunk_size) {
    fprintf(
        stderr,
        "Error (%s): chunk overlap (%d) must be smaller than chunk size (%d)\n",
        context, g_chunk_overlap, g_chunk_size);
    exit(1);
  }
}

typedef struct {
  char* sequence;
  char* seq_id;
  char strand;
  HMMModel* model;
  int original_length;
  int chunk_offset; // Offset of this chunk within the full sequence (0-based)
  int chunk_index;  // Index of this chunk within the sequence (0-based)
  int chunk_count;  // Total number of chunks for the originating sequence
} prediction_task_t;

typedef struct {
  int start;
  int end;
  int phase;
} PredictedExon;

static bool is_exon_state(int state) {
  return state == STATE_EXON_F0 || state == STATE_EXON_F1 ||
         state == STATE_EXON_F2;
}

static int exon_state_to_phase(int state) {
  switch (state) {
  case STATE_EXON_F0:
    return 0;
  case STATE_EXON_F1:
    return 1;
  case STATE_EXON_F2:
    return 2;
  default:
    return 0;
  }
}

static void output_predicted_gene(const prediction_task_t* task,
                                  const PredictedExon* exons, size_t exon_count,
                                  int gene_seq_start, int gene_seq_end,
                                  double score, int original_length) {
  if (!task || !exons || exon_count == 0)
    return;

  if (original_length <= 0)
    return;

  if (gene_seq_start < 0 || gene_seq_end < gene_seq_start)
    return;

  const char* seq_id = task->seq_id ? task->seq_id : "(unknown)";
  int output_start = 0;
  int output_end = 0;

  if (task->strand == '+') {
    output_start = gene_seq_start + 1;
    output_end = gene_seq_end + 1;
  } else {
    output_start = original_length - gene_seq_end;
    output_end = original_length - gene_seq_start;
  }

  if (output_start < 1)
    output_start = 1;
  if (output_end < output_start) {
    int tmp = output_start;
    output_start = output_end;
    output_end = tmp;
  }
  if (output_end > original_length)
    output_end = original_length;

  OutputExon* final_exons =
      (OutputExon*)malloc(exon_count * sizeof(OutputExon));
  if (!final_exons)
    return;

  if (task->strand == '+') {
    for (size_t idx = 0; idx < exon_count; idx++) {
      const PredictedExon* exon = &exons[idx];
      int cds_start = exon->start + 1;
      int cds_end = exon->end + 1;
      if (cds_start < 1)
        cds_start = 1;
      if (cds_end > original_length)
        cds_end = original_length;
      if (cds_end < cds_start) {
        int tmp = cds_start;
        cds_start = cds_end;
        cds_end = tmp;
      }

      final_exons[idx].start = cds_start;
      final_exons[idx].end = cds_end;
      final_exons[idx].phase = exons[idx].phase;
    }
  } else {
    size_t out_idx = 0;
    for (size_t reverse_idx = exon_count; reverse_idx-- > 0;) {
      const PredictedExon* exon = &exons[reverse_idx];
      int cds_start = original_length - exon->end;
      int cds_end = original_length - exon->start;
      if (cds_start < 1)
        cds_start = 1;
      if (cds_end > original_length)
        cds_end = original_length;
      if (cds_end < cds_start) {
        int tmp = cds_start;
        cds_start = cds_end;
        cds_end = tmp;
      }
      final_exons[out_idx].start = cds_start;
      final_exons[out_idx].end = cds_end;
      final_exons[out_idx].phase = exon->phase;
      out_idx++;
    }
  }

  if (!predicted_gene_store_add(&g_predicted_gene_store, seq_id, task->strand,
                                output_start, output_end, score, final_exons,
                                exon_count)) {
    free(final_exons);
  }
}

// Validate ORF: check start codon, stop codon, in-frame stops, and length
static bool is_valid_orf(const char* cds_sequence) {
  // FOR DEBUGGING PURPOSE ONLY; FIXME
  return true;

  if (!cds_sequence) {
    return false;
  }

  size_t len = strlen(cds_sequence);

  // Check length is multiple of 3
  if (len < 3 || len % 3 != 0) {
    return false;
  }

  // Check starts with ATG
  if (toupper((unsigned char)cds_sequence[0]) != 'A' ||
      toupper((unsigned char)cds_sequence[1]) != 'T' ||
      toupper((unsigned char)cds_sequence[2]) != 'G') {
    return false;
  }

  // Check internal codons for in-frame stop codons
  for (size_t i = 3; i < len - 3; i += 3) {
    char codon[4];
    codon[0] = toupper((unsigned char)cds_sequence[i]);
    codon[1] = toupper((unsigned char)cds_sequence[i + 1]);
    codon[2] = toupper((unsigned char)cds_sequence[i + 2]);
    codon[3] = '\0';

    // Check for stop codons: TAA, TAG, TGA
    if ((strcmp(codon, "TAA") == 0) || (strcmp(codon, "TAG") == 0) ||
        (strcmp(codon, "TGA") == 0)) {
      return false; // Internal stop codon
    }
  }

  // Check ends with stop codon
  size_t last_codon_start = len - 3;
  char last_codon[4];
  last_codon[0] = toupper((unsigned char)cds_sequence[last_codon_start]);
  last_codon[1] = toupper((unsigned char)cds_sequence[last_codon_start + 1]);
  last_codon[2] = toupper((unsigned char)cds_sequence[last_codon_start + 2]);
  last_codon[3] = '\0';

  if (strcmp(last_codon, "TAA") != 0 && strcmp(last_codon, "TAG") != 0 &&
      strcmp(last_codon, "TGA") != 0) {
    return false; // No stop codon at end
  }

  return true;
}

// Worker function for parallel prediction
static void predict_sequence_worker(void* arg) {
  prediction_task_t* task = (prediction_task_t*)arg;
  if (!task)
    return;

  double** observations = NULL;
  int* states = NULL;
  PredictedExon* exon_buffer = NULL;
  size_t exon_capacity = 0;
  size_t exon_count = 0;
  int seq_len = 0;
  const char* seq_id = task->seq_id ? task->seq_id : "(unknown)";
  const int chunk_offset = (task->chunk_offset >= 0) ? task->chunk_offset : 0;

  if (!task->sequence)
    goto cleanup;

  seq_len = strlen(task->sequence);
  if (seq_len <= 0)
    goto cleanup;

  if (!build_observation_matrix(task->sequence, seq_len, &observations)) {
    fprintf(stderr,
            "Warning: Failed to compute feature matrix for %s (%c strand)\n",
            seq_id, task->strand);
    goto cleanup;
  }

  // Apply Z-score normalization using global statistics from the model
  int norm_count = task->model->num_features;
  if (norm_count < 0)
    norm_count = 0;
  if (norm_count > task->model->num_features)
    norm_count = task->model->num_features;

  for (int t = 0; t < seq_len; t++) {
    for (int f = 0; f < norm_count; f++) {
      double raw_val = observations[t][f];
      double stddev = task->model->global_feature_stddev[f];
      if (!isfinite(stddev) || stddev < 1e-6)
        stddev = 1e-6; // floor to avoid divide-by-zero or extreme scaling
      double normalized_val =
          (raw_val - task->model->global_feature_mean[f]) / stddev;
      observations[t][f] = normalized_val;
    }
  }

  states = (int*)malloc(seq_len * sizeof(int));
  if (!states) {
    fprintf(stderr,
            "Warning: Failed to allocate state buffer for %s (%c strand)\n",
            seq_id, task->strand);
    goto cleanup;
  }

  double log_prob =
      hmm_viterbi(task->model, observations, task->sequence, seq_len, states);
  double normalized_log_prob = (seq_len > 0) ? (log_prob / seq_len) : log_prob;
  double prediction_score = 0.0;
  if (isfinite(normalized_log_prob)) {
    if (normalized_log_prob <= -700.0) {
      prediction_score = 0.0;
    } else if (normalized_log_prob >= 700.0) {
      prediction_score = 1.0;
    } else {
      prediction_score = exp(normalized_log_prob);
      if (!isfinite(prediction_score))
        prediction_score = 0.0;
      else if (prediction_score > 1.0)
        prediction_score = 1.0;
      else if (prediction_score < 0.0)
        prediction_score = 0.0;
    }
  }
  const int original_length =
      (task->original_length > 0) ? task->original_length : seq_len;

  exon_capacity = 8;
  exon_buffer = (PredictedExon*)malloc(exon_capacity * sizeof(PredictedExon));
  if (!exon_buffer) {
    fprintf(stderr,
            "Warning: Failed to allocate exon buffer for %s (%c strand)\n",
            seq_id, task->strand);
    goto cleanup;
  }

  bool gene_active = false;
  int current_exon_start = -1;
  int gene_seq_start = -1;
  int gene_seq_end = -1;

  for (int i = 0; i < seq_len; i++) {
    int state = states[i];
    bool exon_state = is_exon_state(state);
    bool intron_state = (state == STATE_INTRON);

    if (!gene_active) {
      if (exon_state) {
        gene_active = true;
        gene_seq_start = i;
        gene_seq_end = i;
        exon_count = 0;
        current_exon_start = i;
      }
      continue;
    }

    if (exon_state) {
      if (current_exon_start == -1)
        current_exon_start = i;
      gene_seq_end = i;
      continue;
    }

    if (current_exon_start != -1) {
      int exon_end = i - 1;
      if (exon_end < current_exon_start)
        exon_end = current_exon_start;

      if (exon_count >= exon_capacity) {
        size_t new_capacity = exon_capacity * 2;
        PredictedExon* tmp = (PredictedExon*)realloc(
            exon_buffer, new_capacity * sizeof(PredictedExon));
        if (!tmp) {
          fprintf(stderr,
                  "Warning: Failed to expand exon buffer for %s (%c strand)\n",
                  seq_id, task->strand);
          goto cleanup;
        }
        exon_buffer = tmp;
        exon_capacity = new_capacity;
      }

      exon_buffer[exon_count].start = current_exon_start;
      exon_buffer[exon_count].end = exon_end;
      exon_buffer[exon_count].phase =
          exon_state_to_phase(states[current_exon_start]);
      exon_count++;

      current_exon_start = -1;
      gene_seq_end = exon_end;
    }

    if (!intron_state) {
      if (exon_count > 0 && gene_seq_start >= 0 &&
          gene_seq_end >= gene_seq_start) {
        // Assemble CDS sequence from exons for validation
        size_t cds_len = 0;
        for (size_t e = 0; e < exon_count; e++) {
          cds_len += (exon_buffer[e].end - exon_buffer[e].start + 1);
        }

        char* cds_seq = (char*)malloc(cds_len + 1);
        if (cds_seq) {
          size_t pos = 0;
          for (size_t e = 0; e < exon_count; e++) {
            int exon_len = exon_buffer[e].end - exon_buffer[e].start + 1;
            memcpy(cds_seq + pos, task->sequence + exon_buffer[e].start,
                   exon_len);
            pos += exon_len;
          }
          cds_seq[cds_len] = '\0';

          // Validate ORF before outputting
          int global_gene_start = gene_seq_start + chunk_offset;
          int global_gene_end = gene_seq_end + chunk_offset;
          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start += chunk_offset;
            exon_buffer[e].end += chunk_offset;
          }

          if (is_valid_orf(cds_seq)) {
            output_predicted_gene(task, exon_buffer, exon_count,
                                  global_gene_start, global_gene_end,
                                  prediction_score, original_length);
          }

          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start -= chunk_offset;
            exon_buffer[e].end -= chunk_offset;
          }
          free(cds_seq);
        } else {
          // Memory allocation failed, output without validation
          int global_gene_start = gene_seq_start + chunk_offset;
          int global_gene_end = gene_seq_end + chunk_offset;
          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start += chunk_offset;
            exon_buffer[e].end += chunk_offset;
          }
          output_predicted_gene(task, exon_buffer, exon_count,
                                global_gene_start, global_gene_end,
                                prediction_score, original_length);
          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start -= chunk_offset;
            exon_buffer[e].end -= chunk_offset;
          }
        }
      }

      gene_active = false;
      gene_seq_start = -1;
      gene_seq_end = -1;
      exon_count = 0;
      current_exon_start = -1;
    }
  }

  if (current_exon_start != -1) {
    int exon_end = seq_len - 1;
    if (exon_count >= exon_capacity) {
      size_t new_capacity = exon_capacity * 2;
      PredictedExon* tmp = (PredictedExon*)realloc(
          exon_buffer, new_capacity * sizeof(PredictedExon));
      if (!tmp) {
        fprintf(stderr,
                "Warning: Failed to expand exon buffer for %s (%c strand)\n",
                seq_id, task->strand);
        goto cleanup;
      }
      exon_buffer = tmp;
      exon_capacity = new_capacity;
    }

    exon_buffer[exon_count].start = current_exon_start;
    exon_buffer[exon_count].end = exon_end;
    exon_buffer[exon_count].phase =
        exon_state_to_phase(states[current_exon_start]);
    exon_count++;
    gene_seq_end = exon_end;
    current_exon_start = -1;
  }

  if (gene_active && exon_count > 0 && gene_seq_start >= 0 &&
      gene_seq_end >= gene_seq_start) {
    // Assemble CDS sequence from exons for validation
    size_t cds_len = 0;
    for (size_t e = 0; e < exon_count; e++) {
      cds_len += (exon_buffer[e].end - exon_buffer[e].start + 1);
    }

    char* cds_seq = (char*)malloc(cds_len + 1);
    if (cds_seq) {
      size_t pos = 0;
      for (size_t e = 0; e < exon_count; e++) {
        int exon_len = exon_buffer[e].end - exon_buffer[e].start + 1;
        memcpy(cds_seq + pos, task->sequence + exon_buffer[e].start, exon_len);
        pos += exon_len;
      }
      cds_seq[cds_len] = '\0';

      // Validate ORF before outputting
      int global_gene_start = gene_seq_start + chunk_offset;
      int global_gene_end = gene_seq_end + chunk_offset;
      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start += chunk_offset;
        exon_buffer[e].end += chunk_offset;
      }

      if (is_valid_orf(cds_seq)) {
        output_predicted_gene(task, exon_buffer, exon_count, global_gene_start,
                              global_gene_end, prediction_score,
                              original_length);
      }

      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start -= chunk_offset;
        exon_buffer[e].end -= chunk_offset;
      }
      free(cds_seq);
    } else {
      // Memory allocation failed, output without validation
      int global_gene_start = gene_seq_start + chunk_offset;
      int global_gene_end = gene_seq_end + chunk_offset;
      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start += chunk_offset;
        exon_buffer[e].end += chunk_offset;
      }
      output_predicted_gene(task, exon_buffer, exon_count, global_gene_start,
                            global_gene_end, prediction_score, original_length);
      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start -= chunk_offset;
        exon_buffer[e].end -= chunk_offset;
      }
    }
  }

cleanup:
  if (exon_buffer)
    free(exon_buffer);
  if (states)
    free(states);
  if (observations)
    free_observation_sequence(observations, seq_len);
  free(task->sequence);
  free(task->seq_id);
  free(task);
}

// Training mode: Baum-Welch HMM training
static void print_help(const char* progname) {
  printf("Sunfish HMM-based Gene Annotation Tool\n\n");
  printf("Usage:\n");
  printf("  %s <command> [options]\n\n", progname);
  printf("Commands:\n");
  printf("  help                         Show this help message\n"
         "  train <train.fasta> <train.gff> [--wavelet|-w S1,S2,...|s:e:step]"
         " [--threads|-t N] [--chunk-size N] [--chunk-overlap M]"
         "\n"
         "  predict <target.fasta> [--threads|-t N]\n\n");
  printf("Options:\n");
  printf("  -h, --help                   Show this help message\n");
  printf(
      "  --wavelet, -w               Comma-separated list (a,b,c) or range "
      "s:e:step\n"
      "  --threads, -t N             Number of worker threads (default: auto-"
      "detected)\n"
      "  --chunk-size N              Chunk size in bases for long sequences\n"
      "  --chunk-overlap M           Overlap size in bases between chunks\n\n");
  printf("Examples:\n");
  printf("  %s train data.fa data.gff --wavelet 3,9,81\n", progname);
  printf("  %s predict genome.fa --threads 8 > predictions.gff3\n\n", progname);
}

static void initialize_state_labels(int* labels, int len) {
  if (!labels || len <= 0)
    return;

  for (int i = 0; i < len; i++) {
    labels[i] = STATE_INTERGENIC;
  }
}

static HMMState frame_to_state(int frame) {
  int normalized = frame % 3;
  if (normalized < 0)
    normalized += 3;

  switch (normalized) {
  case 0:
    return STATE_EXON_F0;
  case 1:
    return STATE_EXON_F1;
  default:
    return STATE_EXON_F2;
  }
}

static int normalize_phase(int phase) {
  if (phase < 0)
    return 0;
  return phase % 3;
}

static int compare_exon_start(const void* lhs, const void* rhs) {
  const Exon* a = (const Exon*)lhs;
  const Exon* b = (const Exon*)rhs;

  if (a->start < b->start)
    return -1;
  if (a->start > b->start)
    return 1;
  if (a->end < b->end)
    return -1;
  if (a->end > b->end)
    return 1;
  return 0;
}

static void sort_group_exons(CdsGroup* group) {
  if (!group || group->exon_count <= 1 || group->exons == NULL)
    return;

  qsort(group->exons, group->exon_count, sizeof(Exon), compare_exon_start);
}

typedef struct {
  int start;
  int end;
  int phase;
} RcExon;

static int compare_rc_exon_start(const void* lhs, const void* rhs) {
  const RcExon* a = (const RcExon*)lhs;
  const RcExon* b = (const RcExon*)rhs;

  if (a->start < b->start)
    return -1;
  if (a->start > b->start)
    return 1;
  if (a->end < b->end)
    return -1;
  if (a->end > b->end)
    return 1;
  return 0;
}

static void label_forward_states(const CdsGroup* groups, int group_count,
                                 const char* seq_id, int seq_len,
                                 int* state_labels) {
  if (!groups || group_count <= 0 || !seq_id || !state_labels || seq_len <= 0)
    return;

  for (int g = 0; g < group_count; g++) {
    const CdsGroup* group = &groups[g];
    if (!group || group->exon_count == 0 || group->exons == NULL)
      continue;

    bool has_forward_exon = false;
    for (int e = 0; e < group->exon_count; e++) {
      const Exon* exon = &group->exons[e];
      if (exon->strand != '+')
        continue;
      if (strcmp(exon->seqid, seq_id) == 0) {
        has_forward_exon = true;
        break;
      }
    }
    if (!has_forward_exon)
      continue;

    for (int e = 0; e < group->exon_count; e++) {
      const Exon* exon = &group->exons[e];
      if (exon->strand != '+' || strcmp(exon->seqid, seq_id) != 0)
        continue;

      int start = exon->start - 1;
      int end_exclusive = exon->end;

      if (end_exclusive <= 0)
        continue;

      if (start < 0)
        start = 0;
      if (start >= seq_len)
        continue;

      if (end_exclusive > seq_len)
        end_exclusive = seq_len;
      if (start >= end_exclusive)
        continue;

      int phase = normalize_phase(exon->phase);

      for (int pos = start; pos < end_exclusive; pos++) {
        int offset = pos - start;
        HMMState state = frame_to_state(phase + offset);
        state_labels[pos] = state;
      }

      if (e < group->exon_count - 1) {
        const Exon* next = &group->exons[e + 1];
        if (next->strand != '+' || strcmp(next->seqid, seq_id) != 0)
          continue;

        int intron_start = end_exclusive;
        int intron_end_exclusive = next->start - 1;

        if (intron_end_exclusive <= intron_start)
          continue;

        if (intron_start < 0)
          intron_start = 0;
        if (intron_end_exclusive > seq_len)
          intron_end_exclusive = seq_len;

        for (int pos = intron_start;
             pos < intron_end_exclusive && pos < seq_len; pos++) {
          if (pos >= 0 && state_labels[pos] == STATE_INTERGENIC)
            state_labels[pos] = STATE_INTRON;
        }
      }
    }
  }
}

static void label_reverse_states(const CdsGroup* groups, int group_count,
                                 const char* seq_id, int seq_len,
                                 int* state_labels) {
  if (!groups || group_count <= 0 || !seq_id || !state_labels || seq_len <= 0)
    return;

  for (int g = 0; g < group_count; g++) {
    const CdsGroup* group = &groups[g];
    if (!group || group->exon_count == 0 || group->exons == NULL)
      continue;

    int valid_count = 0;
    RcExon* rc_exons = (RcExon*)malloc(group->exon_count * sizeof(RcExon));
    if (!rc_exons)
      continue;

    for (int e = 0; e < group->exon_count; e++) {
      const Exon* exon = &group->exons[e];
      if (exon->strand != '-' || strcmp(exon->seqid, seq_id) != 0)
        continue;

      int start0 = exon->start - 1;
      int end0 = exon->end - 1;

      if (end0 < 0 || start0 >= seq_len)
        continue;

      if (start0 < 0)
        start0 = 0;
      if (end0 >= seq_len)
        end0 = seq_len - 1;
      if (start0 > end0)
        continue;

      int rc_start = seq_len - 1 - end0;
      int rc_end = seq_len - 1 - start0;

      if (rc_start < 0)
        rc_start = 0;
      if (rc_end >= seq_len)
        rc_end = seq_len - 1;
      if (rc_start > rc_end)
        continue;

      int phase = normalize_phase(exon->phase);

      rc_exons[valid_count].start = rc_start;
      rc_exons[valid_count].end = rc_end;
      rc_exons[valid_count].phase = phase;
      valid_count++;
    }

    if (valid_count == 0) {
      free(rc_exons);
      continue;
    }

    qsort(rc_exons, valid_count, sizeof(RcExon), compare_rc_exon_start);

    for (int e = 0; e < valid_count; e++) {
      RcExon* rc = &rc_exons[e];
      for (int pos = rc->start; pos <= rc->end && pos < seq_len; pos++) {
        if (pos < 0)
          continue;
        int offset = rc->end - pos;
        HMMState state = frame_to_state(rc->phase + offset);
        state_labels[pos] = state;
      }
    }

    for (int e = 0; e < valid_count - 1; e++) {
      int intron_start = rc_exons[e].end + 1;
      int intron_end_exclusive = rc_exons[e + 1].start;

      if (intron_end_exclusive <= intron_start)
        continue;

      if (intron_start < 0)
        intron_start = 0;
      if (intron_end_exclusive > seq_len)
        intron_end_exclusive = seq_len;

      for (int pos = intron_start; pos < intron_end_exclusive && pos < seq_len;
           pos++) {
        if (pos >= 0 && state_labels[pos] == STATE_INTERGENIC)
          state_labels[pos] = STATE_INTRON;
      }
    }

    free(rc_exons);
  }
}

static void normalize_observations_in_place(double*** observations,
                                            const int* seq_lengths,
                                            int total_sequences,
                                            const HMMModel* model) {
  if (!observations || !seq_lengths || !model)
    return;

  for (int seq = 0; seq < total_sequences; seq++) {
    double** seq_obs = observations[seq];
    int len = seq_lengths[seq];

    if (!seq_obs || len <= 0)
      continue;

    for (int t = 0; t < len; t++) {
      double* feature_vec = seq_obs[t];
      if (!feature_vec)
        continue;

      int feature_count = model->num_features;
      if (feature_count > MAX_NUM_FEATURES)
        feature_count = MAX_NUM_FEATURES;

      for (int f = 0; f < feature_count; f++) {
        double stddev = model->global_feature_stddev[f];
        if (stddev < 1e-10)
          stddev = 1e-10;
        feature_vec[f] =
            (feature_vec[f] - model->global_feature_mean[f]) / stddev;
      }
    }
  }
}

static void accumulate_statistics_for_segment(
    const HMMModel* model, double** observations, int obs_len,
    const int* state_labels,
    long long transition_counts[NUM_STATES][NUM_STATES],
    double emission_sum[NUM_STATES][MAX_NUM_FEATURES],
    double emission_sum_sq[NUM_STATES][MAX_NUM_FEATURES],
    long long state_observation_counts[NUM_STATES],
    long long initial_counts[NUM_STATES]) {
  if (!model || !observations || !state_labels || obs_len <= 0)
    return;

  int num_features = model->num_features;
  if (num_features > MAX_NUM_FEATURES)
    num_features = MAX_NUM_FEATURES;

  for (int t = 0; t < obs_len; t++) {
    int state = state_labels[t];
    if (state < 0 || state >= NUM_STATES)
      state = STATE_INTERGENIC;

    if (t == 0)
      initial_counts[state]++;

    if (t < obs_len - 1) {
      int next_state = state_labels[t + 1];
      if (next_state < 0 || next_state >= NUM_STATES)
        next_state = STATE_INTERGENIC;
      transition_counts[state][next_state]++;
    }

    double* feature_vec = observations[t];
    if (!feature_vec)
      continue;

    for (int f = 0; f < num_features; f++) {
      double normalized_val = feature_vec[f];
      emission_sum[state][f] += normalized_val;
      emission_sum_sq[state][f] += normalized_val * normalized_val;
    }
    state_observation_counts[state]++;
  }
}

// Helper structure for collecting duration statistics
typedef struct {
  double* log_durations; // Array of log(duration) values
  int count;             // Number of observations
  int capacity;          // Allocated capacity
} DurationStats;

static void
accumulate_duration_statistics(int seq_len, const int* state_labels,
                               DurationStats duration_stats[NUM_STATES]) {
  if (!state_labels || !duration_stats || seq_len <= 0)
    return;

  int segment_start = 0;
  int current_state = state_labels[0];
  bool current_is_exon = is_exon_state(current_state);

  for (int t = 1; t <= seq_len; t++) {
    int next_state = (t < seq_len) ? state_labels[t] : -1;
    bool next_is_exon = is_exon_state(next_state);

    bool segment_ends = false;
    if (current_is_exon) {
      segment_ends = (t == seq_len) || !next_is_exon;
    } else {
      segment_ends = (t == seq_len) || (next_state != current_state);
    }

    if (segment_ends) {
      int duration = t - segment_start;
      int target_state = current_is_exon ? STATE_EXON_F0 : current_state;

      if (target_state >= 0 && target_state < NUM_STATES && duration > 0) {
        DurationStats* stats = &duration_stats[target_state];

        // Expand array if needed
        if (stats->count >= stats->capacity) {
          int new_capacity = stats->capacity * 2;
          if (new_capacity < 16)
            new_capacity = 16;

          double* new_array = (double*)realloc(stats->log_durations,
                                               new_capacity * sizeof(double));

          if (new_array) {
            stats->log_durations = new_array;
            stats->capacity = new_capacity;
          }
        }

        if (stats->count < stats->capacity) {
          stats->log_durations[stats->count] = log((double)duration);
          stats->count++;
        }
      }

      if (t < seq_len) {
        segment_start = t;
        current_state = state_labels[t];
        current_is_exon = is_exon_state(current_state);
      }
    }
  }
}

static void enforce_exon_cycle_constraints(HMMModel* model) {
  if (!model)
    return;

  const HMMState exon_cycle[] = {STATE_EXON_F0, STATE_EXON_F1, STATE_EXON_F2};
  const size_t exon_cycle_len = sizeof(exon_cycle) / sizeof(exon_cycle[0]);

  for (size_t idx = 0; idx < exon_cycle_len; idx++) {
    HMMState state = exon_cycle[idx];
    HMMState expected_next = exon_cycle[(idx + 1) % exon_cycle_len];
    int row = (int)state;

    double exon_transition_mass = 0.0;
    for (size_t target_idx = 0; target_idx < exon_cycle_len; target_idx++) {
      HMMState exon_target = exon_cycle[target_idx];
      exon_transition_mass += model->transition[row][(int)exon_target];
    }
    if (exon_transition_mass < 1e-10)
      exon_transition_mass = 1e-10;

    model->transition[row][(int)expected_next] = exon_transition_mass;
    for (size_t target_idx = 0; target_idx < exon_cycle_len; target_idx++) {
      HMMState exon_target = exon_cycle[target_idx];
      if (exon_target == expected_next)
        continue;
      model->transition[row][(int)exon_target] = 1e-10;
    }

    for (int col = 0; col < NUM_STATES; col++) {
      if (!is_exon_state(col) && model->transition[row][col] < 1e-10)
        model->transition[row][col] = 1e-10;
    }

    double row_sum = 0.0;
    for (int col = 0; col < NUM_STATES; col++) {
      row_sum += model->transition[row][col];
    }

    if (row_sum <= 0.0) {
      for (int col = 0; col < NUM_STATES; col++) {
        model->transition[row][col] = (col == (int)expected_next) ? 1.0 : 1e-10;
      }
      row_sum = 0.0;
      for (int col = 0; col < NUM_STATES; col++) {
        row_sum += model->transition[row][col];
      }
    }

    for (int col = 0; col < NUM_STATES; col++) {
      model->transition[row][col] /= row_sum;
    }
  }
}

// Helper function to convert base character to index (A=0, C=1, G=2, T=3)
static int base_to_index(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 0;
  case 'C':
    return 1;
  case 'G':
    return 2;
  case 'T':
    return 3;
  default:
    return -1; // Invalid base
  }
}

// Train splice site PWM model from annotated data
static SplicePWM* train_splice_model(const FastaData* genome,
                                     const CdsGroup* groups, int group_count) {
  if (!genome || !groups || group_count <= 0) {
    return NULL;
  }

  // Allocate and initialize counts structure
  SpliceCounts* counts = (SpliceCounts*)calloc(1, sizeof(SpliceCounts));
  if (!counts) {
    return NULL;
  }

  // Iterate through all CDS groups to find donor and acceptor sites
  for (int g = 0; g < group_count; g++) {
    const CdsGroup* group = &groups[g];
    if (group->exon_count < 1) {
      continue;
    }

    // Find the sequence this group belongs to
    const char* seqid = group->exons[0].seqid;
    const FastaRecord* record = NULL;
    for (int i = 0; i < genome->count; i++) {
      if (strcmp(genome->records[i].id, seqid) == 0) {
        record = &genome->records[i];
        break;
      }
    }
    if (!record || !record->sequence) {
      continue;
    }

    const char* seq = record->sequence;
    int seq_len = strlen(seq);
    char strand = group->exons[0].strand;

    // Process each adjacent exon pair to find splice sites
    for (int e = 0; e < group->exon_count - 1; e++) {
      const Exon* exon1 = &group->exons[e];
      const Exon* exon2 = &group->exons[e + 1];

      if (strand == '+') {
        // Donor site: at the end of exon1 (exon-intron boundary)
        // Extract sequence centered around the boundary
        int donor_center = exon1->end; // GFF is 1-based, end is inclusive
        int donor_start = donor_center - DONOR_MOTIF_SIZE / 2;

        if (donor_start >= 0 && donor_start + DONOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
            int idx = base_to_index(seq[donor_start + pos]);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->donor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_donor_sites++;
          }
        }

        // Acceptor site: at the start of exon2 (intron-exon boundary)
        int acceptor_center = exon2->start - 1; // Convert to 0-based
        int acceptor_start = acceptor_center - ACCEPTOR_MOTIF_SIZE / 2;

        if (acceptor_start >= 0 &&
            acceptor_start + ACCEPTOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
            int idx = base_to_index(seq[acceptor_start + pos]);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->acceptor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_acceptor_sites++;
          }
        }
      } else if (strand == '-') {
        // For reverse strand, donor/acceptor are reversed
        // Donor site: at the start of exon1 (actually acceptor in genomic
        // coords)
        int donor_center = exon1->start - 1; // Convert to 0-based
        int donor_start = donor_center - DONOR_MOTIF_SIZE / 2;

        if (donor_start >= 0 && donor_start + DONOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          // Extract and reverse complement
          char motif[DONOR_MOTIF_SIZE + 1];
          for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
            motif[pos] = seq[donor_start + DONOR_MOTIF_SIZE - 1 - pos];
          }
          motif[DONOR_MOTIF_SIZE] = '\0';

          // Apply reverse complement
          for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
            char base = motif[pos];
            char rc_base;
            switch (toupper((unsigned char)base)) {
            case 'A':
              rc_base = 'T';
              break;
            case 'T':
              rc_base = 'A';
              break;
            case 'G':
              rc_base = 'C';
              break;
            case 'C':
              rc_base = 'G';
              break;
            default:
              rc_base = 'N';
              break;
            }

            int idx = base_to_index(rc_base);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->donor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_donor_sites++;
          }
        }

        // Acceptor site: at the end of exon2
        int acceptor_center = exon2->end;
        int acceptor_start = acceptor_center - ACCEPTOR_MOTIF_SIZE / 2;

        if (acceptor_start >= 0 &&
            acceptor_start + ACCEPTOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          // Extract and reverse complement
          char motif[ACCEPTOR_MOTIF_SIZE + 1];
          for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
            motif[pos] = seq[acceptor_start + ACCEPTOR_MOTIF_SIZE - 1 - pos];
          }
          motif[ACCEPTOR_MOTIF_SIZE] = '\0';

          // Apply reverse complement
          for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
            char base = motif[pos];
            char rc_base;
            switch (toupper((unsigned char)base)) {
            case 'A':
              rc_base = 'T';
              break;
            case 'T':
              rc_base = 'A';
              break;
            case 'G':
              rc_base = 'C';
              break;
            case 'C':
              rc_base = 'G';
              break;
            default:
              rc_base = 'N';
              break;
            }

            int idx = base_to_index(rc_base);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->acceptor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_acceptor_sites++;
          }
        }
      }
    }
  }

  // Convert counts to log-odds PWM
  SplicePWM* pwm = (SplicePWM*)calloc(1, sizeof(SplicePWM));
  if (!pwm) {
    free(counts);
    return NULL;
  }

  // Background frequencies (assume uniform)
  double bg_freq = 0.25;
  double pseudocount = 1.0;

  // Calculate donor PWM
  pwm->min_donor_score = 0.0;
  for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
    double position_sum = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      position_sum += counts->donor_counts[base][pos] + pseudocount;
    }

    double min_log_odds = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      double freq =
          (counts->donor_counts[base][pos] + pseudocount) / position_sum;
      double log_odds = log(freq / bg_freq);
      pwm->donor_pwm[base][pos] = log_odds;
      if (log_odds < min_log_odds) {
        min_log_odds = log_odds;
      }
    }
    pwm->min_donor_score += min_log_odds;
  }

  // Calculate acceptor PWM
  pwm->min_acceptor_score = 0.0;
  for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
    double position_sum = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      position_sum += counts->acceptor_counts[base][pos] + pseudocount;
    }

    double min_log_odds = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      double freq =
          (counts->acceptor_counts[base][pos] + pseudocount) / position_sum;
      double log_odds = log(freq / bg_freq);
      pwm->acceptor_pwm[base][pos] = log_odds;
      if (log_odds < min_log_odds) {
        min_log_odds = log_odds;
      }
    }
    pwm->min_acceptor_score += min_log_odds;
  }

  fprintf(stderr,
          "Trained splice PWM from %d donor sites and %d acceptor sites\n",
          counts->total_donor_sites, counts->total_acceptor_sites);

  free(counts);
  return pwm;
}

static void handle_train(int argc, char* argv[]) {
  if (argc < 4) {
    fprintf(stderr,
            "Usage: %s train <train.fasta> <train.gff> [--wavelet|-w "
            "S1,S2,...|s:e:step] [--threads|-t N] [--chunk-size N]"
            " [--chunk-overlap M]\n",
            argv[0]);
    exit(1);
  }

  const char* fasta_path = argv[2];
  const char* gff_path = argv[3];

  // Parse optional arguments
  bool threads_specified = false;
  for (int i = 4; i < argc; i++) {
    if ((strcmp(argv[i], "--wavelet") == 0 || strcmp(argv[i], "-w") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires an argument\n", argv[i]);
        exit(1);
      }
      const char* arg = argv[++i];
      // If argument contains ':' treat as range start:end:step
      if (strchr(arg, ':')) {
        int parsed =
            parse_wavelet_range(arg, g_wavelet_scales, MAX_NUM_WAVELETS);
        if (parsed < 0) {
          fprintf(stderr, "Error: Invalid wavelet range '%s'\n", arg);
          exit(1);
        }
        g_num_wavelet_scales = parsed;
        fprintf(stderr, "Using %d wavelet scales (range)\n",
                g_num_wavelet_scales);
      } else if (strchr(arg, ',')) {
        g_num_wavelet_scales =
            parse_wavelet_scales(arg, g_wavelet_scales, MAX_NUM_WAVELETS);
        fprintf(stderr, "Using %d wavelet scales (list)\n",
                g_num_wavelet_scales);
      } else {
        // Single numeric value
        double v = atof(arg);
        if (v <= 0.0) {
          fprintf(stderr, "Error: Invalid wavelet scale '%s'\n", arg);
          exit(1);
        }
        g_wavelet_scales[0] = v;
        g_num_wavelet_scales = 1;
        fprintf(stderr, "Using single wavelet scale %.2f\n", v);
      }
    } else if ((strcmp(argv[i], "--threads") == 0 ||
                strcmp(argv[i], "-t") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int parsed_threads = parse_threads_value(argv[++i]);
      if (parsed_threads < 0) {
        fprintf(stderr, "Error: Invalid thread count '%s'\n", argv[i]);
        exit(1);
      }
      g_num_threads = parsed_threads;
      threads_specified = true;
    } else if (strcmp(argv[i], "--chunk-size") == 0) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int value = 0;
      if (!parse_non_negative_int(argv[++i], &value) || value <= 0) {
        fprintf(stderr, "Error: Invalid chunk size '%s'\n", argv[i]);
        exit(1);
      }
      g_chunk_size = value;
      g_use_chunking = true;
    } else if (strcmp(argv[i], "--chunk-overlap") == 0) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a non-negative integer\n", argv[i]);
        exit(1);
      }
      int value = 0;
      if (!parse_non_negative_int(argv[++i], &value)) {
        fprintf(stderr, "Error: Invalid chunk overlap '%s'\n", argv[i]);
        exit(1);
      }
      g_chunk_overlap = value;
      g_use_chunking = true;
    }
  }

  validate_chunk_configuration_or_exit("train");

  if (!update_feature_counts()) {
    fprintf(stderr,
            "Error: Total feature dimensionality exceeds supported maximum "
            "(%d). Adjust wavelet settings.\n",
            MAX_NUM_FEATURES);
    exit(1);
  }

  fprintf(stderr, "Feature configuration: %d wavelet dims = %d total\n",
          g_num_wavelet_scales * 2, g_total_feature_count);

  ensure_thread_count("training", threads_specified);

  // Load training data
  FastaData* genome = parse_fasta(fasta_path);
  if (!genome) {
    fprintf(stderr, "Failed to load FASTA file\n");
    exit(1);
  }
  fprintf(stderr, "Loaded %d sequences\n", genome->count);

  int group_count;
  CdsGroup* groups = parse_gff_for_cds(gff_path, &group_count);
  if (!groups) {
    fprintf(stderr, "Failed to load GFF3 file\n");
    free_fasta_data(genome);
    exit(1);
  }
  fprintf(stderr, "Loaded %d CDS groups\n", group_count);

  for (int i = 0; i < group_count; i++) {
    sort_group_exons(&groups[i]);
  }

  // Extract observation sequences from CDS regions using chunked processing
  int total_segments = 0;
  for (int i = 0; i < genome->count; i++) {
    const char* seq = genome->records[i].sequence;
    if (!seq)
      continue;
    int seq_len = strlen(seq);
    if (seq_len <= 0)
      continue;

    int chunk_count =
        calculate_num_chunks(seq_len, g_chunk_size, g_chunk_overlap);
    if (chunk_count < 1)
      chunk_count = 1;
    total_segments += chunk_count * 2;
  }

  if (total_segments <= 0) {
    fprintf(stderr,
            "No valid sequences found for training after chunk partitioning\n");
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  double*** observations = (double***)malloc(total_segments * sizeof(double**));
  int* seq_lengths = (int*)malloc(total_segments * sizeof(int));
  training_segment_meta_t* segment_meta = (training_segment_meta_t*)calloc(
      total_segments, sizeof(training_segment_meta_t));
  sequence_segment_collection_t* segment_collections =
      (sequence_segment_collection_t*)calloc(
          genome->count, sizeof(sequence_segment_collection_t));

  if (!observations || !seq_lengths || !segment_meta || !segment_collections) {
    fprintf(stderr, "Failed to allocate buffers for training observations\n");
    free(observations);
    free(seq_lengths);
    free(segment_meta);
    if (segment_collections)
      free_sequence_segment_collections(segment_collections, genome->count);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  for (int i = 0; i < total_segments; i++) {
    observations[i] = NULL;
    seq_lengths[i] = 0;
  }

  fprintf(stderr,
          "Augmenting training data with reverse complements (%d total "
          "segments)\n",
          total_segments);
  fprintf(stderr,
          "Computing wavelet feature matrices for training sequences "
          "using up to %d threads...\n",
          g_num_threads);

  thread_pool_t* pool = thread_pool_create(g_num_threads);
  if (pool == NULL) {
    fprintf(stderr, "Failed to create thread pool for training\n");
    free(observations);
    free(seq_lengths);
    free(segment_meta);
    free_sequence_segment_collections(segment_collections, genome->count);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  pthread_mutex_t error_mutex;
  if (pthread_mutex_init(&error_mutex, NULL) != 0) {
    fprintf(stderr, "Failed to initialize training mutex\n");
    thread_pool_destroy(pool);
    free(observations);
    free(seq_lengths);
    free(segment_meta);
    free_sequence_segment_collections(segment_collections, genome->count);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  bool worker_error = false;
  char error_message[256] = {0};
  bool scheduling_failed = false;
  int segment_idx = 0;

  for (int i = 0; i < genome->count && !scheduling_failed; i++) {
    const char* seq = genome->records[i].sequence;
    const char* seq_id = genome->records[i].id;
    if (!seq)
      continue;
    int seq_len = strlen(seq);
    if (seq_len <= 0)
      continue;

    int chunk_count =
        calculate_num_chunks(seq_len, g_chunk_size, g_chunk_overlap);
    if (chunk_count < 1)
      chunk_count = 1;

    for (int chunk_idx = 0; chunk_idx < chunk_count; chunk_idx++) {
      int chunk_start = 0;
      int chunk_end = 0;
      get_chunk_bounds(seq_len, g_chunk_size, g_chunk_overlap, chunk_idx,
                       &chunk_start, &chunk_end);
      if (chunk_end <= chunk_start)
        continue;
      int chunk_len = chunk_end - chunk_start;

      if (segment_idx + 2 > total_segments) {
        scheduling_failed = true;
        snprintf(error_message, sizeof(error_message),
                 "Internal error: segment index overflow during scheduling");
        break;
      }

      training_segment_meta_t* forward_meta = &segment_meta[segment_idx];
      forward_meta->genome_index = i;
      forward_meta->seq_id = seq_id;
      forward_meta->seq_len = seq_len;
      forward_meta->strand = '+';
      forward_meta->chunk_start = chunk_start;
      forward_meta->chunk_end = chunk_end;
      forward_meta->chunk_index = chunk_idx;
      forward_meta->chunk_count = chunk_count;
      forward_meta->orientation_start = chunk_start;
      forward_meta->effective_start = chunk_start;
      forward_meta->effective_length = chunk_len;
      forward_meta->state_offset = chunk_start;

      if (!append_segment_index(&segment_collections[i].plus_indices,
                                &segment_collections[i].plus_count,
                                &segment_collections[i].plus_capacity,
                                segment_idx)) {
        pthread_mutex_lock(&error_mutex);
        if (!worker_error) {
          worker_error = true;
          snprintf(
              error_message, sizeof(error_message),
              "Failed to track training segment metadata for %s (+ strand)",
              seq_id ? seq_id : "(unknown)");
        }
        pthread_mutex_unlock(&error_mutex);
        scheduling_failed = true;
        break;
      }

      training_task_t* forward_task =
          (training_task_t*)malloc(sizeof(training_task_t));
      if (!forward_task) {
        pthread_mutex_lock(&error_mutex);
        if (!worker_error) {
          worker_error = true;
          snprintf(
              error_message, sizeof(error_message),
              "Failed to allocate training task for %s (+ strand chunk %d)",
              seq_id ? seq_id : "(unknown)", chunk_idx + 1);
        }
        pthread_mutex_unlock(&error_mutex);
        scheduling_failed = true;
        break;
      }

      memset(forward_task, 0, sizeof(training_task_t));
      forward_task->sequence = seq;
      forward_task->seq_id = seq_id;
      forward_task->seq_len = seq_len;
      forward_task->array_index = segment_idx;
      forward_task->strand = '+';
      forward_task->observations_array = observations;
      forward_task->seq_lengths_array = seq_lengths;
      forward_task->error_mutex = &error_mutex;
      forward_task->error_flag = &worker_error;
      forward_task->error_message = error_message;
      forward_task->error_message_size = sizeof(error_message);
      forward_task->sequence_number = i + 1;
      forward_task->chunk_start = chunk_start;
      forward_task->chunk_end = chunk_end;
      forward_task->is_chunk = (chunk_count > 1);

      if (!thread_pool_add_task(pool, training_observation_worker,
                                forward_task)) {
        pthread_mutex_lock(&error_mutex);
        if (!worker_error) {
          worker_error = true;
          snprintf(error_message, sizeof(error_message),
                   "Failed to enqueue training task for %s (+ strand chunk %d)",
                   seq_id ? seq_id : "(unknown)", chunk_idx + 1);
        }
        pthread_mutex_unlock(&error_mutex);
        free(forward_task);
        scheduling_failed = true;
        break;
      }

      segment_idx++;

      training_segment_meta_t* reverse_meta = &segment_meta[segment_idx];
      reverse_meta->genome_index = i;
      reverse_meta->seq_id = seq_id;
      reverse_meta->seq_len = seq_len;
      reverse_meta->strand = '-';
      reverse_meta->chunk_start = chunk_start;
      reverse_meta->chunk_end = chunk_end;
      reverse_meta->chunk_index = chunk_idx;
      reverse_meta->chunk_count = chunk_count;
      reverse_meta->orientation_start = seq_len - chunk_end;
      if (reverse_meta->orientation_start < 0)
        reverse_meta->orientation_start = 0;
      reverse_meta->effective_start = reverse_meta->orientation_start;
      reverse_meta->effective_length = chunk_len;
      reverse_meta->state_offset = reverse_meta->orientation_start;

      if (!append_segment_index(&segment_collections[i].minus_indices,
                                &segment_collections[i].minus_count,
                                &segment_collections[i].minus_capacity,
                                segment_idx)) {
        pthread_mutex_lock(&error_mutex);
        if (!worker_error) {
          worker_error = true;
          snprintf(
              error_message, sizeof(error_message),
              "Failed to track training segment metadata for %s (- strand)",
              seq_id ? seq_id : "(unknown)");
        }
        pthread_mutex_unlock(&error_mutex);
        scheduling_failed = true;
        break;
      }

      training_task_t* reverse_task =
          (training_task_t*)malloc(sizeof(training_task_t));
      if (!reverse_task) {
        pthread_mutex_lock(&error_mutex);
        if (!worker_error) {
          worker_error = true;
          snprintf(
              error_message, sizeof(error_message),
              "Failed to allocate training task for %s (- strand chunk %d)",
              seq_id ? seq_id : "(unknown)", chunk_idx + 1);
        }
        pthread_mutex_unlock(&error_mutex);
        scheduling_failed = true;
        break;
      }

      memset(reverse_task, 0, sizeof(training_task_t));
      reverse_task->sequence = seq;
      reverse_task->seq_id = seq_id;
      reverse_task->seq_len = seq_len;
      reverse_task->array_index = segment_idx;
      reverse_task->strand = '-';
      reverse_task->observations_array = observations;
      reverse_task->seq_lengths_array = seq_lengths;
      reverse_task->error_mutex = &error_mutex;
      reverse_task->error_flag = &worker_error;
      reverse_task->error_message = error_message;
      reverse_task->error_message_size = sizeof(error_message);
      reverse_task->sequence_number = i + 1;
      reverse_task->chunk_start = chunk_start;
      reverse_task->chunk_end = chunk_end;
      reverse_task->is_chunk = (chunk_count > 1);

      if (!thread_pool_add_task(pool, training_observation_worker,
                                reverse_task)) {
        pthread_mutex_lock(&error_mutex);
        if (!worker_error) {
          worker_error = true;
          snprintf(error_message, sizeof(error_message),
                   "Failed to enqueue training task for %s (- strand chunk %d)",
                   seq_id ? seq_id : "(unknown)", chunk_idx + 1);
        }
        pthread_mutex_unlock(&error_mutex);
        free(reverse_task);
        scheduling_failed = true;
        break;
      }

      segment_idx++;
    }
  }

  thread_pool_wait(pool);
  thread_pool_destroy(pool);
  pthread_mutex_destroy(&error_mutex);

  if (segment_idx < total_segments)
    total_segments = segment_idx;

  if (worker_error || scheduling_failed) {
    fprintf(stderr, "%s\n",
            error_message[0] ? error_message
                             : "Failed to prepare training observations");
    for (int i = 0; i < total_segments; i++) {
      if (observations[i]) {
        free_observation_sequence(observations[i], seq_lengths[i]);
      }
    }
    free(observations);
    free(seq_lengths);
    free(segment_meta);
    free_sequence_segment_collections(segment_collections, genome->count);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  for (int seq_idx = 0; seq_idx < genome->count; seq_idx++) {
    const char* seq = genome->records[seq_idx].sequence;
    if (!seq)
      continue;
    int seq_len = strlen(seq);
    if (seq_len <= 0)
      continue;

    sequence_segment_collection_t* coll = &segment_collections[seq_idx];

    if (coll->plus_count > 1) {
      g_training_segment_meta_for_sort = segment_meta;
      qsort(coll->plus_indices, coll->plus_count, sizeof(int),
            compare_training_segment_indices);
    }
    for (int idx = 0; idx < coll->plus_count; idx++) {
      int seg_index = coll->plus_indices[idx];
      training_segment_meta_t* meta = &segment_meta[seg_index];
      int start = meta->orientation_start;
      int len = seq_lengths[seg_index];
      int next_start =
          (idx + 1 < coll->plus_count)
              ? segment_meta[coll->plus_indices[idx + 1]].orientation_start
              : seq_len;
      if (next_start > start + len)
        next_start = start + len;
      if (next_start < start)
        next_start = start;
      meta->effective_start = start;
      meta->effective_length = next_start - start;
      meta->state_offset = start;
    }

    if (coll->minus_count > 1) {
      g_training_segment_meta_for_sort = segment_meta;
      qsort(coll->minus_indices, coll->minus_count, sizeof(int),
            compare_training_segment_indices);
    }
    for (int idx = 0; idx < coll->minus_count; idx++) {
      int seg_index = coll->minus_indices[idx];
      training_segment_meta_t* meta = &segment_meta[seg_index];
      int start = meta->orientation_start;
      int len = seq_lengths[seg_index];
      int next_start =
          (idx + 1 < coll->minus_count)
              ? segment_meta[coll->minus_indices[idx + 1]].orientation_start
              : seq_len;
      if (next_start > start + len)
        next_start = start + len;
      if (next_start < start)
        next_start = start;
      meta->effective_start = start;
      meta->effective_length = next_start - start;
      meta->state_offset = start;
    }
  }

  for (int idx = 0; idx < total_segments; idx++) {
    training_segment_meta_t* meta = &segment_meta[idx];
    double** chunk_obs = observations[idx];
    int chunk_len = seq_lengths[idx];

    if (!chunk_obs || chunk_len <= 0) {
      seq_lengths[idx] = 0;
      continue;
    }

    int orientation_start = meta->orientation_start;
    int start_offset = meta->effective_start - orientation_start;
    if (start_offset < 0)
      start_offset = 0;

    int effective_len = meta->effective_length;
    if (start_offset >= chunk_len)
      effective_len = 0;
    if (start_offset + effective_len > chunk_len)
      effective_len = chunk_len - start_offset;
    if (effective_len <= 0) {
      for (int t = 0; t < chunk_len; t++) {
        free(chunk_obs[t]);
      }
      free(chunk_obs);
      observations[idx] = NULL;
      seq_lengths[idx] = 0;
      continue;
    }

    if (start_offset == 0 && effective_len == chunk_len) {
      seq_lengths[idx] = effective_len;
      continue;
    }

    double** trimmed = (double**)malloc(effective_len * sizeof(double*));
    if (!trimmed) {
      fprintf(stderr,
              "Warning: Failed to trim chunked observations for segment %d; "
              "using full chunk\n",
              idx);
      seq_lengths[idx] = chunk_len;
      continue;
    }

    for (int t = 0; t < effective_len; t++) {
      trimmed[t] = chunk_obs[start_offset + t];
    }

    for (int t = 0; t < start_offset; t++) {
      free(chunk_obs[t]);
    }
    for (int t = start_offset + effective_len; t < chunk_len; t++) {
      free(chunk_obs[t]);
    }
    free(chunk_obs);

    observations[idx] = trimmed;
    seq_lengths[idx] = effective_len;
  }

  int usable_segments = 0;
  for (int i = 0; i < total_segments; i++) {
    if (observations[i] && seq_lengths[i] > 0)
      usable_segments++;
  }

  fprintf(stderr,
          "Computed feature matrices (%d dims) for %d training segments\n",
          g_total_feature_count, usable_segments);

  // Initialize HMM model
  HMMModel model;
  hmm_init(&model, g_total_feature_count);
  model.wavelet_feature_count = g_num_wavelet_scales * 2;

  fprintf(stderr, "Starting supervised training with two passes...\n");

  // =========================================================================
  // PASS 1: Calculate global statistics for Z-score normalization
  // =========================================================================
  fprintf(stderr, "Pass 1: Computing global feature statistics...\n");

  double sum[MAX_NUM_FEATURES] = {0};
  double sum_sq[MAX_NUM_FEATURES] = {0};
  long long total_count = 0;

  int global_num_features = model.num_features;
  if (global_num_features > MAX_NUM_FEATURES)
    global_num_features = MAX_NUM_FEATURES;

  for (int seg_idx = 0; seg_idx < total_segments; seg_idx++) {
    if (!observations[seg_idx] || seq_lengths[seg_idx] == 0) {
      continue;
    }

    int seq_len = seq_lengths[seg_idx];
    for (int t = 0; t < seq_len; t++) {
      for (int f = 0; f < global_num_features; f++) {
        double val = observations[seg_idx][t][f];
        sum[f] += val;
        sum_sq[f] += val * val;
      }
      total_count++;
    }
  }

  // Calculate mean and standard deviation
  for (int f = 0; f < global_num_features; f++) {
    model.global_feature_mean[f] = sum[f] / total_count;
    double variance =
        (sum_sq[f] / total_count) -
        (model.global_feature_mean[f] * model.global_feature_mean[f]);
    model.global_feature_stddev[f] = sqrt(variance > 1e-10 ? variance : 1e-10);
  }

  fprintf(stderr, "Global statistics computed from %lld observations\n",
          total_count);

  fprintf(stderr,
          "Applying Z-score normalization to training observations...\n");
  normalize_observations_in_place(observations, seq_lengths, total_segments,
                                  &model);

  // =========================================================================
  // PASS 2: Supervised parameter estimation using GFF annotations
  // =========================================================================
  fprintf(stderr, "Pass 2: Learning HMM parameters from annotations...\n");

  // Initialize accumulators
  long long transition_counts[NUM_STATES][NUM_STATES] = {{0}};
  double emission_sum[NUM_STATES][MAX_NUM_FEATURES] = {{0}};
  double emission_sum_sq[NUM_STATES][MAX_NUM_FEATURES] = {{0}};
  long long state_observation_counts[NUM_STATES] = {0};
  long long initial_counts[NUM_STATES] = {0};

  // Process each sequence to accumulate statistics
  for (int seq_idx = 0; seq_idx < genome->count; seq_idx++) {
    const char* seq_id = genome->records[seq_idx].id;
    const char* seq = genome->records[seq_idx].sequence;
    if (!seq)
      continue;
    int seq_len = strlen(seq);
    if (seq_len <= 0)
      continue;

    int* state_labels = (int*)malloc(seq_len * sizeof(int));
    if (!state_labels) {
      fprintf(stderr, "Warning: Failed to allocate state labels for %s\n",
              seq_id);
      continue;
    }

    sequence_segment_collection_t* coll = &segment_collections[seq_idx];

    bool has_forward_segments = false;
    for (int idx = 0; idx < coll->plus_count; idx++) {
      int seg_index = coll->plus_indices[idx];
      if (seg_index >= total_segments)
        continue;
      if (observations[seg_index] && seq_lengths[seg_index] > 0) {
        has_forward_segments = true;
        break;
      }
    }

    if (has_forward_segments) {
      initialize_state_labels(state_labels, seq_len);
      label_forward_states(groups, group_count, seq_id, seq_len, state_labels);

      for (int idx = 0; idx < coll->plus_count; idx++) {
        int seg_index = coll->plus_indices[idx];
        if (seg_index >= total_segments)
          continue;
        if (!observations[seg_index] || seq_lengths[seg_index] <= 0)
          continue;

        int offset = segment_meta[seg_index].state_offset;
        if (offset < 0 || offset >= seq_len)
          continue;
        if (offset + seq_lengths[seg_index] > seq_len)
          continue;

        const int* labels_ptr = state_labels + offset;
        accumulate_statistics_for_segment(
            &model, observations[seg_index], seq_lengths[seg_index], labels_ptr,
            transition_counts, emission_sum, emission_sum_sq,
            state_observation_counts, initial_counts);
      }
    }

    bool has_reverse_segments = false;
    for (int idx = 0; idx < coll->minus_count; idx++) {
      int seg_index = coll->minus_indices[idx];
      if (seg_index >= total_segments)
        continue;
      if (observations[seg_index] && seq_lengths[seg_index] > 0) {
        has_reverse_segments = true;
        break;
      }
    }

    if (has_reverse_segments) {
      initialize_state_labels(state_labels, seq_len);
      label_reverse_states(groups, group_count, seq_id, seq_len, state_labels);

      for (int idx = 0; idx < coll->minus_count; idx++) {
        int seg_index = coll->minus_indices[idx];
        if (seg_index >= total_segments)
          continue;
        if (!observations[seg_index] || seq_lengths[seg_index] <= 0)
          continue;

        int offset = segment_meta[seg_index].state_offset;
        if (offset < 0 || offset >= seq_len)
          continue;
        if (offset + seq_lengths[seg_index] > seq_len)
          continue;

        const int* labels_ptr = state_labels + offset;
        accumulate_statistics_for_segment(
            &model, observations[seg_index], seq_lengths[seg_index], labels_ptr,
            transition_counts, emission_sum, emission_sum_sq,
            state_observation_counts, initial_counts);
      }
    }

    free(state_labels);
  }

  fprintf(stderr, "Finalizing HMM parameters...\n");

  // Finalize initial probabilities
  long long total_initial = 0;
  for (int i = 0; i < NUM_STATES; i++) {
    total_initial += initial_counts[i];
  }
  for (int i = 0; i < NUM_STATES; i++) {
    if (total_initial > 0) {
      model.initial[i] = (double)initial_counts[i] / total_initial;
    } else {
      model.initial[i] = 1.0 / NUM_STATES;
    }
    // Ensure minimum probability
    if (model.initial[i] < 1e-10) {
      model.initial[i] = 1e-10;
    }
  }

  // Finalize transition probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    long long row_sum = 0;
    for (int j = 0; j < NUM_STATES; j++) {
      row_sum += transition_counts[i][j];
    }

    for (int j = 0; j < NUM_STATES; j++) {
      if (row_sum > 0) {
        model.transition[i][j] = (double)transition_counts[i][j] / row_sum;
      } else {
        model.transition[i][j] = 1.0 / NUM_STATES;
      }
      // Ensure minimum probability
      if (model.transition[i][j] < 1e-10) {
        model.transition[i][j] = 1e-10;
      }
    }
  }

  // Finalize emission parameters (mean and variance)
  int num_features = model.num_features;
  if (num_features > MAX_NUM_FEATURES)
    num_features = MAX_NUM_FEATURES;
  for (int i = 0; i < NUM_STATES; i++) {
    model.emission[i].num_features = num_features;

    for (int f = 0; f < num_features; f++) {
      if (state_observation_counts[i] > 0) {
        double mean = emission_sum[i][f] / state_observation_counts[i];
        double mean_sq = emission_sum_sq[i][f] / state_observation_counts[i];
        double variance = mean_sq - mean * mean;

        /* Assign to component 0 and create a small perturbed component 1 */
        model.emission[i].mean[0][f] = mean;
        model.emission[i].variance[0][f] = (variance > 1e-6) ? variance : 1e-6;
        model.emission[i].mean[1][f] = mean + 0.1;
        model.emission[i].variance[1][f] =
            model.emission[i].variance[0][f] + 0.1;
        model.emission[i].weight[0] = 0.5;
        model.emission[i].weight[1] = 0.5;
      } else {
        /* Defaults for both components */
        model.emission[i].mean[0][f] = 0.0;
        model.emission[i].variance[0][f] = 1.0;
        model.emission[i].mean[1][f] = 0.1;
        model.emission[i].variance[1][f] = 1.1;
        model.emission[i].weight[0] = 0.5;
        model.emission[i].weight[1] = 0.5;
      }
    }

    fprintf(stderr, "State %d: %lld observations\n", i,
            state_observation_counts[i]);
  }

  // =========================================================================
  // Calculate duration statistics for HSMM
  // =========================================================================
  fprintf(stderr, "Calculating duration statistics for HSMM...\n");

  // Initialize duration statistics collectors
  DurationStats duration_stats[NUM_STATES];
  for (int i = 0; i < NUM_STATES; i++) {
    duration_stats[i].log_durations = NULL;
    duration_stats[i].count = 0;
    duration_stats[i].capacity = 0;
  }

  // Collect duration statistics from all sequences
  for (int seq_idx = 0; seq_idx < genome->count; seq_idx++) {
    const char* seq_id = genome->records[seq_idx].id;
    const char* seq = genome->records[seq_idx].sequence;
    if (!seq)
      continue;
    int seq_len = strlen(seq);
    if (seq_len <= 0)
      continue;

    int* state_labels = (int*)malloc(seq_len * sizeof(int));
    if (!state_labels) {
      fprintf(stderr,
              "Warning: Failed to allocate state labels for duration stats\n");
      continue;
    }

    sequence_segment_collection_t* coll = &segment_collections[seq_idx];

    bool forward_available = false;
    for (int idx = 0; idx < coll->plus_count; idx++) {
      int seg_index = coll->plus_indices[idx];
      if (seg_index >= total_segments)
        continue;
      if (observations[seg_index] && seq_lengths[seg_index] > 0) {
        forward_available = true;
        break;
      }
    }

    if (forward_available) {
      initialize_state_labels(state_labels, seq_len);
      label_forward_states(groups, group_count, seq_id, seq_len, state_labels);
      accumulate_duration_statistics(seq_len, state_labels, duration_stats);
    }

    bool reverse_available = false;
    for (int idx = 0; idx < coll->minus_count; idx++) {
      int seg_index = coll->minus_indices[idx];
      if (seg_index >= total_segments)
        continue;
      if (observations[seg_index] && seq_lengths[seg_index] > 0) {
        reverse_available = true;
        break;
      }
    }

    if (reverse_available) {
      initialize_state_labels(state_labels, seq_len);
      label_reverse_states(groups, group_count, seq_id, seq_len, state_labels);
      accumulate_duration_statistics(seq_len, state_labels, duration_stats);
    }

    free(state_labels);
  }

  // Diagnostic: compute combined exon spans treating states 0/1/2 as one unit
  double combined_exon_log_sum = 0.0;
  double combined_exon_log_sum_sq = 0.0;
  int combined_exon_count = 0;
  for (int g = 0; g < group_count; g++) {
    const CdsGroup* group = &groups[g];
    if (!group || group->exon_count <= 0 || !group->exons)
      continue;

    for (int e = 0; e < group->exon_count; e++) {
      const Exon* exon = &group->exons[e];
      int span = exon->end - exon->start + 1;
      if (span <= 0)
        continue;

      double log_span = log((double)span);
      combined_exon_log_sum += log_span;
      combined_exon_log_sum_sq += log_span * log_span;
      combined_exon_count++;
    }
  }

  if (combined_exon_count > 0) {
    double mean_log_span = combined_exon_log_sum / combined_exon_count;
    double stddev_log_span = 1.0;
    if (combined_exon_count > 1) {
      double variance = (combined_exon_log_sum_sq -
                         (combined_exon_log_sum * combined_exon_log_sum) /
                             combined_exon_count) /
                        (combined_exon_count - 1);
      if (variance < 1e-6)
        variance = 1e-6;
      stddev_log_span = sqrt(variance);
    }

    double mean_span_bp = exp(mean_log_span);
    fprintf(stderr,
            "Combined exon spans (012 grouped): %d segments, mean_log=%.4f, "
            "stddev_log=%.4f, mean_length≈%.1f bp\n",
            combined_exon_count, mean_log_span, stddev_log_span, mean_span_bp);
  } else {
    fprintf(stderr,
            "Combined exon spans (012 grouped): No exon annotations found for "
            "span diagnostics\n");
  }

  // Pre-compute shared exon duration statistics (states 0, 1, 2)
  const HMMState exon_states[] = {STATE_EXON_F0, STATE_EXON_F1, STATE_EXON_F2};
  double exon_sum = 0.0;
  double exon_sum_sq = 0.0;
  int exon_count = 0;

  for (size_t idx = 0; idx < sizeof(exon_states) / sizeof(exon_states[0]);
       idx++) {
    int state = (int)exon_states[idx];
    for (int j = 0; j < duration_stats[state].count; j++) {
      double log_d = duration_stats[state].log_durations[j];
      exon_sum += log_d;
      exon_sum_sq += log_d * log_d;
    }
    exon_count += duration_stats[state].count;
  }

  double exon_mean = 0.0;
  double exon_stddev = 1.0;
  bool exon_has_data = exon_count > 0;
  if (exon_has_data) {
    exon_mean = exon_sum / exon_count;
    if (exon_count > 1) {
      double variance =
          (exon_sum_sq - (exon_sum * exon_sum) / exon_count) / (exon_count - 1);
      if (variance < 1e-6)
        variance = 1e-6;
      exon_stddev = sqrt(variance);
    } else {
      exon_stddev = 1.0;
    }
  }

  // Compute mean and stddev of log-durations for each state
  for (int i = 0; i < NUM_STATES; i++) {
    bool is_exon_state =
        (i == STATE_EXON_F0 || i == STATE_EXON_F1 || i == STATE_EXON_F2);

    if (is_exon_state) {
      if (exon_has_data) {
        model.duration[i].mean_log_duration = exon_mean;
        model.duration[i].stddev_log_duration = exon_stddev;

        if (i == STATE_EXON_F0) {
          fprintf(stderr,
                  "States 0/1/2 (exon): %d duration segments combined, "
                  "mean_log=%.4f, stddev_log=%.4f (per-frame segments)\n",
                  exon_count, exon_mean, exon_stddev);
        } else {
          fprintf(stderr,
                  "State %d (exon): sharing shared exon duration parameters\n",
                  i);
        }
      } else {
        model.duration[i].mean_log_duration = 0.0;
        model.duration[i].stddev_log_duration = 1.0;

        if (i == STATE_EXON_F0) {
          fprintf(stderr, "States 0/1/2 (exon): No duration segments observed, "
                          "using defaults\n");
        } else {
          fprintf(stderr,
                  "State %d (exon): sharing default exon duration parameters\n",
                  i);
        }
      }
    } else if (duration_stats[i].count > 0) {
      // Calculate mean for non-exon state
      double sum = 0.0;
      for (int j = 0; j < duration_stats[i].count; j++) {
        sum += duration_stats[i].log_durations[j];
      }
      double mean = sum / duration_stats[i].count;

      // Calculate standard deviation
      double sum_sq = 0.0;
      for (int j = 0; j < duration_stats[i].count; j++) {
        double diff = duration_stats[i].log_durations[j] - mean;
        sum_sq += diff * diff;
      }

      double stddev = 1.0; // default
      if (duration_stats[i].count > 1) {
        double variance = sum_sq / (duration_stats[i].count - 1);
        stddev = sqrt(variance > 1e-6 ? variance : 1e-6);
      }

      model.duration[i].mean_log_duration = mean;
      model.duration[i].stddev_log_duration = stddev;

      fprintf(
          stderr,
          "State %d: %d duration segments, mean_log=%.4f, stddev_log=%.4f\n", i,
          duration_stats[i].count, mean, stddev);
    } else {
      // No segments observed for non-exon state, use defaults
      model.duration[i].mean_log_duration = 0.0;
      model.duration[i].stddev_log_duration = 1.0;
      fprintf(stderr,
              "State %d: No duration segments observed, using defaults\n", i);
    }

    // Free duration statistics
    if (duration_stats[i].log_durations) {
      free(duration_stats[i].log_durations);
    }
  }

  // Ensure duration parameters are identical across exon reading frames
  model.duration[STATE_EXON_F1] = model.duration[STATE_EXON_F0];
  model.duration[STATE_EXON_F2] = model.duration[STATE_EXON_F0];

  enforce_exon_cycle_constraints(&model);

  fprintf(stderr, "Supervised training complete.\n");

  // Train splice site PWM model
  fprintf(stderr, "Training splice site PWM model...\n");
  SplicePWM* splice_pwm = train_splice_model(genome, groups, group_count);
  if (splice_pwm) {
    fprintf(
        stderr,
        "Splice PWM training complete (min donor=%.3f, min acceptor=%.3f)\n",
        splice_pwm->min_donor_score, splice_pwm->min_acceptor_score);

    // Store PWM in model for use during prediction
    model.pwm.has_donor = 1;
    model.pwm.has_acceptor = 1;
    model.pwm.pwm_weight = 1.0;
    model.pwm.min_donor_score = splice_pwm->min_donor_score;
    model.pwm.min_acceptor_score = splice_pwm->min_acceptor_score;

    // Copy PWM matrices
    for (int i = 0; i < NUM_NUCLEOTIDES; i++) {
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        model.pwm.donor_pwm[i][j] = splice_pwm->donor_pwm[i][j];
      }
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        model.pwm.acceptor_pwm[i][j] = splice_pwm->acceptor_pwm[i][j];
      }
    }

    free(splice_pwm);
    fprintf(stderr, "PWM integrated into model.\n");
  } else {
    fprintf(stderr, "Warning: Failed to train splice PWM model\n");
  }

  const int kBaumWelchMaxIterations = 50; // FIXME
  const double kBaumWelchThreshold = 10.0;

  fprintf(
      stderr,
      "Starting Baum-Welch refinement on %d segments (semi-supervised)...\n",
      total_segments);
  if (!hmm_train_baum_welch(&model, observations, seq_lengths, total_segments,
                            kBaumWelchMaxIterations, kBaumWelchThreshold)) {
    fprintf(stderr, "Baum-Welch refinement failed\n");
    exit(1);
  }
  enforce_exon_cycle_constraints(&model);
  fprintf(stderr, "Baum-Welch refinement complete.\n");

  // Save model
  // Store chunking metadata into model before saving
  model.chunk_size = g_chunk_size;
  model.chunk_overlap = g_chunk_overlap;
  model.use_chunking = g_use_chunking ? 1 : 0;

  // Store wavelet scales used for training so prediction can reuse them
  model.num_wavelet_scales = g_num_wavelet_scales;
  for (int i = 0; i < g_num_wavelet_scales && i < MAX_NUM_WAVELETS; i++) {
    model.wavelet_scales[i] = g_wavelet_scales[i];
  }

  if (!hmm_save_model(&model, "sunfish.model")) {
    fprintf(stderr, "Failed to save model\n");
    exit(1);
  }
  fprintf(stderr, "Model saved to sunfish.model\n");

  // Cleanup
  for (int i = 0; i < total_segments; i++) {
    if (observations[i]) {
      free_observation_sequence(observations[i], seq_lengths[i]);
    }
  }
  free(observations);
  free(seq_lengths);
  free(segment_meta);
  free_sequence_segment_collections(segment_collections, genome->count);

  free_cds_groups(groups, group_count);
  free_fasta_data(genome);
}

// Prediction mode: Parallel Viterbi prediction
static void handle_predict(int argc, char* argv[]) {
  if (argc < 3) {
    fprintf(stderr, "Usage: %s predict <target.fasta> [--threads|-t N]\n",
            argv[0]);
    fprintf(stderr, "       (threads auto-detected when omitted; override via "
                    "SUNFISH_THREADS/OMP_NUM_THREADS)\n");
    exit(1);
  }

  const char* fasta_path = argv[2];

  bool threads_specified = false;
  for (int i = 3; i < argc; i++) {
    if ((strcmp(argv[i], "--threads") == 0 || strcmp(argv[i], "-t") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int parsed_threads = parse_threads_value(argv[++i]);
      if (parsed_threads < 0) {
        fprintf(stderr, "Error: Invalid thread count '%s'\n", argv[i]);
        exit(1);
      }
      g_num_threads = parsed_threads;
      threads_specified = true;
    } else {
      fprintf(stderr,
              "Error: Unknown or unsupported option '%s' for predict. "
              "Predict uses parameters stored in the model file.\n",
              argv[i]);
      exit(1);
    }
  }

  ensure_thread_count("prediction", threads_specified);

  // Load HMM model
  HMMModel model;
  if (!hmm_load_model(&model, "sunfish.model")) {
    fprintf(stderr, "Failed to load model. Run 'train' first.\n");
    exit(1);
  }
  fprintf(stderr, "Loaded HMM model with %d features\n", model.num_features);

  // Enforce training parameters from model for predict to ensure parity
  // Wavelet scales
  if (model.num_wavelet_scales > 0) {
    g_num_wavelet_scales = model.num_wavelet_scales;
    for (int i = 0; i < g_num_wavelet_scales && i < MAX_NUM_WAVELETS; i++)
      g_wavelet_scales[i] = model.wavelet_scales[i];
    fprintf(stderr, "Using wavelet scales from model (%d scales)\n",
            g_num_wavelet_scales);
  }

  // Chunking settings
  // Restore chunking parameters saved in the model. Even if the model's
  // `use_chunking` flag is 0, prefer to honor an explicit chunk_size saved
  // during training: use it to split long sequences for parallel
  // prediction and subsequent merge. This helps reproduce training-time
  // segmentation behavior and avoids memory blowups on very long contigs.
  if (model.chunk_size > 0) {
    g_chunk_size = model.chunk_size;
    g_chunk_overlap =
        (model.chunk_overlap >= 0) ? model.chunk_overlap : g_chunk_overlap;
    g_use_chunking = true;
    if (model.use_chunking)
      fprintf(stderr, "Using chunking from model: size=%d overlap=%d\n",
              g_chunk_size, g_chunk_overlap);
    else
      fprintf(stderr,
              "Model contains chunking metadata (size=%d overlap=%d); forcing "
              "chunked prediction to match training\n",
              g_chunk_size, g_chunk_overlap);
  } else {
    // No explicit chunk size in model: fall back to model's use_chunking flag
    g_chunk_size = model.chunk_size > 0 ? model.chunk_size : g_chunk_size;
    g_chunk_overlap =
        model.chunk_overlap >= 0 ? model.chunk_overlap : g_chunk_overlap;
    g_use_chunking = model.use_chunking ? true : false;
    if (g_use_chunking) {
      fprintf(stderr, "Using chunking from model: size=%d overlap=%d\n",
              g_chunk_size, g_chunk_overlap);
    } else {
      fprintf(stderr, "Chunking disabled by model settings\n");
    }
  }

  validate_chunk_configuration_or_exit("predict");

  if (!update_feature_counts()) {
    fprintf(stderr,
            "Error: Total feature dimensionality exceeds supported maximum "
            "(%d). Adjust wavelet settings.\n",
            MAX_NUM_FEATURES);
    exit(1);
  }

  if (g_total_feature_count != model.num_features) {
    fprintf(stderr,
            "Error: Feature dimension mismatch. Model expects %d dims (wavelet "
            "%d) but current configuration yields %d dims (wavelet "
            "%d). Align with training.\n",
            model.num_features, model.wavelet_feature_count,
            g_total_feature_count, g_num_wavelet_scales * 2);
    exit(1);
  }

  fprintf(stderr, "Feature configuration: %d wavelet dims = %d total\n",
          g_num_wavelet_scales * 2, g_total_feature_count);

  // Initialize output queue
  output_queue_init(&g_output_queue);
  g_gene_counter = 0;

  predicted_gene_store_init(&g_predicted_gene_store);

  // Create thread pool
  thread_pool_t* pool = thread_pool_create(g_num_threads);
  if (pool == NULL) {
    fprintf(stderr, "Failed to create thread pool\n");
    exit(1);
  }

  // Load FASTA
  FastaData* genome = parse_fasta(fasta_path);
  if (!genome) {
    fprintf(stderr, "Failed to load FASTA file\n");
    thread_pool_destroy(pool);
    exit(1);
  }

  if (g_use_chunking) {
    int step = (g_chunk_size > g_chunk_overlap)
                   ? (g_chunk_size - g_chunk_overlap)
                   : g_chunk_size;
    fprintf(stderr,
            "Chunking enabled: chunk size %d bp, overlap %d bp (step %d bp)\n",
            g_chunk_size, g_chunk_overlap, step);
  } else {
    fprintf(stderr, "Chunking disabled; processing full sequences\n");
  }

  printf("##gff-version 3\n");

  // Submit prediction tasks to thread pool
  for (int i = 0; i < genome->count; i++) {
    const char* seq = genome->records[i].sequence;
    const char* seq_id = genome->records[i].id;
    int seq_len = strlen(seq);
    int chunk_count =
        calculate_num_chunks(seq_len, g_chunk_size, g_chunk_overlap);
    if (chunk_count < 1)
      chunk_count = 1;

    if (chunk_count > 1) {
      fprintf(
          stderr,
          "Splitting %s into %d chunk(s) per strand (size %d, overlap %d)\n",
          seq_id, chunk_count, g_chunk_size, g_chunk_overlap);
    }

    for (int chunk_idx = 0; chunk_idx < chunk_count; chunk_idx++) {
      int chunk_start = 0;
      int chunk_end = 0;
      get_chunk_bounds(seq_len, g_chunk_size, g_chunk_overlap, chunk_idx,
                       &chunk_start, &chunk_end);
      int chunk_len = chunk_end - chunk_start;
      if (chunk_len <= 0)
        continue;

      prediction_task_t* task =
          (prediction_task_t*)malloc(sizeof(prediction_task_t));
      if (!task) {
        fprintf(
            stderr,
            "Warning: Failed to allocate task for %s (+ strand chunk %d/%d)\n",
            seq_id, chunk_idx + 1, chunk_count);
        continue;
      }

      char* chunk_seq = (char*)malloc((size_t)chunk_len + 1);
      if (!chunk_seq) {
        fprintf(stderr,
                "Warning: Failed to allocate sequence buffer for %s (+ strand "
                "chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task);
        continue;
      }
      memcpy(chunk_seq, seq + chunk_start, (size_t)chunk_len);
      chunk_seq[chunk_len] = '\0';

      char* seq_id_copy = strdup(seq_id);
      if (!seq_id_copy) {
        fprintf(stderr,
                "Warning: Failed to duplicate sequence ID for %s (+ strand)\n",
                seq_id);
        free(chunk_seq);
        free(task);
        continue;
      }

      task->sequence = chunk_seq;
      task->seq_id = seq_id_copy;
      task->strand = '+';
      task->model = &model;
      task->original_length = seq_len;
      task->chunk_offset = chunk_start;
      task->chunk_index = chunk_idx;
      task->chunk_count = chunk_count;

      if (!thread_pool_add_task(pool, predict_sequence_worker, task)) {
        fprintf(stderr,
                "Warning: Failed to enqueue %s (+ strand chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task->sequence);
        free(task->seq_id);
        free(task);
      } else {
        if (chunk_count > 1) {
          fprintf(stderr, "Processing %s (+ strand chunk %d/%d)...\n", seq_id,
                  chunk_idx + 1, chunk_count);
        } else {
          fprintf(stderr, "Processing %s (+ strand)...\n", seq_id);
        }
      }
    }

    char* rc_full = reverse_complement(seq);
    if (!rc_full) {
      fprintf(stderr, "Warning: Failed to generate reverse complement for %s\n",
              seq_id);
      continue;
    }

    for (int chunk_idx = 0; chunk_idx < chunk_count; chunk_idx++) {
      int chunk_start = 0;
      int chunk_end = 0;
      get_chunk_bounds(seq_len, g_chunk_size, g_chunk_overlap, chunk_idx,
                       &chunk_start, &chunk_end);
      int chunk_len = chunk_end - chunk_start;
      if (chunk_len <= 0)
        continue;

      prediction_task_t* task =
          (prediction_task_t*)malloc(sizeof(prediction_task_t));
      if (!task) {
        fprintf(
            stderr,
            "Warning: Failed to allocate task for %s (- strand chunk %d/%d)\n",
            seq_id, chunk_idx + 1, chunk_count);
        continue;
      }

      char* chunk_seq = (char*)malloc((size_t)chunk_len + 1);
      if (!chunk_seq) {
        fprintf(stderr,
                "Warning: Failed to allocate sequence buffer for %s (- strand "
                "chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task);
        continue;
      }
      memcpy(chunk_seq, rc_full + chunk_start, (size_t)chunk_len);
      chunk_seq[chunk_len] = '\0';

      char* seq_id_copy = strdup(seq_id);
      if (!seq_id_copy) {
        fprintf(stderr,
                "Warning: Failed to duplicate sequence ID for %s (- strand)\n",
                seq_id);
        free(chunk_seq);
        free(task);
        continue;
      }

      task->sequence = chunk_seq;
      task->seq_id = seq_id_copy;
      task->strand = '-';
      task->model = &model;
      task->original_length = seq_len;
      task->chunk_offset = chunk_start;
      task->chunk_index = chunk_idx;
      task->chunk_count = chunk_count;

      if (!thread_pool_add_task(pool, predict_sequence_worker, task)) {
        fprintf(stderr,
                "Warning: Failed to enqueue %s (- strand chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task->sequence);
        free(task->seq_id);
        free(task);
      } else {
        if (chunk_count > 1) {
          fprintf(stderr, "Processing %s (- strand chunk %d/%d)...\n", seq_id,
                  chunk_idx + 1, chunk_count);
        } else {
          fprintf(stderr, "Processing %s (- strand)...\n", seq_id);
        }
      }
    }

    free(rc_full);
  }

  // Wait for all tasks to complete
  thread_pool_wait(pool);

  // Aggregate and emit deduplicated gene predictions
  predicted_gene_store_emit_to_queue(&g_predicted_gene_store);

  // Flush output
  output_queue_flush(&g_output_queue);

  fprintf(stderr, "Prediction complete. Found %d genes.\n", g_gene_counter);

  // Cleanup
  predicted_gene_store_destroy(&g_predicted_gene_store);
  thread_pool_destroy(pool);
  output_queue_destroy(&g_output_queue);
  free_fasta_data(genome);
}

int main(int argc, char* argv[]) {
  // Ensure real-time output behavior
  setvbuf(stdout, NULL, _IOLBF, 0);
  setvbuf(stderr, NULL, _IONBF, 0);

  if (!update_feature_counts()) {
    fprintf(stderr,
            "Error: Default feature configuration exceeds supported limits.\n"
            "Adjust MAX_NUM_FEATURES or reduce wavelet settings.\n");
    return 1;
  }

  if (argc < 2) {
    print_help(argv[0]);
    return 0;
  }

  if (strcmp(argv[1], "help") == 0 || strcmp(argv[1], "--help") == 0 ||
      strcmp(argv[1], "-h") == 0) {
    print_help(argv[0]);
    return 0;
  }

  if (strcmp(argv[1], "train") == 0) {
    handle_train(argc, argv);
  } else if (strcmp(argv[1], "predict") == 0) {
    handle_predict(argc, argv);
  } else {
    fprintf(stderr, "Error: Unknown mode '%s'\n", argv[1]);
    fprintf(stderr, "Valid commands: help, train, predict\n");
    print_help(argv[0]);
    return 1;
  }

  return 0;

==> src/thread_pool.c <==
#include <pthread.h>
#include <stdbool.h>
#include <stdlib.h>

#include "../include/thread_pool.h"

// Worker thread function
static void* worker_thread(void* arg) {
  thread_pool_t* pool = (thread_pool_t*)arg;
  
  while (true) {
    pthread_mutex_lock(&pool->queue_mutex);
    
    // Wait for a task or shutdown signal
    while (pool->task_queue_head == NULL && !pool->shutdown) {
      pthread_cond_wait(&pool->queue_cond, &pool->queue_mutex);
    }
    
    // Check for shutdown
    if (pool->shutdown && pool->task_queue_head == NULL) {
      pthread_mutex_unlock(&pool->queue_mutex);
      break;
    }
    
    // Dequeue task
    task_t* task = pool->task_queue_head;
    if (task != NULL) {
      pool->task_queue_head = task->next;
      if (pool->task_queue_head == NULL) {
        pool->task_queue_tail = NULL;
      }
      pool->active_tasks++;
    }
    
    pthread_mutex_unlock(&pool->queue_mutex);
    
    // Execute task
    if (task != NULL) {
      task->function(task->argument);
      free(task);
      
      pthread_mutex_lock(&pool->queue_mutex);
      pool->active_tasks--;
      if (pool->active_tasks == 0 && pool->task_queue_head == NULL) {
        pthread_cond_broadcast(&pool->done_cond);
      }
      pthread_mutex_unlock(&pool->queue_mutex);
    }
  }
  
  return NULL;
}

thread_pool_t* thread_pool_create(int num_threads) {
  if (num_threads <= 0) {
    return NULL;
  }
  
  thread_pool_t* pool = (thread_pool_t*)malloc(sizeof(thread_pool_t));
  if (pool == NULL) {
    return NULL;
  }
  
  pool->thread_count = num_threads;
  pool->task_queue_head = NULL;
  pool->task_queue_tail = NULL;
  pool->active_tasks = 0;
  pool->shutdown = false;
  
  // Initialize mutex and condition variables
  if (pthread_mutex_init(&pool->queue_mutex, NULL) != 0) {
    free(pool);
    return NULL;
  }
  
  if (pthread_cond_init(&pool->queue_cond, NULL) != 0) {
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  if (pthread_cond_init(&pool->done_cond, NULL) != 0) {
    pthread_cond_destroy(&pool->queue_cond);
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  // Allocate thread array
  pool->threads = (pthread_t*)malloc(sizeof(pthread_t) * num_threads);
  if (pool->threads == NULL) {
    pthread_cond_destroy(&pool->done_cond);
    pthread_cond_destroy(&pool->queue_cond);
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  // Create worker threads
  for (int i = 0; i < num_threads; i++) {
    if (pthread_create(&pool->threads[i], NULL, worker_thread, pool) != 0) {
      // Failed to create thread, cleanup
      pool->shutdown = true;
      pthread_cond_broadcast(&pool->queue_cond);
      for (int j = 0; j < i; j++) {
        pthread_join(pool->threads[j], NULL);
      }
      free(pool->threads);
      pthread_cond_destroy(&pool->done_cond);
      pthread_cond_destroy(&pool->queue_cond);
      pthread_mutex_destroy(&pool->queue_mutex);
      free(pool);
      return NULL;
    }
  }
  
  return pool;
}

bool thread_pool_add_task(thread_pool_t* pool, task_func_t function, void* arg) {
  if (pool == NULL || function == NULL) {
    return false;
  }
  
  task_t* task = (task_t*)malloc(sizeof(task_t));
  if (task == NULL) {
    return false;
  }
  
  task->function = function;
  task->argument = arg;
  task->next = NULL;
  
  pthread_mutex_lock(&pool->queue_mutex);
  
  if (pool->shutdown) {
    pthread_mutex_unlock(&pool->queue_mutex);
    free(task);
    return false;
  }
  
  // Enqueue task
  if (pool->task_queue_tail == NULL) {
    pool->task_queue_head = task;
    pool->task_queue_tail = task;
  } else {
    pool->task_queue_tail->next = task;
    pool->task_queue_tail = task;
  }
  
  pthread_cond_signal(&pool->queue_cond);
  pthread_mutex_unlock(&pool->queue_mutex);
  
  return true;
}

void thread_pool_wait(thread_pool_t* pool) {
  if (pool == NULL) {
    return;
  }
  
  pthread_mutex_lock(&pool->queue_mutex);
  
  while (pool->active_tasks > 0 || pool->task_queue_head != NULL) {
    pthread_cond_wait(&pool->done_cond, &pool->queue_mutex);
  }
  
  pthread_mutex_unlock(&pool->queue_mutex);
}

void thread_pool_destroy(thread_pool_t* pool) {
  if (pool == NULL) {
    return;
  }
  
  pthread_mutex_lock(&pool->queue_mutex);
  pool->shutdown = true;
  pthread_cond_broadcast(&pool->queue_cond);
  pthread_mutex_unlock(&pool->queue_mutex);
  
  // Join all threads
  for (int i = 0; i < pool->thread_count; i++) {
    pthread_join(pool->threads[i], NULL);
  }
  
  // Free remaining tasks in queue
  task_t* task = pool->task_queue_head;
  while (task != NULL) {
    task_t* next = task->next;
    free(task);
    task = next;
  }
  
  free(pool->threads);
  pthread_cond_destroy(&pool->done_cond);
  pthread_cond_destroy(&pool->queue_cond);
  pthread_mutex_destroy(&pool->queue_mutex);
  free(pool);

==> src/utils.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/sunfish.h"

static char complement_base(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 'T';
  case 'T':
    return 'A';
  case 'G':
    return 'C';
  case 'C':
    return 'G';
  default:
    return 'N';
  }
}

char* reverse_complement(const char* sequence) {
  if (sequence == NULL) {
    return NULL;
  }

  size_t len = strlen(sequence);
  char* rc = (char*)malloc(len + 1);
  if (!rc) {
    return NULL;
  }

  for (size_t i = 0; i < len; i++) {
    rc[i] = complement_base(sequence[len - 1 - i]);
  }
  rc[len] = '\0';

  return rc;
