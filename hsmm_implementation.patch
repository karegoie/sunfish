diff --git a/include/hmm.h b/include/hmm.h
index bf881b4..af8c761 100644
--- a/include/hmm.h
+++ b/include/hmm.h
@@ -42,6 +42,12 @@ typedef struct {
   double pwm_weight;
 } PWMModel;
 
+// Duration distribution parameters for HSMM
+typedef struct {
+  double mean_log_duration;   // mean of log(duration)
+  double stddev_log_duration; // standard deviation of log(duration)
+} StateDuration;
+
 // HMM model structure
 typedef struct {
   // Transition probabilities: transition[i][j] = P(state_j | state_i)
@@ -68,6 +74,9 @@ typedef struct {
   // PWM model for splice site scoring
   PWMModel pwm;
 
+  // Duration distribution parameters for HSMM (log-normal distribution)
+  StateDuration duration[NUM_STATES];
+
   // Chunking configuration stored with the model so prediction can reuse
   // the chunk size and overlap that were used during training.
   int chunk_size;    // recommended chunk size in bases (0 = unspecified)
diff --git a/src/hmm.c b/src/hmm.c
index 293827c..8a5e3f5 100644
--- a/src/hmm.c
+++ b/src/hmm.c
@@ -214,6 +214,12 @@ void hmm_init(HMMModel* model, int num_features) {
   model->chunk_overlap = 0;
   model->use_chunking = 0;
 
+  // Initialize duration parameters with defaults
+  for (int i = 0; i < NUM_STATES; i++) {
+    model->duration[i].mean_log_duration = 0.0;    // log(1) = 0
+    model->duration[i].stddev_log_duration = 1.0;  // default stddev
+  }
+
   // Initialize wavelet scales metadata
   model->num_wavelet_scales = 0;
   for (int i = 0; i < MAX_NUM_WAVELETS; i++)
@@ -507,48 +513,120 @@ bool hmm_train_baum_welch(HMMModel* model, double*** observations,
   return true;
 }
 
+// Helper function to compute log probability of duration d under log-normal distribution
+static double lognormal_log_pdf(int duration, double mean_log_duration, 
+                                double stddev_log_duration) {
+  if (duration <= 0) {
+    return -INFINITY;
+  }
+  
+  if (stddev_log_duration < 1e-6) {
+    stddev_log_duration = 1e-6;  // Prevent numerical issues
+  }
+  
+  double log_d = log((double)duration);
+  double diff = log_d - mean_log_duration;
+  double var = stddev_log_duration * stddev_log_duration;
+  
+  // Log-PDF of log-normal distribution:
+  // -log(d) - 0.5*log(2*pi*var) - (log(d) - mu)^2 / (2*var)
+  return -log_d - 0.5 * log(2.0 * M_PI * var) - (diff * diff) / (2.0 * var);
+}
+
 double hmm_viterbi(const HMMModel* model, double** observations,
                    const char* sequence, int seq_len, int* states) {
+  // HSMM Viterbi with segment-based processing
+  const int MAX_DURATION = 2000;  // Maximum segment duration to consider
+  
   // Allocate Viterbi matrices
+  // delta[t][j] = max log-probability of path ending at position t in state j
   double** delta = (double**)malloc(seq_len * sizeof(double*));
+  // psi[t][j] stores the best previous state for ending at t in state j
   int** psi = (int**)malloc(seq_len * sizeof(int*));
+  // duration[t][j] stores the optimal duration of state j ending at position t
+  int** duration = (int**)malloc(seq_len * sizeof(int*));
 
   for (int t = 0; t < seq_len; t++) {
     delta[t] = (double*)malloc(NUM_STATES * sizeof(double));
     psi[t] = (int*)malloc(NUM_STATES * sizeof(int));
+    duration[t] = (int*)malloc(NUM_STATES * sizeof(int));
+    
+    for (int j = 0; j < NUM_STATES; j++) {
+      delta[t][j] = -INFINITY;
+      psi[t][j] = 0;
+      duration[t][j] = 1;
+    }
   }
 
-  // Initialization (t=0)
-  for (int i = 0; i < NUM_STATES; i++) {
-    delta[0][i] =
-        log(model->initial[i]) +
-        gaussian_log_pdf(observations[0], model->emission[i].mean,
-                         model->emission[i].variance, model->num_features);
-    psi[0][i] = 0;
+  // Initialization (t=0): start with segments of length 1
+  for (int j = 0; j < NUM_STATES; j++) {
+    delta[0][j] =
+        log(model->initial[j]) +
+        gaussian_log_pdf(observations[0], model->emission[j].mean,
+                         model->emission[j].variance, model->num_features) +
+        lognormal_log_pdf(1, model->duration[j].mean_log_duration,
+                         model->duration[j].stddev_log_duration);
+    psi[0][j] = -1;  // No previous state
+    duration[0][j] = 1;
   }
 
-  // Recursion (t=1 to T-1)
+  // Recursion: for each position t and state j, consider all possible durations
   for (int t = 1; t < seq_len; t++) {
     for (int j = 0; j < NUM_STATES; j++) {
-      double max_val = -INFINITY;
-      int max_state = 0;
-
-      for (int i = 0; i < NUM_STATES; i++) {
-        double transition_log = log(model->transition[i][j]);
-        transition_log +=
-            splice_signal_adjustment(sequence, seq_len, i, j, t, &model->pwm);
-        double val = delta[t - 1][i] + transition_log;
-        if (val > max_val) {
-          max_val = val;
-          max_state = i;
+      double best_score = -INFINITY;
+      int best_prev_state = 0;
+      int best_duration = 1;
+      
+      // Try different segment durations d
+      int max_d = (t + 1 < MAX_DURATION) ? (t + 1) : MAX_DURATION;
+      
+      for (int d = 1; d <= max_d && d <= t + 1; d++) {
+        // Compute emission probability for segment [t-d+1, t]
+        double segment_emission = 0.0;
+        for (int pos = t - d + 1; pos <= t; pos++) {
+          segment_emission += gaussian_log_pdf(observations[pos],
+                                              model->emission[j].mean,
+                                              model->emission[j].variance,
+                                              model->num_features);
+        }
+        
+        // Compute duration probability
+        double duration_prob = lognormal_log_pdf(d, model->duration[j].mean_log_duration,
+                                                model->duration[j].stddev_log_duration);
+        
+        // Consider transitions from all previous states
+        if (d == t + 1) {
+          // Segment starts from position 0 (initial state)
+          double score = log(model->initial[j]) + segment_emission + duration_prob;
+          if (score > best_score) {
+            best_score = score;
+            best_prev_state = -1;
+            best_duration = d;
+          }
+        } else {
+          // Segment starts after position t-d
+          int prev_pos = t - d;
+          for (int i = 0; i < NUM_STATES; i++) {
+            double transition_log = log(model->transition[i][j]);
+            // Add splice signal adjustment at the transition point (t-d+1)
+            transition_log += splice_signal_adjustment(sequence, seq_len, i, j, 
+                                                      t - d + 1, &model->pwm);
+            
+            double score = delta[prev_pos][i] + transition_log + 
+                          segment_emission + duration_prob;
+            
+            if (score > best_score) {
+              best_score = score;
+              best_prev_state = i;
+              best_duration = d;
+            }
+          }
         }
       }
-
-      delta[t][j] =
-          max_val + gaussian_log_pdf(observations[t], model->emission[j].mean,
-                                     model->emission[j].variance,
-                                     model->num_features);
-      psi[t][j] = max_state;
+      
+      delta[t][j] = best_score;
+      psi[t][j] = best_prev_state;
+      duration[t][j] = best_duration;
     }
   }
 
@@ -562,19 +640,35 @@ double hmm_viterbi(const HMMModel* model, double** observations,
     }
   }
 
-  // Backtrack
-  states[seq_len - 1] = best_state;
-  for (int t = seq_len - 2; t >= 0; t--) {
-    states[t] = psi[t + 1][states[t + 1]];
+  // Backtrack using segment information
+  int t = seq_len - 1;
+  int current_state = best_state;
+  
+  while (t >= 0) {
+    int d = duration[t][current_state];
+    int prev_state = psi[t][current_state];
+    
+    // Fill in the states for the segment
+    for (int pos = t - d + 1; pos <= t && pos >= 0; pos++) {
+      states[pos] = current_state;
+    }
+    
+    // Move to previous segment
+    t = t - d;
+    if (prev_state >= 0) {
+      current_state = prev_state;
+    }
   }
 
   // Free matrices
   for (int t = 0; t < seq_len; t++) {
     free(delta[t]);
     free(psi[t]);
+    free(duration[t]);
   }
   free(delta);
   free(psi);
+  free(duration);
 
   return max_prob;
 }
@@ -624,6 +718,14 @@ bool hmm_save_model(const HMMModel* model, const char* filename) {
     fprintf(fp, "\n");
   }
 
+  // Save duration parameters (HSMM)
+  fprintf(fp, "DURATION\n");
+  for (int i = 0; i < NUM_STATES; i++) {
+    fprintf(fp, "%.10f %.10f\n", 
+            model->duration[i].mean_log_duration,
+            model->duration[i].stddev_log_duration);
+  }
+
   // Save global feature statistics for Z-score normalization
   fprintf(fp, "GLOBAL_STATS\n");
   fprintf(fp, "MEAN ");
@@ -1115,6 +1217,28 @@ bool hmm_load_model(HMMModel* model, const char* filename) {
     }
   }
 
+  // Initialize duration parameters with defaults (for backward compatibility)
+  for (int i = 0; i < NUM_STATES; i++) {
+    model->duration[i].mean_log_duration = 0.0;
+    model->duration[i].stddev_log_duration = 1.0;
+  }
+
+  // Read DURATION block if present (optional for backward compatibility)
+  if (fgets(line, sizeof(line), fp) != NULL && 
+      strncmp(line, "DURATION", 8) == 0) {
+    for (int i = 0; i < NUM_STATES; i++) {
+      if (fgets(line, sizeof(line), fp) != NULL) {
+        if (sscanf(line, "%lf %lf", 
+                  &model->duration[i].mean_log_duration,
+                  &model->duration[i].stddev_log_duration) != 2) {
+          // If parsing fails, keep defaults
+          model->duration[i].mean_log_duration = 0.0;
+          model->duration[i].stddev_log_duration = 1.0;
+        }
+      }
+    }
+  }
+
   fclose(fp);
   return true;
 }
diff --git a/src/sunfish.c b/src/sunfish.c
index 44461e9..d18448c 100644
--- a/src/sunfish.c
+++ b/src/sunfish.c
@@ -1524,6 +1524,64 @@ static void accumulate_statistics_for_sequence(
   }
 }
 
+// Helper structure for collecting duration statistics
+typedef struct {
+  double* log_durations;  // Array of log(duration) values
+  int count;             // Number of observations
+  int capacity;          // Allocated capacity
+} DurationStats;
+
+static void accumulate_duration_statistics(
+    int seq_len, const int* state_labels,
+    DurationStats duration_stats[NUM_STATES]) {
+  if (!state_labels || !duration_stats || seq_len <= 0)
+    return;
+
+  int current_state = state_labels[0];
+  int segment_start = 0;
+
+  for (int t = 1; t <= seq_len; t++) {
+    int next_state = (t < seq_len) ? state_labels[t] : -1;
+    
+    // Check if we've reached the end of a segment
+    if (t == seq_len || next_state != current_state) {
+      int duration = t - segment_start;
+      
+      if (current_state >= 0 && current_state < NUM_STATES && duration > 0) {
+        // Expand array if needed
+        if (duration_stats[current_state].count >= 
+            duration_stats[current_state].capacity) {
+          int new_capacity = duration_stats[current_state].capacity * 2;
+          if (new_capacity < 16) new_capacity = 16;
+          
+          double* new_array = (double*)realloc(
+              duration_stats[current_state].log_durations,
+              new_capacity * sizeof(double));
+          
+          if (new_array) {
+            duration_stats[current_state].log_durations = new_array;
+            duration_stats[current_state].capacity = new_capacity;
+          }
+        }
+        
+        // Add log(duration) to the array
+        if (duration_stats[current_state].count < 
+            duration_stats[current_state].capacity) {
+          duration_stats[current_state].log_durations[
+              duration_stats[current_state].count] = log((double)duration);
+          duration_stats[current_state].count++;
+        }
+      }
+      
+      // Start new segment
+      if (t < seq_len) {
+        current_state = next_state;
+        segment_start = t;
+      }
+    }
+  }
+}
+
 static void enforce_exon_cycle_constraints(HMMModel* model) {
   if (!model)
     return;
@@ -2374,6 +2432,96 @@ static void handle_train(int argc, char* argv[]) {
             state_observation_counts[i]);
   }
 
+  // =========================================================================
+  // Calculate duration statistics for HSMM
+  // =========================================================================
+  fprintf(stderr, "Calculating duration statistics for HSMM...\n");
+  
+  // Initialize duration statistics collectors
+  DurationStats duration_stats[NUM_STATES];
+  for (int i = 0; i < NUM_STATES; i++) {
+    duration_stats[i].log_durations = NULL;
+    duration_stats[i].count = 0;
+    duration_stats[i].capacity = 0;
+  }
+  
+  // Collect duration statistics from all sequences
+  for (int seq_idx = 0; seq_idx < genome->count; seq_idx++) {
+    const char* seq_id = genome->records[seq_idx].id;
+    int seq_len = strlen(genome->records[seq_idx].sequence);
+    
+    if (seq_len <= 0)
+      continue;
+    
+    int forward_obs_idx = seq_idx * 2;
+    int reverse_obs_idx = forward_obs_idx + 1;
+    
+    int* state_labels = (int*)malloc(seq_len * sizeof(int));
+    if (!state_labels) {
+      fprintf(stderr, "Warning: Failed to allocate state labels for duration stats\n");
+      continue;
+    }
+    
+    // Process forward strand
+    if (forward_obs_idx < total_sequences && observations[forward_obs_idx] &&
+        seq_lengths[forward_obs_idx] > 0) {
+      initialize_state_labels(state_labels, seq_len);
+      label_forward_states(groups, group_count, seq_id, seq_len, state_labels);
+      accumulate_duration_statistics(seq_len, state_labels, duration_stats);
+    }
+    
+    // Process reverse strand
+    if (reverse_obs_idx < total_sequences && observations[reverse_obs_idx] &&
+        seq_lengths[reverse_obs_idx] > 0) {
+      initialize_state_labels(state_labels, seq_len);
+      label_reverse_states(groups, group_count, seq_id, seq_len, state_labels);
+      accumulate_duration_statistics(seq_len, state_labels, duration_stats);
+    }
+    
+    free(state_labels);
+  }
+  
+  // Compute mean and stddev of log-durations for each state
+  for (int i = 0; i < NUM_STATES; i++) {
+    if (duration_stats[i].count > 0) {
+      // Calculate mean
+      double sum = 0.0;
+      for (int j = 0; j < duration_stats[i].count; j++) {
+        sum += duration_stats[i].log_durations[j];
+      }
+      double mean = sum / duration_stats[i].count;
+      
+      // Calculate standard deviation
+      double sum_sq = 0.0;
+      for (int j = 0; j < duration_stats[i].count; j++) {
+        double diff = duration_stats[i].log_durations[j] - mean;
+        sum_sq += diff * diff;
+      }
+      
+      double stddev = 1.0;  // default
+      if (duration_stats[i].count > 1) {
+        double variance = sum_sq / (duration_stats[i].count - 1);
+        stddev = sqrt(variance > 1e-6 ? variance : 1e-6);
+      }
+      
+      model.duration[i].mean_log_duration = mean;
+      model.duration[i].stddev_log_duration = stddev;
+      
+      fprintf(stderr, "State %d: %d duration segments, mean_log=%.4f, stddev_log=%.4f\n",
+              i, duration_stats[i].count, mean, stddev);
+    } else {
+      // No segments observed, use defaults
+      model.duration[i].mean_log_duration = 0.0;
+      model.duration[i].stddev_log_duration = 1.0;
+      fprintf(stderr, "State %d: No duration segments observed, using defaults\n", i);
+    }
+    
+    // Free duration statistics
+    if (duration_stats[i].log_durations) {
+      free(duration_stats[i].log_durations);
+    }
+  }
+
   enforce_exon_cycle_constraints(&model);
 
   fprintf(stderr, "Supervised training complete.\n");
