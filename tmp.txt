==> include/cwt.h <==
#ifndef CWT_H
#define CWT_H

#include <complex.h>
#include <stdbool.h>

#include "fft.h"

/**
 * Convert DNA base to complex number on the complex plane.
 * A -> (1+1i), T -> (1-1i), G -> (-1+1i), C -> (-1-1i)
 * @param base DNA base character
 * @return Complex number representation
 */
cplx dna_to_complex(char base);

/**
 * Convert DNA sequence to numerical signal (complex array).
 * @param sequence DNA sequence string
 * @param length Length of sequence
 * @param output Output array (must be pre-allocated)
 */
void dna_to_signal(const char* sequence, int length, cplx* output);

/**
 * Generate Morlet wavelet for a given scale parameter.
 * Formula: ψ(t) = (1/√(s·π^(1/4))) * exp(-1/2 * (t/s)^2) * exp(-j*2π*t/s)
 * @param scale Scale parameter s
 * @param length Length of the wavelet (should be centered at length/2)
 * @param output Output array (must be pre-allocated)
 */
void generate_morlet_wavelet(double scale, int length, cplx* output);

/**
 * Perform convolution using FFT.
 * @param signal Input signal
 * @param signal_len Length of signal
 * @param wavelet Wavelet kernel
 * @param wavelet_len Length of wavelet
 * @param output Output array (must be pre-allocated, size signal_len)
 * @return true on success, false on error
 */
bool convolve_with_wavelet(const cplx* signal, int signal_len,
                           const cplx* wavelet, int wavelet_len,
                           cplx* output);

/**
 * Compute CWT features for a DNA sequence at multiple scales.
 * @param sequence DNA sequence
 * @param seq_len Length of sequence
 * @param scales Array of scale parameters
 * @param num_scales Number of scales
 * @param features Output 2D array [num_scales][seq_len] (must be pre-allocated)
 * @return true on success, false on error
 */
bool compute_cwt_features(const char* sequence, int seq_len,
                          const double* scales, int num_scales,
                          double** features);


==> include/fasta_parser.h <==
#ifndef FASTA_PARSER_H
#define FASTA_PARSER_H

// Data Structures
typedef struct {
  char* id;
  char* sequence;
} FastaRecord;

typedef struct {
  FastaRecord* records;
  int count;
} FastaData;

void free_fasta_data(FastaData* data);
FastaData* parse_fasta(const char* path);


==> include/fft.h <==
#ifndef FFT_H
#define FFT_H

#include <complex.h>
#include <stdbool.h>

// Type alias for convenience
typedef double complex cplx;

/**
 * Compute the Fast Fourier Transform (FFT) using Cooley-Tukey algorithm.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 * @param inverse If true, compute inverse FFT
 */
void fft(cplx* x, int N, bool inverse);

/**
 * Compute inverse FFT with proper normalization.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 */
void ifft(cplx* x, int N);

/**
 * Check if a number is a power of 2.
 * @param n Number to check
 * @return true if n is a power of 2, false otherwise
 */
bool is_power_of_2(int n);

/**
 * Find next power of 2 greater than or equal to n.
 * @param n Input number
 * @return Next power of 2
 */
int next_power_of_2(int n);


==> include/gff_parser.h <==
#ifndef GFF_PARSER_H
#define GFF_PARSER_H

// Data Structures
typedef struct {
  char* seqid;
  int start;
  int end;
  char strand;
  int phase;
} Exon;

typedef struct {
  char* parent_id;
  Exon* exons;
  int exon_count;
} CdsGroup;

void free_cds_groups(CdsGroup* groups, int count);
CdsGroup* parse_gff_for_cds(const char* path, int* group_count);


==> include/hmm.h <==
#ifndef HMM_H
#define HMM_H

#include <stdbool.h>

// HMM states
typedef enum {
  STATE_EXON_F0 = 0,
  STATE_EXON_F1 = 1,
  STATE_EXON_F2 = 2,
  STATE_INTRON = 3,
  STATE_INTERGENIC = 4,
  NUM_STATES = 5
} HMMState;

// Maximum number of wavelet scales (features)
// Increased to support user-specified ranges up to 100 scales.
#define MAX_NUM_WAVELETS 100

// Maximum dimensionality of feature vectors (wavelet + k-mer)
#define MAX_NUM_FEATURES 8192

// Gaussian emission parameters for a single state
typedef struct {
  double mean[MAX_NUM_FEATURES];
  double variance[MAX_NUM_FEATURES];
  int num_features;
} GaussianEmission;

// PWM structures for splice site scoring
#define DONOR_MOTIF_SIZE 9
#define ACCEPTOR_MOTIF_SIZE 15
#define NUM_NUCLEOTIDES 4

typedef struct {
  double donor_pwm[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  double acceptor_pwm[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  double min_donor_score;
  double min_acceptor_score;
  int has_donor;
  int has_acceptor;
  double pwm_weight;
} PWMModel;

// HMM model structure
typedef struct {
  // Transition probabilities: transition[i][j] = P(state_j | state_i)
  double transition[NUM_STATES][NUM_STATES];

  // Initial state probabilities
  double initial[NUM_STATES];

  // Emission parameters for each state (multivariate Gaussian with diagonal
  // covariance)
  GaussianEmission emission[NUM_STATES];

  int num_features;
  int wavelet_feature_count;
  int kmer_feature_count;
  int kmer_size;

  // Global feature statistics for Z-score normalization
  double global_feature_mean[MAX_NUM_FEATURES];
  double global_feature_stddev[MAX_NUM_FEATURES];

  // PWM model for splice site scoring
  PWMModel pwm;
} HMMModel;

/**
 * Initialize HMM with default/random parameters.
 * @param model HMM model to initialize
 * @param num_features Number of CWT features (wavelet scales)
 */
void hmm_init(HMMModel* model, int num_features);

/**
 * Compute Gaussian probability density function (PDF) for diagonal covariance.
 * @param observation Feature vector
 * @param mean Mean vector
 * @param variance Variance vector (diagonal of covariance matrix)
 * @param num_features Dimension of vectors
 * @return Log probability
 */
double gaussian_log_pdf(const double* observation, const double* mean,
                        const double* variance, int num_features);

/**
 * Train HMM using Baum-Welch algorithm.
 * @param model HMM model to train
 * @param observations Array of observation sequences (2D:
 * [num_sequences][seq_len][num_features])
 * @param seq_lengths Length of each sequence
 * @param num_sequences Number of training sequences
 * @param max_iterations Maximum number of EM iterations
 * @param convergence_threshold Convergence threshold for log-likelihood change
 * @return true on success, false on error
 */
bool hmm_train_baum_welch(HMMModel* model, double*** observations,
                          int* seq_lengths, int num_sequences,
                          int max_iterations, double convergence_threshold);

/**
 * Predict state sequence using Viterbi algorithm.
 * @param model HMM model
 * @param observations Observation sequence [seq_len][num_features]
 * @param seq_len Length of sequence
 * @param states Output state sequence (must be pre-allocated)
 * @return Log probability of most likely path
 */
double hmm_viterbi(const HMMModel* model, double** observations,
                   const char* sequence, int seq_len, int* states);

/**
 * Save HMM model to file.
 * @param model HMM model
 * @param filename Output filename
 * @return true on success, false on error
 */
bool hmm_save_model(const HMMModel* model, const char* filename);

/**
 * Load HMM model from file.
 * @param model HMM model to load into
 * @param filename Input filename
 * @return true on success, false on error
 */
bool hmm_load_model(HMMModel* model, const char* filename);


==> include/sunfish.h <==
#ifndef SUNFISH_H
#define SUNFISH_H

#include <stdbool.h>

#include "fasta_parser.h"
#include "gff_parser.h"
#include "hmm.h"

// Line and buffer sizes
enum { MAX_LINE_LEN = 50000, MAX_PEPTIDE_LEN = 100000, MAX_DNA_LEN = 1000000 };

// Amino acids
enum { NUM_AMINO_ACIDS = 20 };

typedef struct {
  char* sequence;
  int counts[NUM_AMINO_ACIDS];
  int exon_count;
  int cds_length_nt;
} PeptideInfo;

// PWM Structures
typedef struct {
  double donor_pwm[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  double acceptor_pwm[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  double min_donor_score;
  double min_acceptor_score;
} SplicePWM;

typedef struct {
  int donor_counts[NUM_NUCLEOTIDES][DONOR_MOTIF_SIZE];
  int acceptor_counts[NUM_NUCLEOTIDES][ACCEPTOR_MOTIF_SIZE];
  int total_donor_sites;
  int total_acceptor_sites;
} SpliceCounts;

char* reverse_complement(const char* sequence);


==> include/thread_pool.h <==
#ifndef THREAD_POOL_H
#define THREAD_POOL_H

#include <pthread.h>
#include <stdbool.h>

// Task function signature
typedef void (*task_func_t)(void* arg);

// Task structure
typedef struct task_t {
  task_func_t function;
  void* argument;
  struct task_t* next;
} task_t;

// Thread pool structure
typedef struct {
  pthread_t* threads;
  int thread_count;
  
  task_t* task_queue_head;
  task_t* task_queue_tail;
  
  pthread_mutex_t queue_mutex;
  pthread_cond_t queue_cond;
  pthread_cond_t done_cond;
  
  int active_tasks;
  bool shutdown;
} thread_pool_t;

/**
 * Create a thread pool with specified number of worker threads.
 * @param num_threads Number of worker threads to create
 * @return Pointer to thread pool, or NULL on error
 */
thread_pool_t* thread_pool_create(int num_threads);

/**
 * Add a task to the thread pool's queue.
 * @param pool Thread pool
 * @param function Function to execute
 * @param arg Argument to pass to function
 * @return true on success, false on error
 */
bool thread_pool_add_task(thread_pool_t* pool, task_func_t function, void* arg);

/**
 * Wait for all tasks to complete.
 * @param pool Thread pool
 */
void thread_pool_wait(thread_pool_t* pool);

/**
 * Destroy the thread pool and free all resources.
 * @param pool Thread pool to destroy
 */
void thread_pool_destroy(thread_pool_t* pool);


==> src/cwt.c <==
#include <complex.h>
#include <ctype.h>
#include <math.h>
#include <stdbool.h>
#include <stdlib.h>
#include <string.h>

#include "../include/cwt.h"
#include "../include/fft.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

cplx dna_to_complex(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 1.0 + 1.0 * I;
  case 'T':
    return 1.0 - 1.0 * I;
  case 'G':
    return -1.0 + 1.0 * I;
  case 'C':
    return -1.0 - 1.0 * I;
  default:
    // For unknown bases, return zero
    return 0.0 + 0.0 * I;
  }
}

void dna_to_signal(const char* sequence, int length, cplx* output) {
  for (int i = 0; i < length; i++) {
    output[i] = dna_to_complex(sequence[i]);
  }
}

void generate_morlet_wavelet(double scale, int length, cplx* output) {
  // Morlet wavelet: ψ(t) = (1/√(s·π^(1/4))) * exp(-1/2 * (t/s)^2) *
  // exp(-j*2π*t/s)
  double norm_factor = 1.0 / sqrt(scale * pow(M_PI, 0.25));
  int center = length / 2;

  for (int i = 0; i < length; i++) {
    double t = (double)(i - center);
    double t_scaled = t / scale;
    double gaussian = exp(-0.5 * t_scaled * t_scaled);
    double phase = -2.0 * M_PI * t / scale;
    cplx oscillation = cexp(I * phase);
    output[i] = norm_factor * gaussian * oscillation;
  }
}

bool convolve_with_wavelet(const cplx* signal, int signal_len,
                           const cplx* wavelet, int wavelet_len, cplx* output) {
  // Find common padded length (power of 2)
  int max_len = signal_len + wavelet_len - 1;
  int padded_len = next_power_of_2(max_len);

  // Allocate padded arrays
  cplx* signal_padded = (cplx*)calloc(padded_len, sizeof(cplx));
  cplx* wavelet_padded = (cplx*)calloc(padded_len, sizeof(cplx));

  if (signal_padded == NULL || wavelet_padded == NULL) {
    free(signal_padded);
    free(wavelet_padded);
    return false;
  }

  // Copy data to padded arrays
  memcpy(signal_padded, signal, signal_len * sizeof(cplx));
  memcpy(wavelet_padded, wavelet, wavelet_len * sizeof(cplx));

  // Compute FFT of both
  fft(signal_padded, padded_len, false);
  fft(wavelet_padded, padded_len, false);

  // Element-wise multiplication in frequency domain
  for (int i = 0; i < padded_len; i++) {
    signal_padded[i] = signal_padded[i] * wavelet_padded[i];
  }

  // Inverse FFT
  ifft(signal_padded, padded_len);

  // Calculate offset to correct for convolution delay
  int offset = wavelet_len / 2;

  // Extract complex values with offset correction
  for (int i = 0; i < signal_len; i++) {
    output[i] = signal_padded[i + offset];
  }

  free(signal_padded);
  free(wavelet_padded);

  return true;
}

bool compute_cwt_features(const char* sequence, int seq_len,
                          const double* scales, int num_scales,
                          double** features) {
  // Convert DNA to complex signal
  cplx* signal = (cplx*)malloc(seq_len * sizeof(cplx));
  if (signal == NULL) {
    return false;
  }
  dna_to_signal(sequence, seq_len, signal);

  // For each scale, generate wavelet and convolve
  for (int s = 0; s < num_scales; s++) {
    // Wavelet length equals the given scale (no longer using 10*s)
    int wavelet_len = (int)(scales[s]);
    if (wavelet_len < 1)
      wavelet_len = 1;
    if (wavelet_len > seq_len)
      wavelet_len = seq_len;

    cplx* wavelet = (cplx*)malloc(wavelet_len * sizeof(cplx));
    if (wavelet == NULL) {
      free(signal);
      return false;
    }

    generate_morlet_wavelet(scales[s], wavelet_len, wavelet);

    // Allocate temporary buffer for complex results
    cplx* cwt_result = (cplx*)malloc(seq_len * sizeof(cplx));
    if (cwt_result == NULL) {
      free(wavelet);
      free(signal);
      return false;
    }

    if (!convolve_with_wavelet(signal, seq_len, wavelet, wavelet_len,
                               cwt_result)) {
      free(cwt_result);
      free(wavelet);
      free(signal);
      return false;
    }

    // Store real, imaginary, magnitude, and phase
    // features[s * 4] = real part
    // features[s * 4 + 1] = imaginary part
    // features[s * 4 + 2] = magnitude
    // features[s * 4 + 3] = phase
    for (int i = 0; i < seq_len; i++) {
      features[s * 4][i] = creal(cwt_result[i]);
      features[s * 4 + 1][i] = cimag(cwt_result[i]);
      features[s * 4 + 2][i] = cabs(cwt_result[i]);
      features[s * 4 + 3][i] = carg(cwt_result[i]);
    }

    free(cwt_result);
    free(wavelet);
  }

  free(signal);
  return true;

==> src/fasta_parser.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/fasta_parser.h"
#include "../include/sunfish.h"

void free_fasta_data(FastaData* data) {
  if (!data)
    return;
  for (int i = 0; i < data->count; i++) {
    free(data->records[i].id);
    free(data->records[i].sequence);
  }
  free(data->records);
  free(data);
}

FastaData* parse_fasta(const char* path) {
  FILE* fp = fopen(path, "r");
  if (!fp) {
    fprintf(stderr, "Error: Cannot open FASTA file: %s\n", path);
    return NULL;
  }
  FastaData* data = (FastaData*)calloc(1, sizeof(FastaData));
  if (!data) {
    fclose(fp);
    return NULL;
  }
  int cap = 16;
  data->records = (FastaRecord*)malloc(cap * sizeof(FastaRecord));
  data->count = 0;
  char line[MAX_LINE_LEN];
  char* cur = NULL;
  size_t cur_cap = 0;
  size_t cur_len = 0;
  while (fgets(line, sizeof(line), fp)) {
    size_t len = strlen(line);
    while (len && (line[len - 1] == '\n' || line[len - 1] == '\r'))
      line[--len] = '\0';
    if (line[0] == '>') {
      if (cur) {
        data->records[data->count - 1].sequence = cur;
        cur = NULL;
      }
      if (data->count >= cap) {
        cap *= 2;
        data->records =
            (FastaRecord*)realloc(data->records, cap * sizeof(FastaRecord));
      }
      const char* header = line + 1;
      size_t id_len = 0;
      while (header[id_len] && !isspace((unsigned char)header[id_len]))
        id_len++;
      char* id = (char*)malloc(id_len + 1);
      memcpy(id, header, id_len);
      id[id_len] = '\0';
      data->records[data->count].id = id;
      data->records[data->count].sequence = NULL;
      data->count++;
      cur_cap = 8192;
      cur_len = 0;
      cur = (char*)malloc(cur_cap);
      cur[0] = '\0';
    } else if (cur) {
      size_t ll = strlen(line);
      while (cur_len + ll + 1 > cur_cap) {
        cur_cap *= 2;
        cur = (char*)realloc(cur, cur_cap);
      }
      memcpy(cur + cur_len, line, ll + 1);
      cur_len += ll;
    }
  }
  if (cur && data->count > 0)
    data->records[data->count - 1].sequence = cur;
  fclose(fp);
  return data;

==> src/fft.c <==
#include <complex.h>
#include <math.h>
#include <stdbool.h>
#include <stdlib.h>
#include <string.h>

#include "../include/fft.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

bool is_power_of_2(int n) {
  return n > 0 && (n & (n - 1)) == 0;
}

int next_power_of_2(int n) {
  if (n <= 0)
    return 1;
  n--;
  n |= n >> 1;
  n |= n >> 2;
  n |= n >> 4;
  n |= n >> 8;
  n |= n >> 16;
  n++;
  return n;
}

/**
 * Bit-reversal permutation for FFT.
 * @param x Array to permute
 * @param N Length of array (must be power of 2)
 */
static void bit_reverse_copy(cplx* x, int N) {
  int j = 0;
  for (int i = 0; i < N; i++) {
    if (i < j) {
      cplx temp = x[i];
      x[i] = x[j];
      x[j] = temp;
    }
    int m = N / 2;
    while (m >= 1 && j >= m) {
      j -= m;
      m /= 2;
    }
    j += m;
  }
}

/**
 * Cooley-Tukey FFT implementation (iterative, in-place).
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 * @param inverse If true, compute inverse FFT (without normalization)
 */
void fft(cplx* x, int N, bool inverse) {
  if (!is_power_of_2(N)) {
    // For simplicity, we require N to be a power of 2
    return;
  }

  // Bit-reversal permutation
  bit_reverse_copy(x, N);

  // FFT computation
  double direction = inverse ? 1.0 : -1.0;
  
  for (int s = 1; s <= (int)(log2(N)); s++) {
    int m = 1 << s; // 2^s
    double theta = direction * 2.0 * M_PI / m;
    cplx wm = cexp(I * theta);
    
    for (int k = 0; k < N; k += m) {
      cplx w = 1.0;
      for (int j = 0; j < m / 2; j++) {
        cplx t = w * x[k + j + m / 2];
        cplx u = x[k + j];
        x[k + j] = u + t;
        x[k + j + m / 2] = u - t;
        w = w * wm;
      }
    }
  }

  // Normalization for inverse FFT
  if (inverse) {
    for (int i = 0; i < N; i++) {
      x[i] /= N;
    }
  }
}

/**
 * Compute inverse FFT with proper normalization.
 * @param x Input/output array of complex numbers
 * @param N Length of array (must be power of 2)
 */
void ifft(cplx* x, int N) {
  fft(x, N, true);

==> src/gff_parser.c <==
#define _POSIX_C_SOURCE 200809L

#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/gff_parser.h"
#include "../include/sunfish.h"

void free_cds_groups(CdsGroup* groups, int count) {
  if (!groups)
    return;
  for (int i = 0; i < count; i++) {
    free(groups[i].parent_id);
    if (groups[i].exons) {
      for (int j = 0; j < groups[i].exon_count; j++) {
        free(groups[i].exons[j].seqid);
      }
      free(groups[i].exons);
    }
  }
  free(groups);
}

CdsGroup* parse_gff_for_cds(const char* path, int* group_count) {
  FILE* fp = fopen(path, "r");
  if (!fp) {
    fprintf(stderr, "Error: Cannot open GFF3 file: %s\n", path);
    *group_count = 0;
    return NULL;
  }
  typedef struct {
    char* parent;
    char* seqid;
    int start;
    int end;
    char strand;
    int phase;
  } CdsTemp;
  int temp_cap = 128, temp_cnt = 0;
  CdsTemp* tmp = (CdsTemp*)malloc(temp_cap * sizeof(CdsTemp));
  char line[MAX_LINE_LEN];
  while (fgets(line, sizeof(line), fp)) {
    if (line[0] == '#' || line[0] == '\n')
      continue;
    char seqid[256], source[256], type[256], strand_char, phase_char;
    int start, end;
    char score[256], attrs[MAX_LINE_LEN];
    int n = sscanf(line, "%255s\t%255s\t%255s\t%d\t%d\t%255s\t%c\t%c\t%[^\n]",
                   seqid, source, type, &start, &end, score, &strand_char,
                   &phase_char, attrs);
    if (n < 9 || strcmp(type, "CDS") != 0)
      continue;
    char* p = strstr(attrs, "Parent=");
    if (!p)
      continue;
    p += 7;
    char* sc = strchr(p, ';');
    size_t plen = sc ? (size_t)(sc - p) : strlen(p);
    char parent[256];
    if (plen >= sizeof(parent))
      plen = sizeof(parent) - 1;
    memcpy(parent, p, plen);
    parent[plen] = '\0';
    if (temp_cnt >= temp_cap) {
      temp_cap *= 2;
      tmp = (CdsTemp*)realloc(tmp, temp_cap * sizeof(CdsTemp));
    }
    tmp[temp_cnt].parent = strdup(parent);
    tmp[temp_cnt].seqid = strdup(seqid);
    tmp[temp_cnt].start = start;
    tmp[temp_cnt].end = end;
    tmp[temp_cnt].strand = strand_char;
    tmp[temp_cnt].phase = phase_char - '0';
    temp_cnt++;
  }
  fclose(fp);
  int grp_cap = 64, grp_cnt = 0;
  CdsGroup* groups = (CdsGroup*)malloc(grp_cap * sizeof(CdsGroup));
  for (int i = 0; i < temp_cnt; i++) {
    int gi = -1;
    for (int j = 0; j < grp_cnt; j++) {
      if (strcmp(groups[j].parent_id, tmp[i].parent) == 0) {
        gi = j;
        break;
      }
    }
    if (gi == -1) {
      if (grp_cnt >= grp_cap) {
        grp_cap *= 2;
        groups = (CdsGroup*)realloc(groups, grp_cap * sizeof(CdsGroup));
      }
      gi = grp_cnt++;
      groups[gi].parent_id = strdup(tmp[i].parent);
      groups[gi].exons = NULL;
      groups[gi].exon_count = 0;
    }
    int ei = groups[gi].exon_count++;
    groups[gi].exons =
        (Exon*)realloc(groups[gi].exons, groups[gi].exon_count * sizeof(Exon));
    groups[gi].exons[ei].seqid = strdup(tmp[i].seqid);
    groups[gi].exons[ei].start = tmp[i].start;
    groups[gi].exons[ei].end = tmp[i].end;
    groups[gi].exons[ei].strand = tmp[i].strand;
    groups[gi].exons[ei].phase = tmp[i].phase;
  }
  for (int i = 0; i < temp_cnt; i++) {
    free(tmp[i].parent);
    free(tmp[i].seqid);
  }
  free(tmp);
  *group_count = grp_cnt;
  return groups;

==> src/hmm.c <==
#include <math.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/hmm.h"

#ifndef M_PI
#define M_PI 3.14159265358979323846
#endif

static inline bool hmm_is_exon_state(int state) {
  return state == STATE_EXON_F0 || state == STATE_EXON_F1 ||
         state == STATE_EXON_F2;
}

static inline char normalize_base(char base) {
  if (base >= 'a' && base <= 'z') {
    return (char)(base - ('a' - 'A'));
  }
  return base;
}

static inline bool is_strict_dna_base(char base) {
  switch (base) {
  case 'A':
  case 'C':
  case 'G':
  case 'T':
    return true;
  default:
    return false;
  }
}

static inline int base_to_index(char base) {
  switch (base) {
  case 'A':
    return 0;
  case 'C':
    return 1;
  case 'G':
    return 2;
  case 'T':
    return 3;
  default:
    return -1;
  }
}

static double pwm_score_at(const double pwm[][DONOR_MOTIF_SIZE], int pwm_len,
                          const char* sequence, int seq_len, int start_pos) {
  if (!sequence || start_pos < 0 || start_pos + pwm_len > seq_len) {
    return 0.0;
  }
  
  double score = 0.0;
  for (int i = 0; i < pwm_len; i++) {
    char base = normalize_base(sequence[start_pos + i]);
    int idx = base_to_index(base);
    if (idx < 0) {
      return 0.0; // Invalid base, no contribution
    }
    score += pwm[idx][i];
  }
  return score;
}

static double pwm_score_acceptor(const double pwm[][ACCEPTOR_MOTIF_SIZE],
                                 const char* sequence, int seq_len, int start_pos) {
  if (!sequence || start_pos < 0 || start_pos + ACCEPTOR_MOTIF_SIZE > seq_len) {
    return 0.0;
  }
  
  double score = 0.0;
  for (int i = 0; i < ACCEPTOR_MOTIF_SIZE; i++) {
    char base = normalize_base(sequence[start_pos + i]);
    int idx = base_to_index(base);
    if (idx < 0) {
      return 0.0; // Invalid base, no contribution
    }
    score += pwm[idx][i];
  }
  return score;
}

static double splice_signal_adjustment(const char* sequence, int seq_len,
                                       int prev_state, int curr_state,
                                       int position, const PWMModel* pwm) {
  if (!sequence || seq_len <= 0) {
    return 0.0;
  }

  // Empirically chosen log-scale bonuses and penalties
  static const double kMatchBonus = 1e-3;
  static const double kMismatchPenalty = -1e-3;

  double adjustment = 0.0;

  // Exon -> Intron transition (donor site)
  if (hmm_is_exon_state(prev_state) && curr_state == STATE_INTRON) {
    if (position + 1 >= seq_len) {
      return 0.0;
    }

    // Simple GT check
    char first = normalize_base(sequence[position]);
    char second = normalize_base(sequence[position + 1]);
    if (is_strict_dna_base(first) && is_strict_dna_base(second)) {
      adjustment += (first == 'G' && second == 'T') ? kMatchBonus : kMismatchPenalty;
    }

    // Add PWM score if available
    if (pwm && pwm->has_donor) {
      int donor_start = position;
      double pwm_score = pwm_score_at((const double (*)[DONOR_MOTIF_SIZE])pwm->donor_pwm,
                                     DONOR_MOTIF_SIZE, sequence, seq_len, donor_start);
      adjustment += pwm_score * pwm->pwm_weight;
    }
  }

  // Intron -> Exon transition (acceptor site)
  if (prev_state == STATE_INTRON && hmm_is_exon_state(curr_state)) {
    if (position - 2 < 0 || position - 1 < 0) {
      return 0.0;
    }

    // Simple AG check
    char penultimate = normalize_base(sequence[position - 2]);
    char ultimate = normalize_base(sequence[position - 1]);
    if (is_strict_dna_base(penultimate) && is_strict_dna_base(ultimate)) {
      adjustment += (penultimate == 'A' && ultimate == 'G') ? kMatchBonus : kMismatchPenalty;
    }

    // Add PWM score if available
    if (pwm && pwm->has_acceptor) {
      int acceptor_start = position - ACCEPTOR_MOTIF_SIZE;
      double pwm_score = pwm_score_acceptor((const double (*)[ACCEPTOR_MOTIF_SIZE])pwm->acceptor_pwm,
                                           sequence, seq_len, acceptor_start);
      adjustment += pwm_score * pwm->pwm_weight;
    }
  }

  return adjustment;
}

void hmm_init(HMMModel* model, int num_features) {
  if (num_features > MAX_NUM_FEATURES) {
    num_features = MAX_NUM_FEATURES;
  }

  model->num_features = num_features;
  model->wavelet_feature_count = 0;
  model->kmer_feature_count = 0;
  model->kmer_size = 0;

  // Initialize uniform transition probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    double sum = 0.0;
    for (int j = 0; j < NUM_STATES; j++) {
      model->transition[i][j] = 1.0 / NUM_STATES;
      sum += model->transition[i][j];
    }
    // Normalize
    for (int j = 0; j < NUM_STATES; j++) {
      model->transition[i][j] /= sum;
    }
  }

  // Initialize uniform initial probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    model->initial[i] = 1.0 / NUM_STATES;
  }

  // Initialize emission parameters with random values
  for (int i = 0; i < NUM_STATES; i++) {
    model->emission[i].num_features = num_features;
    for (int j = 0; j < num_features; j++) {
      // Random mean between 0 and 1
      model->emission[i].mean[j] = (double)rand() / RAND_MAX;
      // Small variance
      model->emission[i].variance[j] = 0.1;
    }
  }

  for (int f = 0; f < num_features; f++) {
    model->global_feature_mean[f] = 0.0;
    model->global_feature_stddev[f] = 1.0;
  }

  // Initialize PWM model
  model->pwm.has_donor = 0;
  model->pwm.has_acceptor = 0;
  model->pwm.pwm_weight = 1.0;
  model->pwm.min_donor_score = 0.0;
  model->pwm.min_acceptor_score = 0.0;
  for (int i = 0; i < NUM_NUCLEOTIDES; i++) {
    for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
      model->pwm.donor_pwm[i][j] = 0.0;
    }
    for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
      model->pwm.acceptor_pwm[i][j] = 0.0;
    }
  }
}

double gaussian_log_pdf(const double* observation, const double* mean,
                        const double* variance, int num_features) {
  double log_prob = 0.0;

  // For diagonal covariance, we can compute the PDF as product of univariate
  // Gaussians
  for (int i = 0; i < num_features; i++) {
    double diff = observation[i] - mean[i];
    double var = variance[i];

    // Prevent numerical issues with very small variance
    if (var < 1e-6) {
      var = 1e-6;
    }

    // Log of univariate Gaussian PDF
    log_prob += -0.5 * log(2.0 * M_PI * var) - 0.5 * (diff * diff) / var;
  }

  return log_prob;
}

// Forward algorithm for Baum-Welch
static double forward_algorithm(const HMMModel* model, double** observations,
                                int seq_len, double** alpha) {
  // alpha[t][i] = P(O_1, O_2, ..., O_t, S_t = i | model)

  // Initialization (t=0)
  for (int i = 0; i < NUM_STATES; i++) {
    alpha[0][i] =
        log(model->initial[i]) +
        gaussian_log_pdf(observations[0], model->emission[i].mean,
                         model->emission[i].variance, model->num_features);
  }

  // Induction (t=1 to T-1)
  for (int t = 1; t < seq_len; t++) {
    for (int j = 0; j < NUM_STATES; j++) {
      double max_val = -INFINITY;
      double sum = 0.0;

      // Log-sum-exp trick for numerical stability
      for (int i = 0; i < NUM_STATES; i++) {
        double val = alpha[t - 1][i] + log(model->transition[i][j]);
        if (val > max_val) {
          max_val = val;
        }
      }

      for (int i = 0; i < NUM_STATES; i++) {
        double val = alpha[t - 1][i] + log(model->transition[i][j]);
        sum += exp(val - max_val);
      }

      alpha[t][j] =
          max_val + log(sum) +
          gaussian_log_pdf(observations[t], model->emission[j].mean,
                           model->emission[j].variance, model->num_features);
    }
  }

  // Termination - compute total log probability
  double max_val = -INFINITY;
  for (int i = 0; i < NUM_STATES; i++) {
    if (alpha[seq_len - 1][i] > max_val) {
      max_val = alpha[seq_len - 1][i];
    }
  }

  double sum = 0.0;
  for (int i = 0; i < NUM_STATES; i++) {
    sum += exp(alpha[seq_len - 1][i] - max_val);
  }

  return max_val + log(sum);
}

// Backward algorithm for Baum-Welch
static void backward_algorithm(const HMMModel* model, double** observations,
                               int seq_len, double** beta) {
  // beta[t][i] = P(O_{t+1}, O_{t+2}, ..., O_T | S_t = i, model)

  // Initialization (t=T-1)
  for (int i = 0; i < NUM_STATES; i++) {
    beta[seq_len - 1][i] = 0.0; // log(1) = 0
  }

  // Induction (t=T-2 down to 0)
  for (int t = seq_len - 2; t >= 0; t--) {
    for (int i = 0; i < NUM_STATES; i++) {
      double max_val = -INFINITY;
      double sum = 0.0;

      // Log-sum-exp trick
      for (int j = 0; j < NUM_STATES; j++) {
        double val =
            log(model->transition[i][j]) + beta[t + 1][j] +
            gaussian_log_pdf(observations[t + 1], model->emission[j].mean,
                             model->emission[j].variance, model->num_features);
        if (val > max_val) {
          max_val = val;
        }
      }

      for (int j = 0; j < NUM_STATES; j++) {
        double val =
            log(model->transition[i][j]) + beta[t + 1][j] +
            gaussian_log_pdf(observations[t + 1], model->emission[j].mean,
                             model->emission[j].variance, model->num_features);
        sum += exp(val - max_val);
      }

      beta[t][i] = max_val + log(sum);
    }
  }
}

bool hmm_train_baum_welch(HMMModel* model, double*** observations,
                          int* seq_lengths, int num_sequences,
                          int max_iterations, double convergence_threshold) {
  double prev_log_likelihood = -INFINITY;

  for (int iter = 0; iter < max_iterations; iter++) {
    double total_log_likelihood = 0.0;

    // Accumulators for M-step
    double initial_acc[NUM_STATES] = {0};
    double transition_acc[NUM_STATES][NUM_STATES] = {{0}};
    double emission_mean_acc[NUM_STATES][MAX_NUM_FEATURES] = {{0}};
    double emission_var_acc[NUM_STATES][MAX_NUM_FEATURES] = {{0}};
    double state_count[NUM_STATES] = {0};

    // E-step: compute forward-backward for all sequences
    for (int seq = 0; seq < num_sequences; seq++) {
      int T = seq_lengths[seq];

      // Allocate alpha and beta matrices
      double** alpha = (double**)malloc(T * sizeof(double*));
      double** beta = (double**)malloc(T * sizeof(double*));
      for (int t = 0; t < T; t++) {
        alpha[t] = (double*)malloc(NUM_STATES * sizeof(double));
        beta[t] = (double*)malloc(NUM_STATES * sizeof(double));
      }

      // Run forward-backward
      double log_prob = forward_algorithm(model, observations[seq], T, alpha);
      backward_algorithm(model, observations[seq], T, beta);
      total_log_likelihood += log_prob;

      // Compute gamma and xi
      for (int t = 0; t < T; t++) {
        // gamma[t][i] = P(S_t = i | O, model)
        double gamma_norm = -INFINITY;
        double gamma[NUM_STATES];

        for (int i = 0; i < NUM_STATES; i++) {
          gamma[i] = alpha[t][i] + beta[t][i];
          if (gamma[i] > gamma_norm) {
            gamma_norm = gamma[i];
          }
        }

        double gamma_sum = 0.0;
        for (int i = 0; i < NUM_STATES; i++) {
          gamma[i] = exp(gamma[i] - gamma_norm);
          gamma_sum += gamma[i];
        }

        for (int i = 0; i < NUM_STATES; i++) {
          gamma[i] /= gamma_sum;

          if (t == 0) {
            initial_acc[i] += gamma[i];
          }

          state_count[i] += gamma[i];

          // Accumulate for emission parameters
          for (int f = 0; f < model->num_features; f++) {
            emission_mean_acc[i][f] += gamma[i] * observations[seq][t][f];
            emission_var_acc[i][f] +=
                gamma[i] * observations[seq][t][f] * observations[seq][t][f];
          }
        }

        // Compute xi for transition probabilities (if not last time step)
        if (t < T - 1) {
          double xi[NUM_STATES][NUM_STATES];
          double xi_norm = -INFINITY;

          for (int i = 0; i < NUM_STATES; i++) {
            for (int j = 0; j < NUM_STATES; j++) {
              xi[i][j] = alpha[t][i] + log(model->transition[i][j]) +
                         gaussian_log_pdf(
                             observations[seq][t + 1], model->emission[j].mean,
                             model->emission[j].variance, model->num_features) +
                         beta[t + 1][j];
              if (xi[i][j] > xi_norm) {
                xi_norm = xi[i][j];
              }
            }
          }

          double xi_sum = 0.0;
          for (int i = 0; i < NUM_STATES; i++) {
            for (int j = 0; j < NUM_STATES; j++) {
              xi[i][j] = exp(xi[i][j] - xi_norm);
              xi_sum += xi[i][j];
            }
          }

          for (int i = 0; i < NUM_STATES; i++) {
            for (int j = 0; j < NUM_STATES; j++) {
              transition_acc[i][j] += xi[i][j] / xi_sum;
            }
          }
        }
      }

      // Free alpha and beta
      for (int t = 0; t < T; t++) {
        free(alpha[t]);
        free(beta[t]);
      }
      free(alpha);
      free(beta);
    }

    // M-step: update parameters
    // Update initial probabilities
    double initial_sum = 0.0;
    for (int i = 0; i < NUM_STATES; i++) {
      initial_sum += initial_acc[i];
    }
    for (int i = 0; i < NUM_STATES; i++) {
      model->initial[i] = initial_acc[i] / initial_sum;
      if (model->initial[i] < 1e-10)
        model->initial[i] = 1e-10;
    }

    // Update transition probabilities
    for (int i = 0; i < NUM_STATES; i++) {
      double trans_sum = 0.0;
      for (int j = 0; j < NUM_STATES; j++) {
        trans_sum += transition_acc[i][j];
      }
      for (int j = 0; j < NUM_STATES; j++) {
        if (trans_sum > 0) {
          model->transition[i][j] = transition_acc[i][j] / trans_sum;
        } else {
          model->transition[i][j] = 1.0 / NUM_STATES;
        }
        if (model->transition[i][j] < 1e-10)
          model->transition[i][j] = 1e-10;
      }
    }

    // Update emission parameters
    for (int i = 0; i < NUM_STATES; i++) {
      if (state_count[i] > 0) {
        for (int f = 0; f < model->num_features; f++) {
          double mean = emission_mean_acc[i][f] / state_count[i];
          double mean_sq = emission_var_acc[i][f] / state_count[i];
          double var = mean_sq - mean * mean;

          model->emission[i].mean[f] = mean;
          model->emission[i].variance[f] = var > 1e-6 ? var : 1e-6;
        }
      }
    }

    // Check convergence
    fprintf(stderr, "Iteration %d: Log-likelihood = %.4f\n", iter + 1,
            total_log_likelihood);

    if (iter > 0 && fabs(total_log_likelihood - prev_log_likelihood) <
                        convergence_threshold) {
      fprintf(stderr, "Converged after %d iterations\n", iter + 1);
      break;
    }

    prev_log_likelihood = total_log_likelihood;
  }

  return true;
}

double hmm_viterbi(const HMMModel* model, double** observations,
                   const char* sequence, int seq_len, int* states) {
  // Allocate Viterbi matrices
  double** delta = (double**)malloc(seq_len * sizeof(double*));
  int** psi = (int**)malloc(seq_len * sizeof(int*));

  for (int t = 0; t < seq_len; t++) {
    delta[t] = (double*)malloc(NUM_STATES * sizeof(double));
    psi[t] = (int*)malloc(NUM_STATES * sizeof(int));
  }

  // Initialization (t=0)
  for (int i = 0; i < NUM_STATES; i++) {
    delta[0][i] =
        log(model->initial[i]) +
        gaussian_log_pdf(observations[0], model->emission[i].mean,
                         model->emission[i].variance, model->num_features);
    psi[0][i] = 0;
  }

  // Recursion (t=1 to T-1)
  for (int t = 1; t < seq_len; t++) {
    for (int j = 0; j < NUM_STATES; j++) {
      double max_val = -INFINITY;
      int max_state = 0;

      for (int i = 0; i < NUM_STATES; i++) {
        double transition_log = log(model->transition[i][j]);
        transition_log += splice_signal_adjustment(sequence, seq_len, i, j, t, &model->pwm);
        double val = delta[t - 1][i] + transition_log;
        if (val > max_val) {
          max_val = val;
          max_state = i;
        }
      }

      delta[t][j] =
          max_val + gaussian_log_pdf(observations[t], model->emission[j].mean,
                                     model->emission[j].variance,
                                     model->num_features);
      psi[t][j] = max_state;
    }
  }

  // Termination - find best final state
  double max_prob = -INFINITY;
  int best_state = 0;
  for (int i = 0; i < NUM_STATES; i++) {
    if (delta[seq_len - 1][i] > max_prob) {
      max_prob = delta[seq_len - 1][i];
      best_state = i;
    }
  }

  // Backtrack
  states[seq_len - 1] = best_state;
  for (int t = seq_len - 2; t >= 0; t--) {
    states[t] = psi[t + 1][states[t + 1]];
  }

  // Free matrices
  for (int t = 0; t < seq_len; t++) {
    free(delta[t]);
    free(psi[t]);
  }
  free(delta);
  free(psi);

  return max_prob;
}

bool hmm_save_model(const HMMModel* model, const char* filename) {
  FILE* fp = fopen(filename, "w");
  if (fp == NULL) {
    return false;
  }

  fprintf(fp, "#HMM_MODEL_V1\n");
  fprintf(fp, "#num_features %d\n", model->num_features);
  fprintf(fp, "#wavelet_features %d\n", model->wavelet_feature_count);
  fprintf(fp, "#kmer_features %d\n", model->kmer_feature_count);
  fprintf(fp, "#kmer_size %d\n", model->kmer_size);
  fprintf(fp, "#num_states %d\n", NUM_STATES);

  // Save initial probabilities
  fprintf(fp, "INITIAL\n");
  for (int i = 0; i < NUM_STATES; i++) {
    fprintf(fp, "%.10f ", model->initial[i]);
  }
  fprintf(fp, "\n");

  // Save transition matrix
  fprintf(fp, "TRANSITION\n");
  for (int i = 0; i < NUM_STATES; i++) {
    for (int j = 0; j < NUM_STATES; j++) {
      fprintf(fp, "%.10f ", model->transition[i][j]);
    }
    fprintf(fp, "\n");
  }

  // Save emission parameters
  fprintf(fp, "EMISSION\n");
  for (int i = 0; i < NUM_STATES; i++) {
    fprintf(fp, "STATE %d\n", i);
    fprintf(fp, "MEAN ");
    for (int j = 0; j < model->num_features; j++) {
      fprintf(fp, "%.10f ", model->emission[i].mean[j]);
    }
    fprintf(fp, "\n");
    fprintf(fp, "VARIANCE ");
    for (int j = 0; j < model->num_features; j++) {
      fprintf(fp, "%.10f ", model->emission[i].variance[j]);
    }
    fprintf(fp, "\n");
  }

  // Save global feature statistics for Z-score normalization
  fprintf(fp, "GLOBAL_STATS\n");
  fprintf(fp, "MEAN ");
  for (int i = 0; i < model->num_features; i++) {
    fprintf(fp, "%.10f ", model->global_feature_mean[i]);
  }
  fprintf(fp, "\n");
  fprintf(fp, "STDDEV ");
  for (int i = 0; i < model->num_features; i++) {
    fprintf(fp, "%.10f ", model->global_feature_stddev[i]);
  }
  fprintf(fp, "\n");

  // Save PWM if present
  if (model->pwm.has_donor || model->pwm.has_acceptor) {
    fprintf(fp, "PWM\n");
    fprintf(fp, "WEIGHT %.10f\n", model->pwm.pwm_weight);
    
    if (model->pwm.has_donor) {
      fprintf(fp, "DONOR %d\n", DONOR_MOTIF_SIZE);
      fprintf(fp, "A:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[0][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "C:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[1][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "G:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[2][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "T:");
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.donor_pwm[3][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "MIN_SCORE %.10f\n", model->pwm.min_donor_score);
    }
    
    if (model->pwm.has_acceptor) {
      fprintf(fp, "ACCEPTOR %d\n", ACCEPTOR_MOTIF_SIZE);
      fprintf(fp, "A:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[0][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "C:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[1][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "G:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[2][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "T:");
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        fprintf(fp, " %.10f", model->pwm.acceptor_pwm[3][j]);
      }
      fprintf(fp, "\n");
      fprintf(fp, "MIN_SCORE %.10f\n", model->pwm.min_acceptor_score);
    }
  }

  fclose(fp);
  return true;
}

bool hmm_load_model(HMMModel* model, const char* filename) {
  FILE* fp = fopen(filename, "r");
  if (fp == NULL) {
    return false;
  }

  char line[1024];

  // Read header
  if (fgets(line, sizeof(line), fp) == NULL) {
    fclose(fp);
    return false;
  }

  model->num_features = 0;
  model->wavelet_feature_count = 0;
  model->kmer_feature_count = 0;
  model->kmer_size = 0;

  int tmp_num_states = NUM_STATES;

  while (true) {
    long pos = ftell(fp);
    if (fgets(line, sizeof(line), fp) == NULL) {
      fclose(fp);
      return false;
    }

    if (line[0] != '#') {
      // Rewind so the next read starts at this non-metadata line
      fseek(fp, pos, SEEK_SET);
      break;
    }

    if (sscanf(line, "#num_features %d", &model->num_features) == 1)
      continue;
    if (sscanf(line, "#wavelet_features %d", &model->wavelet_feature_count) ==
        1)
      continue;
    if (sscanf(line, "#kmer_features %d", &model->kmer_feature_count) == 1)
      continue;
    if (sscanf(line, "#kmer_size %d", &model->kmer_size) == 1)
      continue;
    (void)sscanf(line, "#num_states %d", &tmp_num_states);
  }

  if (model->num_features > MAX_NUM_FEATURES)
    model->num_features = MAX_NUM_FEATURES;

  if (model->wavelet_feature_count < 0)
    model->wavelet_feature_count = 0;
  if (model->kmer_feature_count < 0)
    model->kmer_feature_count = 0;

  if (model->wavelet_feature_count + model->kmer_feature_count == 0) {
    model->wavelet_feature_count = model->num_features;
  } else if (model->wavelet_feature_count == 0 &&
             model->kmer_feature_count <= model->num_features) {
    model->wavelet_feature_count =
        model->num_features - model->kmer_feature_count;
  }

  if (model->wavelet_feature_count > model->num_features)
    model->wavelet_feature_count = model->num_features;

  if (model->wavelet_feature_count + model->kmer_feature_count >
      model->num_features) {
    model->kmer_feature_count =
        model->num_features - model->wavelet_feature_count;
    if (model->kmer_feature_count < 0)
      model->kmer_feature_count = 0;
  }

  if (model->kmer_size < 0)
    model->kmer_size = 0;

  // Read initial probabilities
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "INITIAL", 7) == 0) {
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = line;
      for (int i = 0; i < NUM_STATES; i++) {
        if (sscanf(ptr, "%lf", &model->initial[i]) != 1)
          break;
        ptr = strchr(ptr, ' ');
        if (ptr)
          ptr++;
        else
          break;
      }
    } else {
      fclose(fp);
      return false;
    }
  }

  // Read transition matrix
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "TRANSITION", 10) == 0) {
    for (int i = 0; i < NUM_STATES; i++) {
      if (fgets(line, sizeof(line), fp) != NULL) {
        char* ptr = line;
        for (int j = 0; j < NUM_STATES; j++) {
          if (sscanf(ptr, "%lf", &model->transition[i][j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      } else {
        fclose(fp);
        return false;
      }
    }
  }

  // Read emission parameters
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "EMISSION", 8) == 0) {
    for (int i = 0; i < NUM_STATES; i++) {
      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }

      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }
      // MEAN
      char* ptr = strstr(line, "MEAN");
      if (ptr) {
        ptr += 5;
        for (int j = 0; j < model->num_features; j++) {
          if (sscanf(ptr, "%lf", &model->emission[i].mean[j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }

      if (fgets(line, sizeof(line), fp) == NULL) {
        fclose(fp);
        return false;
      }
      // VARIANCE
      ptr = strstr(line, "VARIANCE");
      if (ptr) {
        ptr += 9;
        for (int j = 0; j < model->num_features; j++) {
          if (sscanf(ptr, "%lf", &model->emission[i].variance[j]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }

      model->emission[i].num_features = model->num_features;
    }
  }

  // Read global feature statistics (optional for backward compatibility)
  if (fgets(line, sizeof(line), fp) != NULL &&
      strncmp(line, "GLOBAL_STATS", 12) == 0) {
    // Read MEAN line
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = strstr(line, "MEAN");
      if (ptr) {
        ptr += 5;
        for (int i = 0; i < model->num_features; i++) {
          if (sscanf(ptr, "%lf", &model->global_feature_mean[i]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }
    }

    // Read STDDEV line
    if (fgets(line, sizeof(line), fp) != NULL) {
      char* ptr = strstr(line, "STDDEV");
      if (ptr) {
        ptr += 7;
        for (int i = 0; i < model->num_features; i++) {
          if (sscanf(ptr, "%lf", &model->global_feature_stddev[i]) != 1)
            break;
          ptr = strchr(ptr, ' ');
          if (ptr)
            ptr++;
          else
            break;
        }
      }
    }
  } else {
    // Initialize to default values if not present (backward compatibility)
    for (int i = 0; i < model->num_features; i++) {
      model->global_feature_mean[i] = 0.0;
      model->global_feature_stddev[i] = 1.0;
    }
  }

  // Initialize PWM with defaults
  model->pwm.has_donor = 0;
  model->pwm.has_acceptor = 0;
  model->pwm.pwm_weight = 1.0;
  model->pwm.min_donor_score = 0.0;
  model->pwm.min_acceptor_score = 0.0;

  // Read PWM block if present (optional for backward compatibility)
  if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "PWM", 3) == 0) {
    // Read WEIGHT line
    if (fgets(line, sizeof(line), fp) != NULL) {
      if (sscanf(line, "WEIGHT %lf", &model->pwm.pwm_weight) != 1) {
        model->pwm.pwm_weight = 1.0;
      }
    }

    // Read DONOR or ACCEPTOR blocks
    while (fgets(line, sizeof(line), fp) != NULL) {
      if (strncmp(line, "DONOR", 5) == 0) {
        int donor_size = 0;
        if (sscanf(line, "DONOR %d", &donor_size) == 1 && 
            donor_size == DONOR_MOTIF_SIZE) {
          model->pwm.has_donor = 1;
          
          // Read A: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "A:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[0][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read C: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "C:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[1][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read G: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "G:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[2][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read T: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "T:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.donor_pwm[3][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read MIN_SCORE line
          if (fgets(line, sizeof(line), fp) != NULL) {
            sscanf(line, "MIN_SCORE %lf", &model->pwm.min_donor_score);
          }
        }
      } else if (strncmp(line, "ACCEPTOR", 8) == 0) {
        int acceptor_size = 0;
        if (sscanf(line, "ACCEPTOR %d", &acceptor_size) == 1 && 
            acceptor_size == ACCEPTOR_MOTIF_SIZE) {
          model->pwm.has_acceptor = 1;
          
          // Read A: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "A:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[0][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read C: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "C:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[1][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read G: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "G:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[2][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read T: line
          if (fgets(line, sizeof(line), fp) != NULL && strncmp(line, "T:", 2) == 0) {
            char* ptr = line + 2;
            for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
              if (sscanf(ptr, "%lf", &model->pwm.acceptor_pwm[3][j]) != 1) break;
              ptr = strchr(ptr, ' ');
              if (ptr) ptr++; else break;
            }
          }
          // Read MIN_SCORE line
          if (fgets(line, sizeof(line), fp) != NULL) {
            sscanf(line, "MIN_SCORE %lf", &model->pwm.min_acceptor_score);
          }
        }
      }
    }
  }

  fclose(fp);
  return true;

==> src/sunfish.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <errno.h>
#include <limits.h>
#include <math.h>
#include <pthread.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>

#include "../include/cwt.h"
#include "../include/fft.h"
#include "../include/hmm.h"
#include "../include/sunfish.h"
#include "../include/thread_pool.h"

// Global configuration
// Default wavelet scales: powers of 3 from 3
static int g_num_wavelet_scales = 8;
static double g_wavelet_scales[MAX_NUM_WAVELETS] = {
    3.0, 9.0, 27.0, 81.0, 243.0, 729.0, 2187.0, 6561.0};
// Default: 0 means "not set"; we'll use number of online processors at runtime
static int g_num_threads = 0;
static int g_kmer_size = 2;
static int g_kmer_feature_count = 16; // 4^2 for default k-mer size 2
static int g_total_feature_count =
    32; // 16 wavelet + 16 k-mer features by default

// Chunk-based prediction configuration
static int g_chunk_size = 50000;    // Default chunk size: 50kb
static int g_chunk_overlap = 5000;  // Default overlap: 5kb
static bool g_use_chunking = false; // Disabled by default; enable via CLI

// Thread-safe output queue
typedef struct output_node_t {
  char* gff_line;
  struct output_node_t* next;
} output_node_t;

typedef struct {
  output_node_t* head;
  output_node_t* tail;
  pthread_mutex_t mutex;
} output_queue_t;

static output_queue_t g_output_queue;
static pthread_mutex_t g_gene_counter_mutex = PTHREAD_MUTEX_INITIALIZER;
static int g_gene_counter = 0;

static int parse_threads_value(const char* arg) {
  if (arg == NULL)
    return -1;

  char* endptr = NULL;
  errno = 0;
  long value = strtol(arg, &endptr, 10);

  if (errno != 0 || endptr == arg || *endptr != '\0')
    return -1;

  if (value < 1 || value > INT_MAX)
    return -1;

  return (int)value;
}

static bool parse_non_negative_int(const char* arg, int* out_value) {
  if (arg == NULL || out_value == NULL)
    return false;

  char* endptr = NULL;
  errno = 0;
  long value = strtol(arg, &endptr, 10);

  if (errno != 0 || endptr == arg || *endptr != '\0')
    return false;

  if (value < 0 || value > INT_MAX)
    return false;

  *out_value = (int)value;
  return true;
}

static int detect_hardware_threads(void) {
  long nprocs = sysconf(_SC_NPROCESSORS_ONLN);
  if (nprocs < 1)
    nprocs = 1;
  if (nprocs > INT_MAX)
    nprocs = INT_MAX;
  return (int)nprocs;
}

static void ensure_thread_count(const char* mode, bool threads_specified) {
  bool auto_detected = false;
  if (g_num_threads <= 0) {
    g_num_threads = detect_hardware_threads();
    auto_detected = true;
  }

  const char* source = auto_detected
                           ? "auto-detected"
                           : (threads_specified ? "user-specified" : "default");

  fprintf(stderr, "Using %d threads for %s (%s)\n", g_num_threads, mode,
          source);
}

static int compute_kmer_feature_count(int k) {
  if (k <= 0)
    return 0;

  // Limit k to avoid excessive feature dimensionality
  if (k > 6)
    return -1;

  int count = 1;
  for (int i = 0; i < k; i++) {
    if (count > MAX_NUM_FEATURES / 4)
      return -1;
    count *= 4;
  }

  return count;
}

static bool update_feature_counts(void) {
  int wavelet_features = g_num_wavelet_scales * 4;
  int kmer_features = 0;

  if (g_kmer_size > 0) {
    kmer_features = compute_kmer_feature_count(g_kmer_size);
    if (kmer_features < 0)
      return false;
  }

  if (wavelet_features + kmer_features > MAX_NUM_FEATURES)
    return false;

  g_kmer_feature_count = kmer_features;
  g_total_feature_count = wavelet_features + kmer_features;
  if (g_total_feature_count <= 0)
    return false;
  return true;
}

static const char* get_field_ptr(const char* line, int field_index) {
  if (!line || field_index <= 0)
    return NULL;

  const char* ptr = line;
  int current = 1;

  while (current < field_index && ptr) {
    const char* next_tab = strchr(ptr, '\t');
    if (!next_tab)
      return NULL;
    ptr = next_tab + 1;
    current++;
  }

  return ptr;
}

static long extract_start_coordinate(const char* line) {
  const char* start_ptr = get_field_ptr(line, 4);
  if (!start_ptr)
    return LONG_MAX;

  return strtol(start_ptr, NULL, 10);
}

static int feature_rank(const char* feature) {
  if (!feature)
    return 100;

  if (strncmp(feature, "gene", 4) == 0)
    return 0;
  if (strncmp(feature, "mRNA", 4) == 0)
    return 1;
  if (strncmp(feature, "CDS", 3) == 0)
    return 2;

  return 10;
}

static int compare_gff_lines(const void* a, const void* b) {
  const char* line_a = *(const char* const*)a;
  const char* line_b = *(const char* const*)b;

  const char* seq_a = line_a;
  const char* seq_b = line_b;

  size_t len_a = 0;
  while (seq_a[len_a] != '\t' && seq_a[len_a] != '\0')
    len_a++;

  size_t len_b = 0;
  while (seq_b[len_b] != '\t' && seq_b[len_b] != '\0')
    len_b++;

  size_t min_len = (len_a < len_b) ? len_a : len_b;
  int cmp = strncmp(seq_a, seq_b, min_len);
  if (cmp == 0) {
    if (len_a != len_b)
      cmp = (len_a < len_b) ? -1 : 1;
  }

  if (cmp != 0)
    return cmp;

  long start_a = extract_start_coordinate(line_a);
  long start_b = extract_start_coordinate(line_b);

  if (start_a < start_b)
    return -1;
  if (start_a > start_b)
    return 1;

  const char* feature_a = get_field_ptr(line_a, 3);
  const char* feature_b = get_field_ptr(line_b, 3);

  int rank_a = feature_rank(feature_a);
  int rank_b = feature_rank(feature_b);
  if (rank_a != rank_b)
    return (rank_a < rank_b) ? -1 : 1;

  return strcmp(line_a, line_b);
}

// Initialize output queue
static void output_queue_init(output_queue_t* queue) {
  queue->head = NULL;
  queue->tail = NULL;
  pthread_mutex_init(&queue->mutex, NULL);
}

// Add output to queue (thread-safe)
static void output_queue_add(output_queue_t* queue, const char* gff_line) {
  output_node_t* node = (output_node_t*)malloc(sizeof(output_node_t));
  if (node == NULL)
    return;

  node->gff_line = strdup(gff_line);
  node->next = NULL;

  pthread_mutex_lock(&queue->mutex);
  if (queue->tail == NULL) {
    queue->head = node;
    queue->tail = node;
  } else {
    queue->tail->next = node;
    queue->tail = node;
  }
  pthread_mutex_unlock(&queue->mutex);
}

// Flush output queue to stdout (not thread-safe, call from main thread)
static void output_queue_flush(output_queue_t* queue) {
  pthread_mutex_lock(&queue->mutex);
  output_node_t* node = queue->head;
  int count = 0;
  while (node != NULL) {
    count++;
    node = node->next;
  }

  char** lines = NULL;
  if (count > 0) {
    lines = (char**)malloc(count * sizeof(char*));
  }

  int idx = 0;
  node = queue->head;
  queue->head = NULL;
  queue->tail = NULL;
  pthread_mutex_unlock(&queue->mutex);

  while (node != NULL) {
    if (lines)
      lines[idx++] = node->gff_line;
    output_node_t* next = node->next;
    free(node);
    node = next;
  }

  if (lines) {
    qsort(lines, count, sizeof(char*), compare_gff_lines);

    for (int i = 0; i < count; i++) {
      printf("%s", lines[i]);
      free(lines[i]);
    }

    free(lines);
  }
}

// Destroy output queue
static void output_queue_destroy(output_queue_t* queue) {
  output_queue_flush(queue);
  pthread_mutex_destroy(&queue->mutex);
}

// Parse command-line wavelet scales argument
static int parse_wavelet_scales(const char* arg, double* scales,
                                int max_scales) {
  int count = 0;
  char* arg_copy = strdup(arg);
  char* token = strtok(arg_copy, ",");

  while (token != NULL && count < max_scales) {
    scales[count++] = atof(token);
    token = strtok(NULL, ",");
  }

  free(arg_copy);
  return count;
}

// Parse range in the form start:end:step and populate scales (up to max_scales)
// Returns number of scales parsed, or -1 on error.
static int parse_wavelet_range(const char* arg, double* scales,
                               int max_scales) {
  if (!arg || !scales || max_scales <= 0)
    return -1;

  // Copy and split by ':'
  char* copy = strdup(arg);
  if (!copy)
    return -1;

  char* saveptr = NULL;
  char* token = strtok_r(copy, ":", &saveptr);
  if (!token) {
    free(copy);
    return -1;
  }
  char* endptr = NULL;
  double start = strtod(token, &endptr);
  if (endptr == token) {
    free(copy);
    return -1;
  }

  token = strtok_r(NULL, ":", &saveptr);
  if (!token) {
    free(copy);
    return -1;
  }
  double endv = strtod(token, &endptr);
  if (endptr == token) {
    free(copy);
    return -1;
  }

  token = strtok_r(NULL, ":", &saveptr);
  if (!token) {
    free(copy);
    return -1;
  }
  double step = strtod(token, &endptr);
  if (endptr == token || step <= 0.0) {
    free(copy);
    return -1;
  }

  int count = 0;
  // Support increasing or decreasing ranges
  if (start <= endv) {
    for (double v = start; v <= endv && count < max_scales; v += step) {
      scales[count++] = v;
    }
  } else {
    for (double v = start; v >= endv && count < max_scales; v -= step) {
      scales[count++] = v;
    }
  }

  free(copy);
  return count;
}

static void free_observation_sequence(double** observations, int seq_len) {
  if (!observations)
    return;

  for (int t = 0; t < seq_len; t++) {
    free(observations[t]);
  }
  free(observations);
}

static bool build_observation_matrix(const char* sequence, int seq_len,
                                     double*** out_observations) {
  if (seq_len <= 0)
    return false;

  int wavelet_feature_rows = g_num_wavelet_scales * 4;
  int kmer_feature_rows = g_kmer_feature_count;
  int num_feature_rows = g_total_feature_count;

  if (wavelet_feature_rows < 0 || kmer_feature_rows < 0)
    return false;

  if (wavelet_feature_rows + kmer_feature_rows != num_feature_rows) {
    // Fallback to recomputing from trusted pieces to avoid mismatches that
    // would otherwise corrupt memory when writing feature rows.
    num_feature_rows = wavelet_feature_rows + kmer_feature_rows;
  }

  if (num_feature_rows <= 0 || num_feature_rows > MAX_NUM_FEATURES)
    return false;

  double** features = (double**)malloc(num_feature_rows * sizeof(double*));
  if (!features)
    return false;

  for (int s = 0; s < num_feature_rows; s++) {
    features[s] = (double*)calloc(seq_len, sizeof(double));
    if (!features[s]) {
      for (int j = 0; j < s; j++) {
        free(features[j]);
      }
      free(features);
      return false;
    }
  }

  if (wavelet_feature_rows > 0) {
    if (!compute_cwt_features(sequence, seq_len, g_wavelet_scales,
                              g_num_wavelet_scales, features)) {
      for (int s = 0; s < num_feature_rows; s++) {
        free(features[s]);
      }
      free(features);
      return false;
    }
  }

  if (kmer_feature_rows > 0 && g_kmer_size > 0) {
    const int feature_offset = wavelet_feature_rows;

    for (int t = 0; t <= seq_len - g_kmer_size; t++) {
      int index = 0;
      bool valid = true;

      for (int k = 0; k < g_kmer_size; k++) {
        char base = sequence[t + k];
        int base_idx;
        switch (toupper((unsigned char)base)) {
        case 'A':
          base_idx = 0;
          break;
        case 'C':
          base_idx = 1;
          break;
        case 'G':
          base_idx = 2;
          break;
        case 'T':
          base_idx = 3;
          break;
        default:
          valid = false;
          base_idx = -1;
          break;
        }

        if (!valid)
          break;

        index = (index << 2) | base_idx;
      }

      if (valid && index < kmer_feature_rows) {
        features[feature_offset + index][t] = 1.0;
      }
    }
  }

  double** observations = (double**)malloc(seq_len * sizeof(double*));
  if (!observations) {
    for (int s = 0; s < num_feature_rows; s++) {
      free(features[s]);
    }
    free(features);
    return false;
  }

  for (int t = 0; t < seq_len; t++) {
    observations[t] = (double*)malloc(num_feature_rows * sizeof(double));
    if (!observations[t]) {
      for (int u = 0; u < t; u++) {
        free(observations[u]);
      }
      free(observations);
      for (int s = 0; s < num_feature_rows; s++) {
        free(features[s]);
      }
      free(features);
      return false;
    }

    for (int f = 0; f < num_feature_rows; f++) {
      observations[t][f] = features[f][t];
    }
  }

  for (int s = 0; s < num_feature_rows; s++) {
    free(features[s]);
  }
  free(features);

  *out_observations = observations;
  return true;
}

// Task structure for parallel processing
typedef struct {
  const char* sequence;
  const char* seq_id;
  int seq_len;
  int array_index;
  char strand;
  double*** observations_array;
  int* seq_lengths_array;
  pthread_mutex_t* error_mutex;
  bool* error_flag;
  char* error_message;
  size_t error_message_size;
  int sequence_number;
  // Chunk-specific fields
  int chunk_start; // Start position in original sequence
  int chunk_end;   // End position in original sequence
  bool is_chunk;   // Whether this is a chunk or full sequence
} training_task_t;

static void training_observation_worker(void* arg) {
  training_task_t* task = (training_task_t*)arg;
  if (task == NULL)
    return;

  const char* sequence = task->sequence;
  char* rc = NULL;
  char* chunk_seq = NULL;
  double** result = NULL;
  bool success = false;

  // Extract chunk if needed
  int effective_len = task->seq_len;
  if (task->is_chunk) {
    effective_len = task->chunk_end - task->chunk_start;
    chunk_seq = (char*)malloc((effective_len + 1) * sizeof(char));
    if (!chunk_seq)
      goto cleanup;
    memcpy(chunk_seq, sequence + task->chunk_start, effective_len);
    chunk_seq[effective_len] = '\0';
    sequence = chunk_seq;
  }

  if (task->strand == '-') {
    rc = reverse_complement(sequence);
    if (!rc)
      goto cleanup;
    sequence = rc;
  }

  if (!build_observation_matrix(sequence, effective_len, &result))
    goto cleanup;

  task->observations_array[task->array_index] = result;
  task->seq_lengths_array[task->array_index] = effective_len;
  success = true;

cleanup:
  if (!success) {
    if (result)
      free_observation_sequence(result, effective_len);

    pthread_mutex_lock(task->error_mutex);
    if (!(*(task->error_flag))) {
      *(task->error_flag) = true;
      if (task->is_chunk) {
        snprintf(task->error_message, task->error_message_size,
                 "Failed to compute feature matrix for chunk [%d-%d] of "
                 "sequence %s (%c strand)",
                 task->chunk_start, task->chunk_end,
                 task->seq_id ? task->seq_id : "(unknown)", task->strand);
      } else {
        snprintf(task->error_message, task->error_message_size,
                 "Failed to compute feature matrix for sequence %s (%c strand, "
                 "index %d)",
                 task->seq_id ? task->seq_id : "(unknown)", task->strand,
                 task->sequence_number);
      }
    }
    pthread_mutex_unlock(task->error_mutex);
  }

  if (rc)
    free(rc);
  if (chunk_seq)
    free(chunk_seq);
  if (!success && task->observations_array[task->array_index] == NULL)
    task->seq_lengths_array[task->array_index] = 0;

  free(task);
}

// Helper function to calculate number of chunks for a sequence
static int calculate_num_chunks(int seq_len, int chunk_size, int overlap) {
  if (!g_use_chunking || seq_len <= chunk_size) {
    return 1; // No chunking needed
  }
  int step = chunk_size - overlap;
  if (step <= 0) {
    return 1; // Invalid configuration, treat as single chunk
  }
  return (seq_len - overlap + step - 1) / step;
}

// Helper function to get chunk boundaries
static void get_chunk_bounds(int seq_len, int chunk_size, int overlap,
                             int chunk_idx, int* start, int* end) {
  if (!g_use_chunking || seq_len <= chunk_size) {
    *start = 0;
    *end = seq_len;
    return;
  }

  int step = chunk_size - overlap;
  *start = chunk_idx * step;
  *end = *start + chunk_size;

  // Adjust last chunk to include remainder
  if (*end > seq_len) {
    *end = seq_len;
  }
}

static void validate_chunk_configuration_or_exit(const char* context) {
  if (!g_use_chunking)
    return;

  if (g_chunk_size <= 0) {
    fprintf(stderr, "Error (%s): chunk size must be greater than zero\n",
            context);
    exit(1);
  }

  if (g_chunk_overlap < 0) {
    fprintf(stderr,
            "Error (%s): chunk overlap must be a non-negative integer\n",
            context);
    exit(1);
  }

  if (g_chunk_overlap >= g_chunk_size) {
    fprintf(
        stderr,
        "Error (%s): chunk overlap (%d) must be smaller than chunk size (%d)\n",
        context, g_chunk_overlap, g_chunk_size);
    exit(1);
  }
}

typedef struct {
  char* sequence;
  char* seq_id;
  char strand;
  HMMModel* model;
  int original_length;
  int chunk_offset; // Offset of this chunk within the full sequence (0-based)
  int chunk_index;  // Index of this chunk within the sequence (0-based)
  int chunk_count;  // Total number of chunks for the originating sequence
} prediction_task_t;

typedef struct {
  int start;
  int end;
  int phase;
} PredictedExon;

static bool is_exon_state(int state) {
  return state == STATE_EXON_F0 || state == STATE_EXON_F1 ||
         state == STATE_EXON_F2;
}

static int exon_state_to_phase(int state) {
  switch (state) {
  case STATE_EXON_F0:
    return 0;
  case STATE_EXON_F1:
    return 1;
  case STATE_EXON_F2:
    return 2;
  default:
    return 0;
  }
}

static void output_predicted_gene(const prediction_task_t* task,
                                  const PredictedExon* exons, size_t exon_count,
                                  int gene_seq_start, int gene_seq_end,
                                  double score, int original_length) {
  if (!task || !exons || exon_count == 0)
    return;

  if (original_length <= 0)
    return;

  if (gene_seq_start < 0 || gene_seq_end < gene_seq_start)
    return;

  const char* seq_id = task->seq_id ? task->seq_id : "(unknown)";

  int gene_id = 0;
  pthread_mutex_lock(&g_gene_counter_mutex);
  gene_id = ++g_gene_counter;
  pthread_mutex_unlock(&g_gene_counter_mutex);

  int output_start = 0;
  int output_end = 0;

  if (task->strand == '+') {
    output_start = gene_seq_start + 1;
    output_end = gene_seq_end + 1;
  } else {
    output_start = original_length - gene_seq_end;
    output_end = original_length - gene_seq_start;
  }

  if (output_start < 1)
    output_start = 1;
  if (output_end < output_start) {
    int tmp = output_start;
    output_start = output_end;
    output_end = tmp;
  }
  if (output_end > original_length)
    output_end = original_length;

  char gff_line[1024];
  snprintf(gff_line, sizeof(gff_line),
           "%s\tsunfish\tgene\t%d\t%d\t%.2f\t%c\t.\tID=gene%d\n", seq_id,
           output_start, output_end, score, task->strand, gene_id);
  output_queue_add(&g_output_queue, gff_line);

  /* Also emit an mRNA feature corresponding to this gene so downstream
    tools (like gffcompare) that expect transcript/mRNA entries can compute
    exon-level statistics. We treat the gene as the parent (gene -> mRNA). */
  char mrna_id[64];
  snprintf(mrna_id, sizeof(mrna_id), "mRNA-gene%d", gene_id);
  snprintf(gff_line, sizeof(gff_line),
           "%s\tsunfish\tmRNA\t%d\t%d\t%.2f\t%c\t.\tID=%s;Parent=gene%d\n",
           seq_id, output_start, output_end, score, task->strand, mrna_id,
           gene_id);
  output_queue_add(&g_output_queue, gff_line);

  if (task->strand == '+') {
    for (size_t idx = 0; idx < exon_count; idx++) {
      const PredictedExon* exon = &exons[idx];
      int cds_start = exon->start + 1;
      int cds_end = exon->end + 1;
      if (cds_start < 1)
        cds_start = 1;
      if (cds_end > original_length)
        cds_end = original_length;

      /* Emit exon feature corresponding to this CDS (Parent = mRNA) */
      snprintf(
          gff_line, sizeof(gff_line),
          "%s\tsunfish\texon\t%d\t%d\t%.2f\t%c\t.\tID=exon-%s-%zu;Parent=%s\n",
          seq_id, cds_start, cds_end, score, task->strand, mrna_id, idx + 1,
          mrna_id);
      output_queue_add(&g_output_queue, gff_line);

      snprintf(gff_line, sizeof(gff_line),
               "%s\tsunfish\tCDS\t%d\t%d\t%.2f\t%c\t%d\tID=cds%d.%zu;Parent="
               "gene%d\n",
               seq_id, cds_start, cds_end, score, task->strand, exon->phase,
               gene_id, idx + 1, gene_id);
      output_queue_add(&g_output_queue, gff_line);
    }
  } else {
    for (size_t reverse_idx = exon_count; reverse_idx-- > 0;) {
      const PredictedExon* exon = &exons[reverse_idx];
      int cds_start = original_length - exon->end;
      int cds_end = original_length - exon->start;
      if (cds_start < 1)
        cds_start = 1;
      if (cds_end > original_length)
        cds_end = original_length;

      /* Emit exon feature corresponding to this CDS (Parent = mRNA) */
      snprintf(
          gff_line, sizeof(gff_line),
          "%s\tsunfish\texon\t%d\t%d\t%.2f\t%c\t.\tID=exon-%s-%zu;Parent=%s\n",
          seq_id, cds_start, cds_end, score, task->strand, mrna_id,
          exon_count - reverse_idx, mrna_id);
      output_queue_add(&g_output_queue, gff_line);

      snprintf(gff_line, sizeof(gff_line),
               "%s\tsunfish\tCDS\t%d\t%d\t%.2f\t%c\t%d\tID=cds%d.%zu;Parent="
               "gene%d\n",
               seq_id, cds_start, cds_end, score, task->strand, exon->phase,
               gene_id, exon_count - reverse_idx, gene_id);
      output_queue_add(&g_output_queue, gff_line);
    }
  }
}

// Validate ORF: check start codon, stop codon, in-frame stops, and length
static bool is_valid_orf(const char* cds_sequence) {
  if (!cds_sequence) {
    return false;
  }

  size_t len = strlen(cds_sequence);

  // Check length is multiple of 3
  if (len < 3 || len % 3 != 0) {
    return false;
  }

  // Check starts with ATG
  if (toupper((unsigned char)cds_sequence[0]) != 'A' ||
      toupper((unsigned char)cds_sequence[1]) != 'T' ||
      toupper((unsigned char)cds_sequence[2]) != 'G') {
    return false;
  }

  // Check internal codons for in-frame stop codons
  for (size_t i = 3; i < len - 3; i += 3) {
    char codon[4];
    codon[0] = toupper((unsigned char)cds_sequence[i]);
    codon[1] = toupper((unsigned char)cds_sequence[i + 1]);
    codon[2] = toupper((unsigned char)cds_sequence[i + 2]);
    codon[3] = '\0';

    // Check for stop codons: TAA, TAG, TGA
    if ((strcmp(codon, "TAA") == 0) || (strcmp(codon, "TAG") == 0) ||
        (strcmp(codon, "TGA") == 0)) {
      return false; // Internal stop codon
    }
  }

  // Check ends with stop codon
  size_t last_codon_start = len - 3;
  char last_codon[4];
  last_codon[0] = toupper((unsigned char)cds_sequence[last_codon_start]);
  last_codon[1] = toupper((unsigned char)cds_sequence[last_codon_start + 1]);
  last_codon[2] = toupper((unsigned char)cds_sequence[last_codon_start + 2]);
  last_codon[3] = '\0';

  if (strcmp(last_codon, "TAA") != 0 && strcmp(last_codon, "TAG") != 0 &&
      strcmp(last_codon, "TGA") != 0) {
    return false; // No stop codon at end
  }

  return true;
}

// Worker function for parallel prediction
static void predict_sequence_worker(void* arg) {
  prediction_task_t* task = (prediction_task_t*)arg;
  if (!task)
    return;

  double** observations = NULL;
  int* states = NULL;
  PredictedExon* exon_buffer = NULL;
  size_t exon_capacity = 0;
  size_t exon_count = 0;
  int seq_len = 0;
  const char* seq_id = task->seq_id ? task->seq_id : "(unknown)";
  const int chunk_offset = (task->chunk_offset >= 0) ? task->chunk_offset : 0;

  if (!task->sequence)
    goto cleanup;

  seq_len = strlen(task->sequence);
  if (seq_len <= 0)
    goto cleanup;

  if (!build_observation_matrix(task->sequence, seq_len, &observations)) {
    fprintf(stderr,
            "Warning: Failed to compute feature matrix for %s (%c strand)\n",
            seq_id, task->strand);
    goto cleanup;
  }

  // Apply Z-score normalization using global statistics from the model
  for (int t = 0; t < seq_len; t++) {
    for (int f = 0; f < task->model->num_features; f++) {
      double raw_val = observations[t][f];
      double normalized_val = (raw_val - task->model->global_feature_mean[f]) /
                              task->model->global_feature_stddev[f];
      observations[t][f] = normalized_val;
    }
  }

  states = (int*)malloc(seq_len * sizeof(int));
  if (!states) {
    fprintf(stderr,
            "Warning: Failed to allocate state buffer for %s (%c strand)\n",
            seq_id, task->strand);
    goto cleanup;
  }

  double log_prob =
      hmm_viterbi(task->model, observations, task->sequence, seq_len, states);
  double normalized_log_prob = (seq_len > 0) ? (log_prob / seq_len) : log_prob;
  double prediction_score = 0.0;
  if (isfinite(normalized_log_prob)) {
    if (normalized_log_prob <= -700.0) {
      prediction_score = 0.0;
    } else if (normalized_log_prob >= 700.0) {
      prediction_score = 1.0;
    } else {
      prediction_score = exp(normalized_log_prob);
      if (!isfinite(prediction_score))
        prediction_score = 0.0;
      else if (prediction_score > 1.0)
        prediction_score = 1.0;
      else if (prediction_score < 0.0)
        prediction_score = 0.0;
    }
  }
  const int original_length =
      (task->original_length > 0) ? task->original_length : seq_len;

  exon_capacity = 8;
  exon_buffer = (PredictedExon*)malloc(exon_capacity * sizeof(PredictedExon));
  if (!exon_buffer) {
    fprintf(stderr,
            "Warning: Failed to allocate exon buffer for %s (%c strand)\n",
            seq_id, task->strand);
    goto cleanup;
  }

  bool gene_active = false;
  int current_exon_start = -1;
  int gene_seq_start = -1;
  int gene_seq_end = -1;

  for (int i = 0; i < seq_len; i++) {
    int state = states[i];
    bool exon_state = is_exon_state(state);
    bool intron_state = (state == STATE_INTRON);

    if (!gene_active) {
      if (exon_state) {
        gene_active = true;
        gene_seq_start = i;
        gene_seq_end = i;
        exon_count = 0;
        current_exon_start = i;
      }
      continue;
    }

    if (exon_state) {
      if (current_exon_start == -1)
        current_exon_start = i;
      gene_seq_end = i;
      continue;
    }

    if (current_exon_start != -1) {
      int exon_end = i - 1;
      if (exon_end < current_exon_start)
        exon_end = current_exon_start;

      if (exon_count >= exon_capacity) {
        size_t new_capacity = exon_capacity * 2;
        PredictedExon* tmp = (PredictedExon*)realloc(
            exon_buffer, new_capacity * sizeof(PredictedExon));
        if (!tmp) {
          fprintf(stderr,
                  "Warning: Failed to expand exon buffer for %s (%c strand)\n",
                  seq_id, task->strand);
          goto cleanup;
        }
        exon_buffer = tmp;
        exon_capacity = new_capacity;
      }

      exon_buffer[exon_count].start = current_exon_start;
      exon_buffer[exon_count].end = exon_end;
      exon_buffer[exon_count].phase =
          exon_state_to_phase(states[current_exon_start]);
      exon_count++;

      current_exon_start = -1;
      gene_seq_end = exon_end;
    }

    if (!intron_state) {
      if (exon_count > 0 && gene_seq_start >= 0 &&
          gene_seq_end >= gene_seq_start) {
        // Assemble CDS sequence from exons for validation
        size_t cds_len = 0;
        for (size_t e = 0; e < exon_count; e++) {
          cds_len += (exon_buffer[e].end - exon_buffer[e].start + 1);
        }

        char* cds_seq = (char*)malloc(cds_len + 1);
        if (cds_seq) {
          size_t pos = 0;
          for (size_t e = 0; e < exon_count; e++) {
            int exon_len = exon_buffer[e].end - exon_buffer[e].start + 1;
            memcpy(cds_seq + pos, task->sequence + exon_buffer[e].start,
                   exon_len);
            pos += exon_len;
          }
          cds_seq[cds_len] = '\0';

          // Validate ORF before outputting
          int global_gene_start = gene_seq_start + chunk_offset;
          int global_gene_end = gene_seq_end + chunk_offset;
          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start += chunk_offset;
            exon_buffer[e].end += chunk_offset;
          }

          if (is_valid_orf(cds_seq)) {
            output_predicted_gene(task, exon_buffer, exon_count,
                                  global_gene_start, global_gene_end,
                                  prediction_score, original_length);
          }

          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start -= chunk_offset;
            exon_buffer[e].end -= chunk_offset;
          }
          free(cds_seq);
        } else {
          // Memory allocation failed, output without validation
          int global_gene_start = gene_seq_start + chunk_offset;
          int global_gene_end = gene_seq_end + chunk_offset;
          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start += chunk_offset;
            exon_buffer[e].end += chunk_offset;
          }
          output_predicted_gene(task, exon_buffer, exon_count,
                                global_gene_start, global_gene_end,
                                prediction_score, original_length);
          for (size_t e = 0; e < exon_count; e++) {
            exon_buffer[e].start -= chunk_offset;
            exon_buffer[e].end -= chunk_offset;
          }
        }
      }

      gene_active = false;
      gene_seq_start = -1;
      gene_seq_end = -1;
      exon_count = 0;
      current_exon_start = -1;
    }
  }

  if (current_exon_start != -1) {
    int exon_end = seq_len - 1;
    if (exon_count >= exon_capacity) {
      size_t new_capacity = exon_capacity * 2;
      PredictedExon* tmp = (PredictedExon*)realloc(
          exon_buffer, new_capacity * sizeof(PredictedExon));
      if (!tmp) {
        fprintf(stderr,
                "Warning: Failed to expand exon buffer for %s (%c strand)\n",
                seq_id, task->strand);
        goto cleanup;
      }
      exon_buffer = tmp;
      exon_capacity = new_capacity;
    }

    exon_buffer[exon_count].start = current_exon_start;
    exon_buffer[exon_count].end = exon_end;
    exon_buffer[exon_count].phase =
        exon_state_to_phase(states[current_exon_start]);
    exon_count++;
    gene_seq_end = exon_end;
    current_exon_start = -1;
  }

  if (gene_active && exon_count > 0 && gene_seq_start >= 0 &&
      gene_seq_end >= gene_seq_start) {
    // Assemble CDS sequence from exons for validation
    size_t cds_len = 0;
    for (size_t e = 0; e < exon_count; e++) {
      cds_len += (exon_buffer[e].end - exon_buffer[e].start + 1);
    }

    char* cds_seq = (char*)malloc(cds_len + 1);
    if (cds_seq) {
      size_t pos = 0;
      for (size_t e = 0; e < exon_count; e++) {
        int exon_len = exon_buffer[e].end - exon_buffer[e].start + 1;
        memcpy(cds_seq + pos, task->sequence + exon_buffer[e].start, exon_len);
        pos += exon_len;
      }
      cds_seq[cds_len] = '\0';

      // Validate ORF before outputting
      int global_gene_start = gene_seq_start + chunk_offset;
      int global_gene_end = gene_seq_end + chunk_offset;
      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start += chunk_offset;
        exon_buffer[e].end += chunk_offset;
      }

      if (is_valid_orf(cds_seq)) {
        output_predicted_gene(task, exon_buffer, exon_count, global_gene_start,
                              global_gene_end, prediction_score,
                              original_length);
      }

      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start -= chunk_offset;
        exon_buffer[e].end -= chunk_offset;
      }
      free(cds_seq);
    } else {
      // Memory allocation failed, output without validation
      int global_gene_start = gene_seq_start + chunk_offset;
      int global_gene_end = gene_seq_end + chunk_offset;
      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start += chunk_offset;
        exon_buffer[e].end += chunk_offset;
      }
      output_predicted_gene(task, exon_buffer, exon_count, global_gene_start,
                            global_gene_end, prediction_score, original_length);
      for (size_t e = 0; e < exon_count; e++) {
        exon_buffer[e].start -= chunk_offset;
        exon_buffer[e].end -= chunk_offset;
      }
    }
  }

cleanup:
  if (exon_buffer)
    free(exon_buffer);
  if (states)
    free(states);
  if (observations)
    free_observation_sequence(observations, seq_len);
  free(task->sequence);
  free(task->seq_id);
  free(task);
}

// Training mode: Baum-Welch HMM training
static void print_help(const char* progname) {
  printf("Sunfish HMM-based Gene Annotation Tool\n\n");
  printf("Usage:\n");
  printf("  %s <command> [options]\n\n", progname);
  printf("Commands:\n");
  printf("  help                         Show this help message\n"
         "  train <train.fasta> <train.gff> [--wavelet|-w S1,S2,...|s:e:step]"
         " [--kmer|-k K] [--threads|-t N] [--chunk-size N] [--chunk-overlap M]"
         " [--chunk|--no-chunk]\n"
         "  predict <target.fasta> [--wavelet|-w S1,S2,...|s:e:step]"
         " [--kmer|-k K] [--threads|-t N] [--chunk-size N] [--chunk-overlap M]"
         " [--chunk|--no-chunk]\n\n");
  printf("Options:\n");
  printf("  -h, --help                   Show this help message\n");
  printf(
      "  --wavelet, -w               Comma-separated list (a,b,c) or range "
      "s:e:step\n"
      "  --kmer, -k K               k-mer size for feature augmentation "
      "(default: 2; use 0 to "
      "disable)\n"
      "  --threads, -t N             Number of worker threads (default: auto-"
      "detected)\n"
      "  --chunk-size N              Chunk size in bases for long sequences\n"
      "  --chunk-overlap M           Overlap size in bases between chunks\n"
      "  --chunk                     Enable chunked processing (default: off)\n"
      "  --no-chunk                  Disable chunked processing\n\n");
  printf("Examples:\n");
  printf("  %s train data.fa data.gff --wavelet 3,9,81\n", progname);
  printf("  %s predict genome.fa --threads 8 > predictions.gff3\n\n", progname);
}

static void initialize_state_labels(int* labels, int len) {
  if (!labels || len <= 0)
    return;

  for (int i = 0; i < len; i++) {
    labels[i] = STATE_INTERGENIC;
  }
}

static HMMState frame_to_state(int frame) {
  int normalized = frame % 3;
  if (normalized < 0)
    normalized += 3;

  switch (normalized) {
  case 0:
    return STATE_EXON_F0;
  case 1:
    return STATE_EXON_F1;
  default:
    return STATE_EXON_F2;
  }
}

static int normalize_phase(int phase) {
  if (phase < 0)
    return 0;
  return phase % 3;
}

static int compare_exon_start(const void* lhs, const void* rhs) {
  const Exon* a = (const Exon*)lhs;
  const Exon* b = (const Exon*)rhs;

  if (a->start < b->start)
    return -1;
  if (a->start > b->start)
    return 1;
  if (a->end < b->end)
    return -1;
  if (a->end > b->end)
    return 1;
  return 0;
}

static void sort_group_exons(CdsGroup* group) {
  if (!group || group->exon_count <= 1 || group->exons == NULL)
    return;

  qsort(group->exons, group->exon_count, sizeof(Exon), compare_exon_start);
}

typedef struct {
  int start;
  int end;
  int phase;
} RcExon;

static int compare_rc_exon_start(const void* lhs, const void* rhs) {
  const RcExon* a = (const RcExon*)lhs;
  const RcExon* b = (const RcExon*)rhs;

  if (a->start < b->start)
    return -1;
  if (a->start > b->start)
    return 1;
  if (a->end < b->end)
    return -1;
  if (a->end > b->end)
    return 1;
  return 0;
}

static void label_forward_states(const CdsGroup* groups, int group_count,
                                 const char* seq_id, int seq_len,
                                 int* state_labels) {
  if (!groups || group_count <= 0 || !seq_id || !state_labels || seq_len <= 0)
    return;

  for (int g = 0; g < group_count; g++) {
    const CdsGroup* group = &groups[g];
    if (!group || group->exon_count == 0 || group->exons == NULL)
      continue;

    bool has_forward_exon = false;
    for (int e = 0; e < group->exon_count; e++) {
      const Exon* exon = &group->exons[e];
      if (exon->strand != '+')
        continue;
      if (strcmp(exon->seqid, seq_id) == 0) {
        has_forward_exon = true;
        break;
      }
    }
    if (!has_forward_exon)
      continue;

    for (int e = 0; e < group->exon_count; e++) {
      const Exon* exon = &group->exons[e];
      if (exon->strand != '+' || strcmp(exon->seqid, seq_id) != 0)
        continue;

      int start = exon->start - 1;
      int end_exclusive = exon->end;

      if (end_exclusive <= 0)
        continue;

      if (start < 0)
        start = 0;
      if (start >= seq_len)
        continue;

      if (end_exclusive > seq_len)
        end_exclusive = seq_len;
      if (start >= end_exclusive)
        continue;

      int phase = normalize_phase(exon->phase);

      for (int pos = start; pos < end_exclusive; pos++) {
        int offset = pos - start;
        HMMState state = frame_to_state(phase + offset);
        state_labels[pos] = state;
      }

      if (e < group->exon_count - 1) {
        const Exon* next = &group->exons[e + 1];
        if (next->strand != '+' || strcmp(next->seqid, seq_id) != 0)
          continue;

        int intron_start = end_exclusive;
        int intron_end_exclusive = next->start - 1;

        if (intron_end_exclusive <= intron_start)
          continue;

        if (intron_start < 0)
          intron_start = 0;
        if (intron_end_exclusive > seq_len)
          intron_end_exclusive = seq_len;

        for (int pos = intron_start;
             pos < intron_end_exclusive && pos < seq_len; pos++) {
          if (pos >= 0 && state_labels[pos] == STATE_INTERGENIC)
            state_labels[pos] = STATE_INTRON;
        }
      }
    }
  }
}

static void label_reverse_states(const CdsGroup* groups, int group_count,
                                 const char* seq_id, int seq_len,
                                 int* state_labels) {
  if (!groups || group_count <= 0 || !seq_id || !state_labels || seq_len <= 0)
    return;

  for (int g = 0; g < group_count; g++) {
    const CdsGroup* group = &groups[g];
    if (!group || group->exon_count == 0 || group->exons == NULL)
      continue;

    int valid_count = 0;
    RcExon* rc_exons = (RcExon*)malloc(group->exon_count * sizeof(RcExon));
    if (!rc_exons)
      continue;

    for (int e = 0; e < group->exon_count; e++) {
      const Exon* exon = &group->exons[e];
      if (exon->strand != '-' || strcmp(exon->seqid, seq_id) != 0)
        continue;

      int start0 = exon->start - 1;
      int end0 = exon->end - 1;

      if (end0 < 0 || start0 >= seq_len)
        continue;

      if (start0 < 0)
        start0 = 0;
      if (end0 >= seq_len)
        end0 = seq_len - 1;
      if (start0 > end0)
        continue;

      int rc_start = seq_len - 1 - end0;
      int rc_end = seq_len - 1 - start0;

      if (rc_start < 0)
        rc_start = 0;
      if (rc_end >= seq_len)
        rc_end = seq_len - 1;
      if (rc_start > rc_end)
        continue;

      int phase = normalize_phase(exon->phase);

      rc_exons[valid_count].start = rc_start;
      rc_exons[valid_count].end = rc_end;
      rc_exons[valid_count].phase = phase;
      valid_count++;
    }

    if (valid_count == 0) {
      free(rc_exons);
      continue;
    }

    qsort(rc_exons, valid_count, sizeof(RcExon), compare_rc_exon_start);

    for (int e = 0; e < valid_count; e++) {
      RcExon* rc = &rc_exons[e];
      for (int pos = rc->start; pos <= rc->end && pos < seq_len; pos++) {
        if (pos < 0)
          continue;
        int offset = rc->end - pos;
        HMMState state = frame_to_state(rc->phase + offset);
        state_labels[pos] = state;
      }
    }

    for (int e = 0; e < valid_count - 1; e++) {
      int intron_start = rc_exons[e].end + 1;
      int intron_end_exclusive = rc_exons[e + 1].start;

      if (intron_end_exclusive <= intron_start)
        continue;

      if (intron_start < 0)
        intron_start = 0;
      if (intron_end_exclusive > seq_len)
        intron_end_exclusive = seq_len;

      for (int pos = intron_start; pos < intron_end_exclusive && pos < seq_len;
           pos++) {
        if (pos >= 0 && state_labels[pos] == STATE_INTERGENIC)
          state_labels[pos] = STATE_INTRON;
      }
    }

    free(rc_exons);
  }
}

static void normalize_observations_in_place(double*** observations,
                                            const int* seq_lengths,
                                            int total_sequences,
                                            const HMMModel* model) {
  if (!observations || !seq_lengths || !model)
    return;

  for (int seq = 0; seq < total_sequences; seq++) {
    double** seq_obs = observations[seq];
    int len = seq_lengths[seq];

    if (!seq_obs || len <= 0)
      continue;

    for (int t = 0; t < len; t++) {
      double* feature_vec = seq_obs[t];
      if (!feature_vec)
        continue;

      int feature_count = model->num_features;
      if (feature_count > MAX_NUM_FEATURES)
        feature_count = MAX_NUM_FEATURES;

      for (int f = 0; f < feature_count; f++) {
        double stddev = model->global_feature_stddev[f];
        if (stddev < 1e-10)
          stddev = 1e-10;
        feature_vec[f] =
            (feature_vec[f] - model->global_feature_mean[f]) / stddev;
      }
    }
  }
}

static void accumulate_statistics_for_sequence(
    const HMMModel* model, double*** observations, int* seq_lengths,
    int obs_idx, int seq_len, const int* state_labels,
    long long transition_counts[NUM_STATES][NUM_STATES],
    double emission_sum[NUM_STATES][MAX_NUM_FEATURES],
    double emission_sum_sq[NUM_STATES][MAX_NUM_FEATURES],
    long long state_observation_counts[NUM_STATES],
    long long initial_counts[NUM_STATES]) {
  if (!model || !observations || !state_labels || !transition_counts ||
      !emission_sum || !emission_sum_sq || !state_observation_counts ||
      !initial_counts)
    return;

  if (obs_idx < 0)
    return;

  double** obs = observations[obs_idx];
  if (!obs)
    return;

  int obs_len = seq_lengths ? seq_lengths[obs_idx] : seq_len;
  if (seq_len <= 0 || obs_len <= 0)
    return;

  int effective_len = (seq_len < obs_len) ? seq_len : obs_len;
  if (effective_len <= 0)
    return;

  int num_features = model->num_features;
  if (num_features > MAX_NUM_FEATURES)
    num_features = MAX_NUM_FEATURES;

  for (int t = 0; t < effective_len; t++) {
    int state = state_labels[t];
    if (state < 0 || state >= NUM_STATES)
      state = STATE_INTERGENIC;

    if (t == 0)
      initial_counts[state]++;

    if (t < effective_len - 1) {
      int next_state = state_labels[t + 1];
      if (next_state < 0 || next_state >= NUM_STATES)
        next_state = STATE_INTERGENIC;
      transition_counts[state][next_state]++;
    }

    for (int f = 0; f < num_features; f++) {
      double normalized_val = obs[t][f];
      emission_sum[state][f] += normalized_val;
      emission_sum_sq[state][f] += normalized_val * normalized_val;
    }
    state_observation_counts[state]++;
  }
}

static void enforce_exon_cycle_constraints(HMMModel* model) {
  if (!model)
    return;

  const HMMState exon_cycle[] = {STATE_EXON_F0, STATE_EXON_F1, STATE_EXON_F2};
  const size_t exon_cycle_len = sizeof(exon_cycle) / sizeof(exon_cycle[0]);

  for (size_t idx = 0; idx < exon_cycle_len; idx++) {
    HMMState state = exon_cycle[idx];
    HMMState expected_next = exon_cycle[(idx + 1) % exon_cycle_len];
    int row = (int)state;

    double exon_transition_mass = 0.0;
    for (size_t target_idx = 0; target_idx < exon_cycle_len; target_idx++) {
      HMMState exon_target = exon_cycle[target_idx];
      exon_transition_mass += model->transition[row][(int)exon_target];
    }
    if (exon_transition_mass < 1e-10)
      exon_transition_mass = 1e-10;

    model->transition[row][(int)expected_next] = exon_transition_mass;
    for (size_t target_idx = 0; target_idx < exon_cycle_len; target_idx++) {
      HMMState exon_target = exon_cycle[target_idx];
      if (exon_target == expected_next)
        continue;
      model->transition[row][(int)exon_target] = 1e-10;
    }

    for (int col = 0; col < NUM_STATES; col++) {
      if (!is_exon_state(col) && model->transition[row][col] < 1e-10)
        model->transition[row][col] = 1e-10;
    }

    double row_sum = 0.0;
    for (int col = 0; col < NUM_STATES; col++) {
      row_sum += model->transition[row][col];
    }

    if (row_sum <= 0.0) {
      for (int col = 0; col < NUM_STATES; col++) {
        model->transition[row][col] = (col == (int)expected_next) ? 1.0 : 1e-10;
      }
      row_sum = 0.0;
      for (int col = 0; col < NUM_STATES; col++) {
        row_sum += model->transition[row][col];
      }
    }

    for (int col = 0; col < NUM_STATES; col++) {
      model->transition[row][col] /= row_sum;
    }
  }
}

// Helper function to convert base character to index (A=0, C=1, G=2, T=3)
static int base_to_index(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 0;
  case 'C':
    return 1;
  case 'G':
    return 2;
  case 'T':
    return 3;
  default:
    return -1; // Invalid base
  }
}

// Train splice site PWM model from annotated data
static SplicePWM* train_splice_model(const FastaData* genome,
                                     const CdsGroup* groups, int group_count) {
  if (!genome || !groups || group_count <= 0) {
    return NULL;
  }

  // Allocate and initialize counts structure
  SpliceCounts* counts = (SpliceCounts*)calloc(1, sizeof(SpliceCounts));
  if (!counts) {
    return NULL;
  }

  // Iterate through all CDS groups to find donor and acceptor sites
  for (int g = 0; g < group_count; g++) {
    const CdsGroup* group = &groups[g];
    if (group->exon_count < 1) {
      continue;
    }

    // Find the sequence this group belongs to
    const char* seqid = group->exons[0].seqid;
    const FastaRecord* record = NULL;
    for (int i = 0; i < genome->count; i++) {
      if (strcmp(genome->records[i].id, seqid) == 0) {
        record = &genome->records[i];
        break;
      }
    }
    if (!record || !record->sequence) {
      continue;
    }

    const char* seq = record->sequence;
    int seq_len = strlen(seq);
    char strand = group->exons[0].strand;

    // Process each adjacent exon pair to find splice sites
    for (int e = 0; e < group->exon_count - 1; e++) {
      const Exon* exon1 = &group->exons[e];
      const Exon* exon2 = &group->exons[e + 1];

      if (strand == '+') {
        // Donor site: at the end of exon1 (exon-intron boundary)
        // Extract sequence centered around the boundary
        int donor_center = exon1->end; // GFF is 1-based, end is inclusive
        int donor_start = donor_center - DONOR_MOTIF_SIZE / 2;

        if (donor_start >= 0 && donor_start + DONOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
            int idx = base_to_index(seq[donor_start + pos]);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->donor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_donor_sites++;
          }
        }

        // Acceptor site: at the start of exon2 (intron-exon boundary)
        int acceptor_center = exon2->start - 1; // Convert to 0-based
        int acceptor_start = acceptor_center - ACCEPTOR_MOTIF_SIZE / 2;

        if (acceptor_start >= 0 &&
            acceptor_start + ACCEPTOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
            int idx = base_to_index(seq[acceptor_start + pos]);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->acceptor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_acceptor_sites++;
          }
        }
      } else if (strand == '-') {
        // For reverse strand, donor/acceptor are reversed
        // Donor site: at the start of exon1 (actually acceptor in genomic
        // coords)
        int donor_center = exon1->start - 1; // Convert to 0-based
        int donor_start = donor_center - DONOR_MOTIF_SIZE / 2;

        if (donor_start >= 0 && donor_start + DONOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          // Extract and reverse complement
          char motif[DONOR_MOTIF_SIZE + 1];
          for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
            motif[pos] = seq[donor_start + DONOR_MOTIF_SIZE - 1 - pos];
          }
          motif[DONOR_MOTIF_SIZE] = '\0';

          // Apply reverse complement
          for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
            char base = motif[pos];
            char rc_base;
            switch (toupper((unsigned char)base)) {
            case 'A':
              rc_base = 'T';
              break;
            case 'T':
              rc_base = 'A';
              break;
            case 'G':
              rc_base = 'C';
              break;
            case 'C':
              rc_base = 'G';
              break;
            default:
              rc_base = 'N';
              break;
            }

            int idx = base_to_index(rc_base);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->donor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_donor_sites++;
          }
        }

        // Acceptor site: at the end of exon2
        int acceptor_center = exon2->end;
        int acceptor_start = acceptor_center - ACCEPTOR_MOTIF_SIZE / 2;

        if (acceptor_start >= 0 &&
            acceptor_start + ACCEPTOR_MOTIF_SIZE <= seq_len) {
          bool valid = true;
          // Extract and reverse complement
          char motif[ACCEPTOR_MOTIF_SIZE + 1];
          for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
            motif[pos] = seq[acceptor_start + ACCEPTOR_MOTIF_SIZE - 1 - pos];
          }
          motif[ACCEPTOR_MOTIF_SIZE] = '\0';

          // Apply reverse complement
          for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
            char base = motif[pos];
            char rc_base;
            switch (toupper((unsigned char)base)) {
            case 'A':
              rc_base = 'T';
              break;
            case 'T':
              rc_base = 'A';
              break;
            case 'G':
              rc_base = 'C';
              break;
            case 'C':
              rc_base = 'G';
              break;
            default:
              rc_base = 'N';
              break;
            }

            int idx = base_to_index(rc_base);
            if (idx < 0) {
              valid = false;
              break;
            }
            counts->acceptor_counts[idx][pos]++;
          }
          if (valid) {
            counts->total_acceptor_sites++;
          }
        }
      }
    }
  }

  // Convert counts to log-odds PWM
  SplicePWM* pwm = (SplicePWM*)calloc(1, sizeof(SplicePWM));
  if (!pwm) {
    free(counts);
    return NULL;
  }

  // Background frequencies (assume uniform)
  double bg_freq = 0.25;
  double pseudocount = 1.0;

  // Calculate donor PWM
  pwm->min_donor_score = 0.0;
  for (int pos = 0; pos < DONOR_MOTIF_SIZE; pos++) {
    double position_sum = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      position_sum += counts->donor_counts[base][pos] + pseudocount;
    }

    double min_log_odds = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      double freq =
          (counts->donor_counts[base][pos] + pseudocount) / position_sum;
      double log_odds = log(freq / bg_freq);
      pwm->donor_pwm[base][pos] = log_odds;
      if (log_odds < min_log_odds) {
        min_log_odds = log_odds;
      }
    }
    pwm->min_donor_score += min_log_odds;
  }

  // Calculate acceptor PWM
  pwm->min_acceptor_score = 0.0;
  for (int pos = 0; pos < ACCEPTOR_MOTIF_SIZE; pos++) {
    double position_sum = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      position_sum += counts->acceptor_counts[base][pos] + pseudocount;
    }

    double min_log_odds = 0.0;
    for (int base = 0; base < NUM_NUCLEOTIDES; base++) {
      double freq =
          (counts->acceptor_counts[base][pos] + pseudocount) / position_sum;
      double log_odds = log(freq / bg_freq);
      pwm->acceptor_pwm[base][pos] = log_odds;
      if (log_odds < min_log_odds) {
        min_log_odds = log_odds;
      }
    }
    pwm->min_acceptor_score += min_log_odds;
  }

  fprintf(stderr,
          "Trained splice PWM from %d donor sites and %d acceptor sites\n",
          counts->total_donor_sites, counts->total_acceptor_sites);

  free(counts);
  return pwm;
}

static void handle_train(int argc, char* argv[]) {
  if (argc < 4) {
    fprintf(
        stderr,
        "Usage: %s train <train.fasta> <train.gff> [--wavelet|-w "
        "S1,S2,...|s:e:step] [--kmer|-k K] [--threads|-t N] [--chunk-size N]"
        " [--chunk-overlap M] [--chunk|--no-chunk]\n",
        argv[0]);
    exit(1);
  }

  const char* fasta_path = argv[2];
  const char* gff_path = argv[3];

  // Parse optional arguments
  bool threads_specified = false;
  bool kmer_specified = false;
  for (int i = 4; i < argc; i++) {
    if ((strcmp(argv[i], "--wavelet") == 0 || strcmp(argv[i], "-w") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires an argument\n", argv[i]);
        exit(1);
      }
      const char* arg = argv[++i];
      // If argument contains ':' treat as range start:end:step
      if (strchr(arg, ':')) {
        int parsed =
            parse_wavelet_range(arg, g_wavelet_scales, MAX_NUM_WAVELETS);
        if (parsed < 0) {
          fprintf(stderr, "Error: Invalid wavelet range '%s'\n", arg);
          exit(1);
        }
        g_num_wavelet_scales = parsed;
        fprintf(stderr, "Using %d wavelet scales (range)\n",
                g_num_wavelet_scales);
      } else if (strchr(arg, ',')) {
        g_num_wavelet_scales =
            parse_wavelet_scales(arg, g_wavelet_scales, MAX_NUM_WAVELETS);
        fprintf(stderr, "Using %d wavelet scales (list)\n",
                g_num_wavelet_scales);
      } else {
        // Single numeric value
        double v = atof(arg);
        if (v <= 0.0) {
          fprintf(stderr, "Error: Invalid wavelet scale '%s'\n", arg);
          exit(1);
        }
        g_wavelet_scales[0] = v;
        g_num_wavelet_scales = 1;
        fprintf(stderr, "Using single wavelet scale %.2f\n", v);
      }
    } else if ((strcmp(argv[i], "--kmer") == 0 || strcmp(argv[i], "-k") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a non-negative integer\n", argv[i]);
        exit(1);
      }

      const char* arg = argv[++i];
      char* endptr = NULL;
      errno = 0;
      long parsed = strtol(arg, &endptr, 10);
      if (errno != 0 || endptr == arg || *endptr != '\0' || parsed < 0 ||
          parsed > INT_MAX) {
        fprintf(stderr, "Error: Invalid k-mer size '%s'\n", arg);
        exit(1);
      }

      int candidate = (int)parsed;
      if (candidate > 0) {
        int possible = compute_kmer_feature_count(candidate);
        if (possible < 0) {
          fprintf(stderr,
                  "Error: k-mer size %d is too large for the maximum feature "
                  "capacity (%d)\n",
                  candidate, MAX_NUM_FEATURES);
          exit(1);
        }
      }

      g_kmer_size = candidate;
      kmer_specified = true;
    } else if ((strcmp(argv[i], "--threads") == 0 ||
                strcmp(argv[i], "-t") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int parsed_threads = parse_threads_value(argv[++i]);
      if (parsed_threads < 0) {
        fprintf(stderr, "Error: Invalid thread count '%s'\n", argv[i]);
        exit(1);
      }
      g_num_threads = parsed_threads;
      threads_specified = true;
    } else if (strcmp(argv[i], "--chunk-size") == 0) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int value = 0;
      if (!parse_non_negative_int(argv[++i], &value) || value <= 0) {
        fprintf(stderr, "Error: Invalid chunk size '%s'\n", argv[i]);
        exit(1);
      }
      g_chunk_size = value;
      g_use_chunking = true;
    } else if (strcmp(argv[i], "--chunk-overlap") == 0) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a non-negative integer\n", argv[i]);
        exit(1);
      }
      int value = 0;
      if (!parse_non_negative_int(argv[++i], &value)) {
        fprintf(stderr, "Error: Invalid chunk overlap '%s'\n", argv[i]);
        exit(1);
      }
      g_chunk_overlap = value;
      g_use_chunking = true;
    } else if (strcmp(argv[i], "--chunk") == 0) {
      g_use_chunking = true;
    } else if (strcmp(argv[i], "--no-chunk") == 0) {
      g_use_chunking = false;
    }
  }

  validate_chunk_configuration_or_exit("train");

  if (!update_feature_counts()) {
    fprintf(stderr,
            "Error: Total feature dimensionality exceeds supported maximum "
            "(%d). Adjust wavelet or k-mer settings.\n",
            MAX_NUM_FEATURES);
    exit(1);
  }

  if (kmer_specified && g_kmer_size > 0) {
    fprintf(stderr, "Using k-mer size %d (%d features)\n", g_kmer_size,
            g_kmer_feature_count);
  } else if (!kmer_specified && g_kmer_size > 0) {
    fprintf(stderr, "k-mer size %d active (%d features)\n", g_kmer_size,
            g_kmer_feature_count);
  }

  fprintf(stderr,
          "Feature configuration: %d wavelet dims + %d k-mer dims = %d total\n",
          g_num_wavelet_scales * 4, g_kmer_feature_count,
          g_total_feature_count);

  ensure_thread_count("training", threads_specified);

  // Load training data
  FastaData* genome = parse_fasta(fasta_path);
  if (!genome) {
    fprintf(stderr, "Failed to load FASTA file\n");
    exit(1);
  }
  fprintf(stderr, "Loaded %d sequences\n", genome->count);

  int group_count;
  CdsGroup* groups = parse_gff_for_cds(gff_path, &group_count);
  if (!groups) {
    fprintf(stderr, "Failed to load GFF3 file\n");
    free_fasta_data(genome);
    exit(1);
  }
  fprintf(stderr, "Loaded %d CDS groups\n", group_count);

  for (int i = 0; i < group_count; i++) {
    sort_group_exons(&groups[i]);
  }

  // Extract observation sequences from CDS regions
  // For simplicity, we'll compute feature matrices for all sequences in
  // parallel
  int total_sequences = genome->count * 2;
  double*** observations =
      (double***)malloc(total_sequences * sizeof(double**));
  int* seq_lengths = (int*)malloc(total_sequences * sizeof(int));

  if (!observations || !seq_lengths) {
    fprintf(stderr, "Failed to allocate buffers for training observations\n");
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  for (int i = 0; i < total_sequences; i++) {
    observations[i] = NULL;
    seq_lengths[i] = 0;
  }

  fprintf(stderr,
          "Augmenting training data with reverse complements (%d total "
          "sequences)\n",
          total_sequences);
  fprintf(stderr,
          "Computing feature matrices (wavelet + k-mer) for training sequences "
          "using up to %d threads...\n",
          g_num_threads);

  thread_pool_t* pool = thread_pool_create(g_num_threads);
  if (pool == NULL) {
    fprintf(stderr, "Failed to create thread pool for training\n");
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  pthread_mutex_t error_mutex;
  if (pthread_mutex_init(&error_mutex, NULL) != 0) {
    fprintf(stderr, "Failed to initialize training mutex\n");
    thread_pool_destroy(pool);
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  bool worker_error = false;
  char error_message[256] = {0};
  bool scheduling_failed = false;

  for (int i = 0; i < genome->count && !scheduling_failed; i++) {
    const char* seq = genome->records[i].sequence;
    const char* seq_id = genome->records[i].id;
    int seq_len = strlen(seq);
    int forward_idx = i * 2;
    int reverse_idx = forward_idx + 1;

    training_task_t* forward_task =
        (training_task_t*)malloc(sizeof(training_task_t));
    if (!forward_task) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to allocate training task for %s (+ strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      scheduling_failed = true;
      break;
    }

    memset(forward_task, 0, sizeof(training_task_t));
    forward_task->sequence = seq;
    forward_task->seq_id = seq_id;
    forward_task->seq_len = seq_len;
    forward_task->array_index = forward_idx;
    forward_task->strand = '+';
    forward_task->observations_array = observations;
    forward_task->seq_lengths_array = seq_lengths;
    forward_task->error_mutex = &error_mutex;
    forward_task->error_flag = &worker_error;
    forward_task->error_message = error_message;
    forward_task->error_message_size = sizeof(error_message);
    forward_task->sequence_number = i + 1;
    forward_task->chunk_start = 0;
    forward_task->chunk_end = seq_len;
    forward_task->is_chunk = false;

    if (!thread_pool_add_task(pool, training_observation_worker,
                              forward_task)) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to enqueue training task for %s (+ strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      free(forward_task);
      scheduling_failed = true;
      break;
    }

    training_task_t* reverse_task =
        (training_task_t*)malloc(sizeof(training_task_t));
    if (!reverse_task) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to allocate training task for %s (- strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      scheduling_failed = true;
      break;
    }

    memset(reverse_task, 0, sizeof(training_task_t));
    reverse_task->sequence = seq;
    reverse_task->seq_id = seq_id;
    reverse_task->seq_len = seq_len;
    reverse_task->array_index = reverse_idx;
    reverse_task->strand = '-';
    reverse_task->observations_array = observations;
    reverse_task->seq_lengths_array = seq_lengths;
    reverse_task->error_mutex = &error_mutex;
    reverse_task->error_flag = &worker_error;
    reverse_task->error_message = error_message;
    reverse_task->error_message_size = sizeof(error_message);
    reverse_task->sequence_number = i + 1;
    reverse_task->chunk_start = 0;
    reverse_task->chunk_end = seq_len;
    reverse_task->is_chunk = false;

    if (!thread_pool_add_task(pool, training_observation_worker,
                              reverse_task)) {
      pthread_mutex_lock(&error_mutex);
      if (!worker_error) {
        worker_error = true;
        snprintf(error_message, sizeof(error_message),
                 "Failed to enqueue training task for %s (- strand)",
                 seq_id ? seq_id : "(unknown)");
      }
      pthread_mutex_unlock(&error_mutex);
      free(reverse_task);
      scheduling_failed = true;
      break;
    }
  }

  thread_pool_wait(pool);
  thread_pool_destroy(pool);
  pthread_mutex_destroy(&error_mutex);

  if (worker_error || scheduling_failed) {
    fprintf(stderr, "%s\n",
            error_message[0] ? error_message
                             : "Failed to prepare training observations");
    for (int i = 0; i < total_sequences; i++) {
      if (observations[i]) {
        free_observation_sequence(observations[i], seq_lengths[i]);
      }
    }
    free(observations);
    free(seq_lengths);
    free_cds_groups(groups, group_count);
    free_fasta_data(genome);
    exit(1);
  }

  fprintf(stderr,
          "Computed feature matrices (%d dims) for %d training sequences\n",
          g_total_feature_count, total_sequences);

  // Initialize HMM model
  HMMModel model;
  hmm_init(&model, g_total_feature_count);
  model.wavelet_feature_count = g_num_wavelet_scales * 4;
  model.kmer_feature_count = g_kmer_feature_count;
  model.kmer_size = g_kmer_size;

  fprintf(stderr, "Starting supervised training with two passes...\n");

  // =========================================================================
  // PASS 1: Calculate global statistics for Z-score normalization
  // =========================================================================
  fprintf(stderr, "Pass 1: Computing global feature statistics...\n");

  double sum[MAX_NUM_FEATURES] = {0};
  double sum_sq[MAX_NUM_FEATURES] = {0};
  long long total_count = 0;

  int global_num_features = model.num_features;
  if (global_num_features > MAX_NUM_FEATURES)
    global_num_features = MAX_NUM_FEATURES;

  for (int seq_idx = 0; seq_idx < total_sequences; seq_idx++) {
    if (!observations[seq_idx] || seq_lengths[seq_idx] == 0) {
      continue;
    }

    int seq_len = seq_lengths[seq_idx];
    for (int t = 0; t < seq_len; t++) {
      for (int f = 0; f < global_num_features; f++) {
        double val = observations[seq_idx][t][f];
        sum[f] += val;
        sum_sq[f] += val * val;
      }
      total_count++;
    }
  }

  // Calculate mean and standard deviation
  for (int f = 0; f < global_num_features; f++) {
    model.global_feature_mean[f] = sum[f] / total_count;
    double variance =
        (sum_sq[f] / total_count) -
        (model.global_feature_mean[f] * model.global_feature_mean[f]);
    model.global_feature_stddev[f] = sqrt(variance > 1e-10 ? variance : 1e-10);
  }

  fprintf(stderr, "Global statistics computed from %lld observations\n",
          total_count);

  fprintf(stderr,
          "Applying Z-score normalization to training observations...\n");
  normalize_observations_in_place(observations, seq_lengths, total_sequences,
                                  &model);

  // =========================================================================
  // PASS 2: Supervised parameter estimation using GFF annotations
  // =========================================================================
  fprintf(stderr, "Pass 2: Learning HMM parameters from annotations...\n");

  // Initialize accumulators
  long long transition_counts[NUM_STATES][NUM_STATES] = {{0}};
  double emission_sum[NUM_STATES][MAX_NUM_FEATURES] = {{0}};
  double emission_sum_sq[NUM_STATES][MAX_NUM_FEATURES] = {{0}};
  long long state_observation_counts[NUM_STATES] = {0};
  long long initial_counts[NUM_STATES] = {0};

  // Process each sequence to accumulate statistics
  for (int seq_idx = 0; seq_idx < genome->count; seq_idx++) {
    const char* seq_id = genome->records[seq_idx].id;
    int seq_len = strlen(genome->records[seq_idx].sequence);

    if (seq_len <= 0)
      continue;

    int forward_obs_idx = seq_idx * 2;
    int reverse_obs_idx = forward_obs_idx + 1;

    int* state_labels = (int*)malloc(seq_len * sizeof(int));
    if (!state_labels) {
      fprintf(stderr, "Warning: Failed to allocate state labels for %s\n",
              seq_id);
      continue;
    }

    if (forward_obs_idx < total_sequences && observations[forward_obs_idx] &&
        seq_lengths[forward_obs_idx] > 0) {
      initialize_state_labels(state_labels, seq_len);
      label_forward_states(groups, group_count, seq_id, seq_len, state_labels);
      // printf("DEBUG FWD LABELS for %s:\n", seq_id);
      // for (int k = 0; k < seq_len; k++) {
      //   printf("%d", state_labels[k]);
      // }
      printf("\n");
      accumulate_statistics_for_sequence(
          &model, observations, seq_lengths, forward_obs_idx, seq_len,
          state_labels, transition_counts, emission_sum, emission_sum_sq,
          state_observation_counts, initial_counts);
    }

    if (reverse_obs_idx < total_sequences && observations[reverse_obs_idx] &&
        seq_lengths[reverse_obs_idx] > 0) {
      initialize_state_labels(state_labels, seq_len);
      label_reverse_states(groups, group_count, seq_id, seq_len, state_labels);
      // printf("DEBUG REV LABELS for %s:\n", seq_id);
      // for (int k = 0; k < seq_len; k++) {
      //   printf("%d", state_labels[k]);
      // }
      printf("\n");
      accumulate_statistics_for_sequence(
          &model, observations, seq_lengths, reverse_obs_idx, seq_len,
          state_labels, transition_counts, emission_sum, emission_sum_sq,
          state_observation_counts, initial_counts);
    }

    free(state_labels);
  }

  fprintf(stderr, "Finalizing HMM parameters...\n");

  // Finalize initial probabilities
  long long total_initial = 0;
  for (int i = 0; i < NUM_STATES; i++) {
    total_initial += initial_counts[i];
  }
  for (int i = 0; i < NUM_STATES; i++) {
    if (total_initial > 0) {
      model.initial[i] = (double)initial_counts[i] / total_initial;
    } else {
      model.initial[i] = 1.0 / NUM_STATES;
    }
    // Ensure minimum probability
    if (model.initial[i] < 1e-10) {
      model.initial[i] = 1e-10;
    }
  }

  // Finalize transition probabilities
  for (int i = 0; i < NUM_STATES; i++) {
    long long row_sum = 0;
    for (int j = 0; j < NUM_STATES; j++) {
      row_sum += transition_counts[i][j];
    }

    for (int j = 0; j < NUM_STATES; j++) {
      if (row_sum > 0) {
        model.transition[i][j] = (double)transition_counts[i][j] / row_sum;
      } else {
        model.transition[i][j] = 1.0 / NUM_STATES;
      }
      // Ensure minimum probability
      if (model.transition[i][j] < 1e-10) {
        model.transition[i][j] = 1e-10;
      }
    }
  }

  // Finalize emission parameters (mean and variance)
  int num_features = model.num_features;
  if (num_features > MAX_NUM_FEATURES)
    num_features = MAX_NUM_FEATURES;
  for (int i = 0; i < NUM_STATES; i++) {
    model.emission[i].num_features = num_features;

    for (int f = 0; f < num_features; f++) {
      if (state_observation_counts[i] > 0) {
        double mean = emission_sum[i][f] / state_observation_counts[i];
        double mean_sq = emission_sum_sq[i][f] / state_observation_counts[i];
        double variance = mean_sq - mean * mean;

        model.emission[i].mean[f] = mean;
        model.emission[i].variance[f] = (variance > 1e-6) ? variance : 1e-6;
      } else {
        // No observations for this state, use defaults
        model.emission[i].mean[f] = 0.0;
        model.emission[i].variance[f] = 1.0;
      }
    }

    fprintf(stderr, "State %d: %lld observations\n", i,
            state_observation_counts[i]);
  }

  enforce_exon_cycle_constraints(&model);

  fprintf(stderr, "Supervised training complete.\n");

  // Train splice site PWM model
  fprintf(stderr, "Training splice site PWM model...\n");
  SplicePWM* splice_pwm = train_splice_model(genome, groups, group_count);
  if (splice_pwm) {
    fprintf(
        stderr,
        "Splice PWM training complete (min donor=%.3f, min acceptor=%.3f)\n",
        splice_pwm->min_donor_score, splice_pwm->min_acceptor_score);

    // Store PWM in model for use during prediction
    model.pwm.has_donor = 1;
    model.pwm.has_acceptor = 1;
    model.pwm.pwm_weight = 1.0;
    model.pwm.min_donor_score = splice_pwm->min_donor_score;
    model.pwm.min_acceptor_score = splice_pwm->min_acceptor_score;

    // Copy PWM matrices
    for (int i = 0; i < NUM_NUCLEOTIDES; i++) {
      for (int j = 0; j < DONOR_MOTIF_SIZE; j++) {
        model.pwm.donor_pwm[i][j] = splice_pwm->donor_pwm[i][j];
      }
      for (int j = 0; j < ACCEPTOR_MOTIF_SIZE; j++) {
        model.pwm.acceptor_pwm[i][j] = splice_pwm->acceptor_pwm[i][j];
      }
    }

    free(splice_pwm);
    fprintf(stderr, "PWM integrated into model.\n");
  } else {
    fprintf(stderr, "Warning: Failed to train splice PWM model\n");
  }

  const int kBaumWelchMaxIterations = 100;
  const double kBaumWelchThreshold = 10.0;

  fprintf(
      stderr,
      "Starting Baum-Welch refinement on %d sequences (semi-supervised)...\n",
      total_sequences);
  if (!hmm_train_baum_welch(&model, observations, seq_lengths, total_sequences,
                            kBaumWelchMaxIterations, kBaumWelchThreshold)) {
    fprintf(stderr, "Baum-Welch refinement failed\n");
    exit(1);
  }
  enforce_exon_cycle_constraints(&model);
  fprintf(stderr, "Baum-Welch refinement complete.\n");

  // Save model
  if (!hmm_save_model(&model, "sunfish.model")) {
    fprintf(stderr, "Failed to save model\n");
    exit(1);
  }
  fprintf(stderr, "Model saved to sunfish.model\n");

  // Cleanup
  for (int i = 0; i < total_sequences; i++) {
    if (observations[i]) {
      free_observation_sequence(observations[i], seq_lengths[i]);
    }
  }
  free(observations);
  free(seq_lengths);

  free_cds_groups(groups, group_count);
  free_fasta_data(genome);
}

// Prediction mode: Parallel Viterbi prediction
static void handle_predict(int argc, char* argv[]) {
  if (argc < 3) {
    fprintf(
        stderr,
        "Usage: %s predict <target.fasta> [--wavelet|-w "
        "S1,S2,...|s:e:step] [--kmer|-k K] [--threads|-t N] [--chunk-size N]"
        " [--chunk-overlap M] [--chunk|--no-chunk]\n",
        argv[0]);
    exit(1);
  }

  const char* fasta_path = argv[2];

  bool threads_specified = false;
  bool kmer_specified = false;
  for (int i = 3; i < argc; i++) {
    if ((strcmp(argv[i], "--wavelet") == 0 || strcmp(argv[i], "-w") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires an argument\n", argv[i]);
        exit(1);
      }
      const char* arg = argv[++i];
      if (strchr(arg, ':')) {
        int parsed =
            parse_wavelet_range(arg, g_wavelet_scales, MAX_NUM_WAVELETS);
        if (parsed < 0) {
          fprintf(stderr, "Error: Invalid wavelet range '%s'\n", arg);
          exit(1);
        }
        g_num_wavelet_scales = parsed;
        fprintf(stderr, "Using %d wavelet scales (range)\n",
                g_num_wavelet_scales);
      } else if (strchr(arg, ',')) {
        g_num_wavelet_scales =
            parse_wavelet_scales(arg, g_wavelet_scales, MAX_NUM_WAVELETS);
        fprintf(stderr, "Using %d wavelet scales (list)\n",
                g_num_wavelet_scales);
      } else {
        double v = atof(arg);
        if (v <= 0.0) {
          fprintf(stderr, "Error: Invalid wavelet scale '%s'\n", arg);
          exit(1);
        }
        g_wavelet_scales[0] = v;
        g_num_wavelet_scales = 1;
        fprintf(stderr, "Using single wavelet scale %.2f\n", v);
      }
    } else if ((strcmp(argv[i], "--kmer") == 0 || strcmp(argv[i], "-k") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a non-negative integer\n", argv[i]);
        exit(1);
      }

      const char* arg = argv[++i];
      char* endptr = NULL;
      errno = 0;
      long parsed = strtol(arg, &endptr, 10);
      if (errno != 0 || endptr == arg || *endptr != '\0' || parsed < 0 ||
          parsed > INT_MAX) {
        fprintf(stderr, "Error: Invalid k-mer size '%s'\n", arg);
        exit(1);
      }

      int candidate = (int)parsed;
      if (candidate > 0) {
        int possible = compute_kmer_feature_count(candidate);
        if (possible < 0) {
          fprintf(stderr,
                  "Error: k-mer size %d is too large for the maximum feature "
                  "capacity (%d)\n",
                  candidate, MAX_NUM_FEATURES);
          exit(1);
        }
      }

      g_kmer_size = candidate;
      kmer_specified = true;
    } else if ((strcmp(argv[i], "--threads") == 0 ||
                strcmp(argv[i], "-t") == 0)) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int parsed_threads = parse_threads_value(argv[++i]);
      if (parsed_threads < 0) {
        fprintf(stderr, "Error: Invalid thread count '%s'\n", argv[i]);
        exit(1);
      }
      g_num_threads = parsed_threads;
      threads_specified = true;
    } else if (strcmp(argv[i], "--chunk-size") == 0) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a positive integer\n", argv[i]);
        exit(1);
      }
      int value = 0;
      if (!parse_non_negative_int(argv[++i], &value) || value <= 0) {
        fprintf(stderr, "Error: Invalid chunk size '%s'\n", argv[i]);
        exit(1);
      }
      g_chunk_size = value;
      g_use_chunking = true;
    } else if (strcmp(argv[i], "--chunk-overlap") == 0) {
      if (i + 1 >= argc) {
        fprintf(stderr, "Error: %s requires a non-negative integer\n", argv[i]);
        exit(1);
      }
      int value = 0;
      if (!parse_non_negative_int(argv[++i], &value)) {
        fprintf(stderr, "Error: Invalid chunk overlap '%s'\n", argv[i]);
        exit(1);
      }
      g_chunk_overlap = value;
      g_use_chunking = true;
    } else if (strcmp(argv[i], "--chunk") == 0) {
      g_use_chunking = true;
    } else if (strcmp(argv[i], "--no-chunk") == 0) {
      g_use_chunking = false;
    }
  }

  validate_chunk_configuration_or_exit("predict");

  if (!update_feature_counts()) {
    fprintf(stderr,
            "Error: Total feature dimensionality exceeds supported maximum "
            "(%d). Adjust wavelet or k-mer settings.\n",
            MAX_NUM_FEATURES);
    exit(1);
  }

  ensure_thread_count("prediction", threads_specified);

  // Load HMM model
  HMMModel model;
  if (!hmm_load_model(&model, "sunfish.model")) {
    fprintf(stderr, "Failed to load model. Run 'train' first.\n");
    exit(1);
  }
  fprintf(stderr, "Loaded HMM model with %d features\n", model.num_features);

  if (model.kmer_size > 0) {
    int possible = compute_kmer_feature_count(model.kmer_size);
    if (possible < 0) {
      fprintf(stderr,
              "Error: Model encodes unsupported k-mer size %d for current "
              "build (max %d). Re-train with smaller k.\n",
              model.kmer_size, MAX_NUM_FEATURES);
      exit(1);
    }
  }

  if (kmer_specified) {
    if (g_kmer_size != model.kmer_size) {
      fprintf(stderr,
              "Error: Model trained with k-mer size %d but CLI specified %d. "
              "Please supply matching --kmer value.\n",
              model.kmer_size, g_kmer_size);
      exit(1);
    }
  } else {
    g_kmer_size = model.kmer_size;
  }

  if (!update_feature_counts()) {
    fprintf(stderr,
            "Error: Total feature dimensionality exceeds supported maximum "
            "(%d). Adjust wavelet or k-mer settings.\n",
            MAX_NUM_FEATURES);
    exit(1);
  }

  if (g_total_feature_count != model.num_features) {
    fprintf(stderr,
            "Error: Feature dimension mismatch. Model expects %d dims (wavelet "
            "%d, k-mer %d) but current configuration yields %d dims (wavelet "
            "%d, k-mer %d). Align --wavelet/--kmer with training.\n",
            model.num_features, model.wavelet_feature_count,
            model.kmer_feature_count, g_total_feature_count,
            g_num_wavelet_scales * 2, g_kmer_feature_count);
    exit(1);
  }

  if (g_kmer_size > 0) {
    if (kmer_specified) {
      fprintf(stderr, "Using k-mer size %d (%d features)\n", g_kmer_size,
              g_kmer_feature_count);
    } else {
      fprintf(stderr, "Model k-mer size %d (%d features) in use\n", g_kmer_size,
              g_kmer_feature_count);
    }
  }

  fprintf(stderr,
          "Feature configuration: %d wavelet dims + %d k-mer dims = %d total\n",
          g_num_wavelet_scales * 4, g_kmer_feature_count,
          g_total_feature_count);

  // Initialize output queue
  output_queue_init(&g_output_queue);
  g_gene_counter = 0;

  // Create thread pool
  thread_pool_t* pool = thread_pool_create(g_num_threads);
  if (pool == NULL) {
    fprintf(stderr, "Failed to create thread pool\n");
    exit(1);
  }

  // Load FASTA
  FastaData* genome = parse_fasta(fasta_path);
  if (!genome) {
    fprintf(stderr, "Failed to load FASTA file\n");
    thread_pool_destroy(pool);
    exit(1);
  }

  if (g_use_chunking) {
    int step = (g_chunk_size > g_chunk_overlap)
                   ? (g_chunk_size - g_chunk_overlap)
                   : g_chunk_size;
    fprintf(stderr,
            "Chunking enabled: chunk size %d bp, overlap %d bp (step %d bp)\n",
            g_chunk_size, g_chunk_overlap, step);
  } else {
    fprintf(stderr, "Chunking disabled; processing full sequences\n");
  }

  printf("##gff-version 3\n");

  // Submit prediction tasks to thread pool
  for (int i = 0; i < genome->count; i++) {
    const char* seq = genome->records[i].sequence;
    const char* seq_id = genome->records[i].id;
    int seq_len = strlen(seq);
    int chunk_count =
        calculate_num_chunks(seq_len, g_chunk_size, g_chunk_overlap);
    if (chunk_count < 1)
      chunk_count = 1;

    if (chunk_count > 1) {
      fprintf(
          stderr,
          "Splitting %s into %d chunk(s) per strand (size %d, overlap %d)\n",
          seq_id, chunk_count, g_chunk_size, g_chunk_overlap);
    }

    for (int chunk_idx = 0; chunk_idx < chunk_count; chunk_idx++) {
      int chunk_start = 0;
      int chunk_end = 0;
      get_chunk_bounds(seq_len, g_chunk_size, g_chunk_overlap, chunk_idx,
                       &chunk_start, &chunk_end);
      int chunk_len = chunk_end - chunk_start;
      if (chunk_len <= 0)
        continue;

      prediction_task_t* task =
          (prediction_task_t*)malloc(sizeof(prediction_task_t));
      if (!task) {
        fprintf(
            stderr,
            "Warning: Failed to allocate task for %s (+ strand chunk %d/%d)\n",
            seq_id, chunk_idx + 1, chunk_count);
        continue;
      }

      char* chunk_seq = (char*)malloc((size_t)chunk_len + 1);
      if (!chunk_seq) {
        fprintf(stderr,
                "Warning: Failed to allocate sequence buffer for %s (+ strand "
                "chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task);
        continue;
      }
      memcpy(chunk_seq, seq + chunk_start, (size_t)chunk_len);
      chunk_seq[chunk_len] = '\0';

      char* seq_id_copy = strdup(seq_id);
      if (!seq_id_copy) {
        fprintf(stderr,
                "Warning: Failed to duplicate sequence ID for %s (+ strand)\n",
                seq_id);
        free(chunk_seq);
        free(task);
        continue;
      }

      task->sequence = chunk_seq;
      task->seq_id = seq_id_copy;
      task->strand = '+';
      task->model = &model;
      task->original_length = seq_len;
      task->chunk_offset = chunk_start;
      task->chunk_index = chunk_idx;
      task->chunk_count = chunk_count;

      if (!thread_pool_add_task(pool, predict_sequence_worker, task)) {
        fprintf(stderr,
                "Warning: Failed to enqueue %s (+ strand chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task->sequence);
        free(task->seq_id);
        free(task);
      } else {
        if (chunk_count > 1) {
          fprintf(stderr, "Processing %s (+ strand chunk %d/%d)...\n", seq_id,
                  chunk_idx + 1, chunk_count);
        } else {
          fprintf(stderr, "Processing %s (+ strand)...\n", seq_id);
        }
      }
    }

    char* rc_full = reverse_complement(seq);
    if (!rc_full) {
      fprintf(stderr, "Warning: Failed to generate reverse complement for %s\n",
              seq_id);
      continue;
    }

    for (int chunk_idx = 0; chunk_idx < chunk_count; chunk_idx++) {
      int chunk_start = 0;
      int chunk_end = 0;
      get_chunk_bounds(seq_len, g_chunk_size, g_chunk_overlap, chunk_idx,
                       &chunk_start, &chunk_end);
      int chunk_len = chunk_end - chunk_start;
      if (chunk_len <= 0)
        continue;

      prediction_task_t* task =
          (prediction_task_t*)malloc(sizeof(prediction_task_t));
      if (!task) {
        fprintf(
            stderr,
            "Warning: Failed to allocate task for %s (- strand chunk %d/%d)\n",
            seq_id, chunk_idx + 1, chunk_count);
        continue;
      }

      char* chunk_seq = (char*)malloc((size_t)chunk_len + 1);
      if (!chunk_seq) {
        fprintf(stderr,
                "Warning: Failed to allocate sequence buffer for %s (- strand "
                "chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task);
        continue;
      }
      memcpy(chunk_seq, rc_full + chunk_start, (size_t)chunk_len);
      chunk_seq[chunk_len] = '\0';

      char* seq_id_copy = strdup(seq_id);
      if (!seq_id_copy) {
        fprintf(stderr,
                "Warning: Failed to duplicate sequence ID for %s (- strand)\n",
                seq_id);
        free(chunk_seq);
        free(task);
        continue;
      }

      task->sequence = chunk_seq;
      task->seq_id = seq_id_copy;
      task->strand = '-';
      task->model = &model;
      task->original_length = seq_len;
      task->chunk_offset = chunk_start;
      task->chunk_index = chunk_idx;
      task->chunk_count = chunk_count;

      if (!thread_pool_add_task(pool, predict_sequence_worker, task)) {
        fprintf(stderr,
                "Warning: Failed to enqueue %s (- strand chunk %d/%d)\n",
                seq_id, chunk_idx + 1, chunk_count);
        free(task->sequence);
        free(task->seq_id);
        free(task);
      } else {
        if (chunk_count > 1) {
          fprintf(stderr, "Processing %s (- strand chunk %d/%d)...\n", seq_id,
                  chunk_idx + 1, chunk_count);
        } else {
          fprintf(stderr, "Processing %s (- strand)...\n", seq_id);
        }
      }
    }

    free(rc_full);
  }

  // Wait for all tasks to complete
  thread_pool_wait(pool);

  // Flush output
  output_queue_flush(&g_output_queue);

  fprintf(stderr, "Prediction complete. Found %d genes.\n", g_gene_counter);

  // Cleanup
  thread_pool_destroy(pool);
  output_queue_destroy(&g_output_queue);
  free_fasta_data(genome);
}

int main(int argc, char* argv[]) {
  // Ensure real-time output behavior
  setvbuf(stdout, NULL, _IOLBF, 0);
  setvbuf(stderr, NULL, _IONBF, 0);

  if (!update_feature_counts()) {
    fprintf(stderr,
            "Error: Default feature configuration exceeds supported limits.\n"
            "Adjust MAX_NUM_FEATURES or reduce wavelet/k-mer settings.\n");
    return 1;
  }

  if (argc < 2) {
    print_help(argv[0]);
    return 0;
  }

  if (strcmp(argv[1], "help") == 0 || strcmp(argv[1], "--help") == 0 ||
      strcmp(argv[1], "-h") == 0) {
    print_help(argv[0]);
    return 0;
  }

  if (strcmp(argv[1], "train") == 0) {
    handle_train(argc, argv);
  } else if (strcmp(argv[1], "predict") == 0) {
    handle_predict(argc, argv);
  } else {
    fprintf(stderr, "Error: Unknown mode '%s'\n", argv[1]);
    fprintf(stderr, "Valid commands: help, train, predict\n");
    print_help(argv[0]);
    return 1;
  }

  return 0;

==> src/thread_pool.c <==
#include <pthread.h>
#include <stdbool.h>
#include <stdlib.h>

#include "../include/thread_pool.h"

// Worker thread function
static void* worker_thread(void* arg) {
  thread_pool_t* pool = (thread_pool_t*)arg;
  
  while (true) {
    pthread_mutex_lock(&pool->queue_mutex);
    
    // Wait for a task or shutdown signal
    while (pool->task_queue_head == NULL && !pool->shutdown) {
      pthread_cond_wait(&pool->queue_cond, &pool->queue_mutex);
    }
    
    // Check for shutdown
    if (pool->shutdown && pool->task_queue_head == NULL) {
      pthread_mutex_unlock(&pool->queue_mutex);
      break;
    }
    
    // Dequeue task
    task_t* task = pool->task_queue_head;
    if (task != NULL) {
      pool->task_queue_head = task->next;
      if (pool->task_queue_head == NULL) {
        pool->task_queue_tail = NULL;
      }
      pool->active_tasks++;
    }
    
    pthread_mutex_unlock(&pool->queue_mutex);
    
    // Execute task
    if (task != NULL) {
      task->function(task->argument);
      free(task);
      
      pthread_mutex_lock(&pool->queue_mutex);
      pool->active_tasks--;
      if (pool->active_tasks == 0 && pool->task_queue_head == NULL) {
        pthread_cond_broadcast(&pool->done_cond);
      }
      pthread_mutex_unlock(&pool->queue_mutex);
    }
  }
  
  return NULL;
}

thread_pool_t* thread_pool_create(int num_threads) {
  if (num_threads <= 0) {
    return NULL;
  }
  
  thread_pool_t* pool = (thread_pool_t*)malloc(sizeof(thread_pool_t));
  if (pool == NULL) {
    return NULL;
  }
  
  pool->thread_count = num_threads;
  pool->task_queue_head = NULL;
  pool->task_queue_tail = NULL;
  pool->active_tasks = 0;
  pool->shutdown = false;
  
  // Initialize mutex and condition variables
  if (pthread_mutex_init(&pool->queue_mutex, NULL) != 0) {
    free(pool);
    return NULL;
  }
  
  if (pthread_cond_init(&pool->queue_cond, NULL) != 0) {
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  if (pthread_cond_init(&pool->done_cond, NULL) != 0) {
    pthread_cond_destroy(&pool->queue_cond);
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  // Allocate thread array
  pool->threads = (pthread_t*)malloc(sizeof(pthread_t) * num_threads);
  if (pool->threads == NULL) {
    pthread_cond_destroy(&pool->done_cond);
    pthread_cond_destroy(&pool->queue_cond);
    pthread_mutex_destroy(&pool->queue_mutex);
    free(pool);
    return NULL;
  }
  
  // Create worker threads
  for (int i = 0; i < num_threads; i++) {
    if (pthread_create(&pool->threads[i], NULL, worker_thread, pool) != 0) {
      // Failed to create thread, cleanup
      pool->shutdown = true;
      pthread_cond_broadcast(&pool->queue_cond);
      for (int j = 0; j < i; j++) {
        pthread_join(pool->threads[j], NULL);
      }
      free(pool->threads);
      pthread_cond_destroy(&pool->done_cond);
      pthread_cond_destroy(&pool->queue_cond);
      pthread_mutex_destroy(&pool->queue_mutex);
      free(pool);
      return NULL;
    }
  }
  
  return pool;
}

bool thread_pool_add_task(thread_pool_t* pool, task_func_t function, void* arg) {
  if (pool == NULL || function == NULL) {
    return false;
  }
  
  task_t* task = (task_t*)malloc(sizeof(task_t));
  if (task == NULL) {
    return false;
  }
  
  task->function = function;
  task->argument = arg;
  task->next = NULL;
  
  pthread_mutex_lock(&pool->queue_mutex);
  
  if (pool->shutdown) {
    pthread_mutex_unlock(&pool->queue_mutex);
    free(task);
    return false;
  }
  
  // Enqueue task
  if (pool->task_queue_tail == NULL) {
    pool->task_queue_head = task;
    pool->task_queue_tail = task;
  } else {
    pool->task_queue_tail->next = task;
    pool->task_queue_tail = task;
  }
  
  pthread_cond_signal(&pool->queue_cond);
  pthread_mutex_unlock(&pool->queue_mutex);
  
  return true;
}

void thread_pool_wait(thread_pool_t* pool) {
  if (pool == NULL) {
    return;
  }
  
  pthread_mutex_lock(&pool->queue_mutex);
  
  while (pool->active_tasks > 0 || pool->task_queue_head != NULL) {
    pthread_cond_wait(&pool->done_cond, &pool->queue_mutex);
  }
  
  pthread_mutex_unlock(&pool->queue_mutex);
}

void thread_pool_destroy(thread_pool_t* pool) {
  if (pool == NULL) {
    return;
  }
  
  pthread_mutex_lock(&pool->queue_mutex);
  pool->shutdown = true;
  pthread_cond_broadcast(&pool->queue_cond);
  pthread_mutex_unlock(&pool->queue_mutex);
  
  // Join all threads
  for (int i = 0; i < pool->thread_count; i++) {
    pthread_join(pool->threads[i], NULL);
  }
  
  // Free remaining tasks in queue
  task_t* task = pool->task_queue_head;
  while (task != NULL) {
    task_t* next = task->next;
    free(task);
    task = next;
  }
  
  free(pool->threads);
  pthread_cond_destroy(&pool->done_cond);
  pthread_cond_destroy(&pool->queue_cond);
  pthread_mutex_destroy(&pool->queue_mutex);
  free(pool);

==> src/utils.c <==
#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "../include/sunfish.h"

static char complement_base(char base) {
  switch (toupper((unsigned char)base)) {
  case 'A':
    return 'T';
  case 'T':
    return 'A';
  case 'G':
    return 'C';
  case 'C':
    return 'G';
  default:
    return 'N';
  }
}

char* reverse_complement(const char* sequence) {
  if (sequence == NULL) {
    return NULL;
  }

  size_t len = strlen(sequence);
  char* rc = (char*)malloc(len + 1);
  if (!rc) {
    return NULL;
  }

  for (size_t i = 0; i < len; i++) {
    rc[i] = complement_base(sequence[len - 1 - i]);
  }
  rc[len] = '\0';

  return rc;
